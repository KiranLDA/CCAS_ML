#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Feb 10 16:44:39 2020

@author: kiran
"""
# function dependencies
import librosa
import librosa.display
import numpy as np
import pandas as pd
import warnings
import decimal #import *
import functools
import random
import os
import re


def generate_mel_spectrogram(y, sr, start, stop, n_mels, window, fft_win , fft_hop , normalise):
    ''' Generate a mel frequency spectrogram
    
    The input will be an image of the sound which is generated using a spectrogram. This generates the spectrogram
    y:
        sound dataframe containing values from wav file 
    sr:
        sample rate in Hz
    start:
        start time be used to subset y and generate spectrogram (in seconds)
    stop:
        end timeto be used to subset y and generate spectrogram (in seconds)
    n_mels: 
        number of mel bands - suggested 64 or 128
    window: 
        spectrogram window generation type - suggested "hann"
    fft_win: 
        window length (in seconds)
    fft_hop: 
        hop between window starts (in seconds)
    normalise:
        true or false depending on whether we want to normalise accross the 
        mel bands to remove noise and get stronger signal
    
    '''
    win_length  = int(fft_win * sr) 
    hop_length = int(fft_hop * sr) 
    
    start = int(round(sr * decimal.Decimal(start),3))
    stop =  int(round(sr * decimal.Decimal(stop),3))
    
    data_subset = np.asfortranarray(y[start:stop])
    
    s = librosa.feature.melspectrogram(y = data_subset ,
                                       sr = sr, 
                                       n_mels = n_mels , 
                                       fmax = sr/2, 
                                       n_fft = win_length,
                                       hop_length = hop_length, 
                                       window = window, 
                                       win_length = win_length )
    spectro = librosa.power_to_db(s, ref=np.max)
    
    if normalise:
        spectro = spectro - spectro.mean(axis=0, keepdims=True)

    return spectro


def get_sec_long(time_str):
    """Get Seconds from time which is in string format h:m:s.000"""
    h, m, s = time_str.split(':')
    return float(int(h) * 3600 + int(m) * 60 + decimal.Decimal(s))

def get_sec_short(time_str):
    """Get Seconds from time which is in string format m:s.000"""
    m, s = time_str.split(':')
    return float(int(m) * 60 + decimal.Decimal(s))

def try_time(x):
    try: 
        y = get_sec_short(x) 
    except ValueError: 
        y = get_sec_long(x)
    return(y)   

def convert_secs_to_fulltime(x):
    return "%02d:%02d:%02d.%03d" % \
        functools.reduce(lambda ll,b : divmod(ll[0],b) + ll[1:],
               [(round(x*1000),),1000,60,60])
    
def create_table(label_path, call_types, sep, start_column, duration_column, 
             label_column, convert_to_seconds, label_for_other, label_for_noise , engine, multiclass_forbidden):
    ''' 
    This function
    (1) reads in a csv label file generated by audition, 
    (2) converts the start and duration to seconds and estimates end time, and 
    (3) matches the different labels into call types
    
    label_path:
        file path to a csv or text label file generated by audition or raven
    call_types:
        a dictionary of call types and how they are labelled in the data - it is not case sensitive
    sep:
        Input is a string. This is to specify the separator for reading in the label file. 
        For instancance "\t" can  be used to represent a tab delimited text file.
    start_column:
         Input is a string. THis is the name of the column containing the start time of the labelled calls
    duration_column:
        Input is a string. THis is the name of the column containing the duration value of the labelled calls
    label_column:
        Input is a string. THis is the name of the column containing the labels
    convert_to_seconds:
        Input is boolean (i.e. True or False). If true, then start time and duration time will be converted to seconds
    label_for_other:
        string which specifies which label any labels which do not fall into the call_types dectionary will be allocated to. 
        For instance, with meerkats, the 'chew' label might be relabelled as "oth". Normally this should be 
        in the call_types dictionary, but if not, this label will be created.
    label_for_noise:
        string used to label bakcground noise
    engine:
        parameter from pandas read_csv function which is to do with how sep is read
    multiclass_forbidden:
        Can be true or false. This value decides whether each call can be classed as multiple things, i.e. close call and movement fusion if false, or other if false
    '''
    # import the labels from the csv document
    raw_table  = pd.read_csv(label_path, sep=sep, header=0, engine = engine) 
    
    # create an empty table which will be the output of the function
    label_table = pd.DataFrame()
    label_table["Label"] = raw_table[label_column]
    label_table["Start"] = raw_table[start_column]
    label_table["Duration"] = raw_table[duration_column]
    
    # if time is not in seconds, convert to sectonds
    if convert_to_seconds:
        f = lambda x: try_time(x[start_column])
        label_table["Start"] = raw_table.apply(f, axis=1)
        
        f = lambda x: get_sec_short(x[duration_column])
        label_table["Duration"] = raw_table.apply(f, axis=1)
        
    # add an end time
    f = lambda x: float(x["Start"]) + float(x["Duration"])
    label_table["End"] = label_table.apply(f, axis=1)
    
    
    # loop through the labels and turn them into a true/false columns
    for true_label in call_types:
        label_table[true_label] = False
        for old_label in call_types[true_label]:
            label_table.loc[label_table["Label"].str.contains(old_label, regex=True, case = False), true_label] = True
    
    # Check which columns are in no category and allocate them to other
    df = label_table[list(call_types.keys())]
    unclassed = df.apply(lambda row: True if not any(row) else False if True in list(row) else np.nan, axis=1)
    if any(unclassed == True):
        warnings.warn("These values will be classed as other : " + str(list(label_table["Label"][list(unclassed)])))
        label_table.loc[list(unclassed), label_for_other] = True

    # ensure that each call is not allocated to two categories
    if multiclass_forbidden:
        calls = list(call_types.keys())[0:(len(call_types.keys())-2)]

        # find calls with multiple labels
        df = label_table[calls]
        label_table.loc[(df == True).sum(axis=1) >= 2, calls] = False
        label_table.loc[(df == True).sum(axis=1) >= 2, label_for_other] = True
        
        # find one call which is also other
        df = label_table[calls]     
        label_table.loc[((df == True).sum(axis=1) == 1) & (label_table[label_for_other]==True), label_for_other] = False
        label_table.loc[((df == True).sum(axis=1) == 1) & (label_table[label_for_noise]==True), label_for_noise] = False


    return label_table

def create_label_matrix(label_table, spectro, call_types, start, stop, label_for_noise):
    '''
    This function creates a matrix where each row represents a calltype over time where each bin corresponds 
    to a spectrogram. Typially the calltypes label
    label_table:
        this is the output from create_table which outputs a pandas table with the following columns
            "Label" - a label for a particular call type e.g. "cc" for close call
            "Start" - start time in seconds of the call events
            "Duraion" - duration in seconds of the call events
            "End" - end time in seconds of the call events
            a sequence of labels defined from the call_types dictionary and containing only True and False
    spectro:
        spectrogram generated by create_spectrogram
    call_types:
        a dictionary of call types and how they are labelled in the data - it is not case sensitive
    start:
        start time in seconds of the spectrogram (rolling window)
    stop:
        end time in seconds of the spectrogram (rolling window)
    label_for_noise:
        string used to label bakcground noise
    '''
    
    timesteps = spectro.shape[1] # find number of columns for matrix
    colnames = np.linspace(start, stop, num=timesteps)#np.arange(start=start, stop=stop, step=(stop-start)/timesteps)
    rownames = call_types.keys()
    # timesteps_per_second = timesteps / spec_window_size 
    
    # create an empty matrix where each row represents a call type 
    # and each column represents a timestep which matches the spectrogram timesteps
    label_matrix = pd.DataFrame(np.zeros((len(rownames), timesteps)),
                                index = rownames, columns = colnames)
    # make sure there is a noise row 
    label_matrix.loc[label_for_noise] = 1 
    
    # find the labels for the given spectrogram
    mask = (((label_table['Start']> start) & (label_table['End'] < stop))|
    ((label_table['End']> start) & (label_table['End'] < stop))|
    ((label_table['Start']> start) & (label_table['Start'] < stop)))
    mask = mask.index[mask==True]
    # probably not the most elegant, but should allow multiple calls per spectrogram
    for calli in mask: #loop over the calls that occur in that spectrogram and find their type
        call_name = (label_table.loc[calli,:] == True)
        call_name = call_name[call_name==True].index
        for calltypei in call_name: #loop through the different types and mark them as 1 and noise as 0 - this allows hybrids
            label_matrix.loc[label_for_noise,
                             ((colnames >= float(label_table['Start'][calli])) & 
                             (colnames <= float(label_table['End'][calli])))] = 0    
            label_matrix.loc[label_matrix.index == calltypei,
                                 ((colnames >= float(label_table['Start'][calli])) & 
                                 (colnames <= float(label_table['End'][calli])))] = 1

    '''
    # find rows where the sum is greater than 1 i.e. categorise fusion calls as "other"
    fusions = label_matrix.sum(0)>1
    label_matrix.loc[:,fusions == True] = 0
    label_matrix.loc[label_for_other,fusions == True] = 1
    '''
    
    return label_matrix


def create_call_nocall_matrix(label_table, spectro, start, stop, label_for_noise):
    '''
    This function creates a matrix where each row represents "call/not call" "over time where each bin corresponds 
    to a spectrogram. Typially the call label
    label_table:
        this is the output from create_table which outputs a pandas table with the following columns
            "Label" - a label for a particular call type e.g. "cc" for close call
            "Start" - start time in seconds of the call events
            "Duraion" - duration in seconds of the call events
            "End" - end time in seconds of the call events
            a sequence of labels defined from the call_types dictionary and containing only True and False
    spectro:
        spectrogram generated by create_spectrogram
    start:
        start time in seconds of the spectrogram (rolling window)
    stop:
        end time in seconds of the spectrogram (rolling window)
    label_for_noise:
        string used to label bakcground noise
    '''
    # categories = {
    timesteps = spectro.shape[1] # find number of columns for matrix
    colnames = np.arange(start=start, stop=stop, step=(stop-start)/timesteps)#np.linspace(start, stop, num=timesteps)#
    rownames = ['call', label_for_noise]#categories.keys()
    # timesteps_per_second = timesteps / spec_window_size 
    
    # create an empty matrix where each row represents a call type 
    # and each column represents a timestep which matches the spectrogram timesteps
    label_matrix = pd.DataFrame(np.zeros((len(rownames), timesteps)),
                                index = rownames, columns = colnames)
    # make sure there is a noise row 
    label_matrix.loc[label_for_noise] = 1 
    
    # find the rows in the label_table which are relevant for the given spectrogram
    label = (((label_table['Start']> start) & (label_table['End'] < stop))|
    ((label_table['End']> start) & (label_table['End'] < stop))|
    ((label_table['Start']> start) & (label_table['Start'] < stop)))      
    label = label.index[label==True]
    # for every row in the label table
    for row in label: #loop over the calls that occur in that spectrogram and find their type
        call_occ = (label_table.loc[row,:] == True)
        call_occ = call_occ[call_occ==True].index
        #for calltypei in call_occ: #loop through the different types and mark them as 1 and noise as 0 - this allows hybrids
        if call_occ!=label_for_noise:
            label_matrix.loc[label_for_noise,
                             ((colnames >= float(label_table['Start'][row])) & 
                             (colnames <= float(label_table['End'][row])))] = 0    
            label_matrix.loc[rownames[0],
                                 ((colnames >= float(label_table['Start'][row])) & 
                                 (colnames <= float(label_table['End'][row])))] = 1

    '''
    # find rows where the sum is greater than 1 i.e. categorise fusion calls as "other"
    fusions = label_matrix.sum(0)>1
    label_matrix.loc[:,fusions == True] = 0
    label_matrix.loc[label_for_other,fusions == True] = 1
    '''    
    return label_matrix


def augment_with_noise(spec_filepaths, noise_filepaths, wav_filepaths, calltype, scaling_factor, other_ignored_in_training,
                       random_range, spec_window_size, n_mels, window, fft_win, fft_hop, normalise,
                       save_label_table_path, call_types, label_for_other, label_for_noise):
    '''
    This function looks in the folder where the spectrograms are saved, 
    finds a random spectrogram of a specific call type, finds the matching wavfile with a bit of randomness
    find a random noise spectrogram and finds the matching wav with a bit of randomness
    and adds the noise to the call and saves a new spectrogram
    
    Input parameters:
        spec_filepaths: 
            list of strings - folder where all the spectrograms are stored
        noise_filepaths: 
            list of strings - folder where all the spectrograms are stored (can be the same as spec_filepaths or different if noise spectrograms aare storeed elsewhere)
        wav_filepaths:
            string - folder where all the wav files are stored
        calltype:
            string - call type to be augmented e.g. "cc" or "GRN"
        scaling_factor:
            float - might want to scale noise down if it is being added to a call, 
            e.g. scaling_factor = 1 for no scaling or scaling_factor = 0.3 so that noise is scaled to 30%
        other_ignored_in_training:
            True or False whether or not to include other in the training
        random_range:
            float - want to randomise the chunk of call being augmented so that it is not exactly the same as the originial spcetrogram
            e.g. the size of half if the spectrogram is recommended, so for meerkats this would be half of a second
        spec_window_size:
            float: spectrogram window size in seconds
        n_mels: 
            number of mel bands - suggested 64 or 128
        window: 
            spectrogram window generation type - suggested "hann"
        fft_win: 
            window length (in seconds)
        fft_hop: 
            hop between window starts (in seconds)
        normalise:
            true or false depending on whether we want to normalise accross the 
            mel bands to remove noise and get stronger signal
        save_label_table_path:
            location where label tables are stored
        call_types:
            a dictionary of call types and how they are labelled in the data - it is not case sensitive
        label_for_other:
            string which specifies which label any labels which do not fall into the call_types dectionary will be allocated to. 
            For instance, with meerkats, the 'chew' label might be relabelled as "oth". Normally this should be 
            in the call_types dictionary, but if not, this label will be created.
        label_for_noise:
            string used to label bakcground noise e.g. "noise"
    Output:
        augmented_data:
            an array containing the sum of call and the noise files
        augmented_spectrogram:
            a numpy array of a mel spectrogram of the augmented data
        augmented_label:
            a numpy array containing the labels
        aug_spec_filename: 
            filename for the augmented spectrogram (this way it tracks which file it came from and what the start and stop are)
        aug_mat_filename:
            filename for the augmented spectrogram (this way it tracks which file it came from and what the start and stop are)
        
        
    '''
  
    # randomly choose a spectrogram 
    call_spec = random.choice([x for x in spec_filepaths if calltype in x])#glob.glob(folder + "/*" + calltype +".npy")
    # keep only the file name
    call_spec = os.path.basename(call_spec) 
    # keep only the general name of the file so it can be linked to the corresponding .wav
    call_bits = re.split("_SPEC_", call_spec)
    file_ID = call_bits[0] 
    # find the wav
    call_wav_path = [s for s in wav_filepaths if file_ID in s][0]
    # find the corresponding labels
    call_label_table = file_ID + "_LABEL_TABLE.txt"
    label_table_path = os.path.join(save_label_table_path, call_label_table)
    label_table = pd.read_csv(label_table_path,  sep = ";")
    #save the label tables with other, but for the purpose of labelling, remove other
    if other_ignored_in_training:
        label_table = label_table[label_table[label_for_other] == False]
        label_table= label_table.reset_index(drop=True)
    #randomise the start a little so the new spectrogram will be a little different from the old
    call_start = round(float(float(re.split("s-", call_bits[1])[0]) + np.random.uniform(-random_range, random_range, 1)), 3)
    call_stop = round(call_start + spec_window_size,3 )
    #load the wave
    y, sr = librosa.load(call_wav_path, sr=None, mono=False)
    start_lab = int(round(sr * decimal.Decimal(call_start),3))
    stop_lab =  int(round(sr * decimal.Decimal(call_stop),3))
    #suset the wav
    data_subset = np.asfortranarray(y[start_lab:stop_lab])
    
    # randomly choose a noise file - same as above, only with noise
    noise_spec = random.choice([x for x in noise_filepaths if label_for_noise in x])#glob.glob(folder + "/*" + calltype +".npy")
    noise_spec = os.path.basename(noise_spec) 
    noise_bits = re.split("_SPEC_", noise_spec)
    noise_wav = noise_bits[0] #+".wav"
    noise_wav_path = [s for s in wav_filepaths if noise_wav in s][0]
    noise_start = round(float(float(re.split("s-", noise_bits[1])[0]) + np.random.uniform(-random_range, random_range, 1)), 3)
    noise_stop = round(noise_start + spec_window_size,3 )
    y, sr = librosa.load(noise_wav_path, sr=None, mono=False)
    start = int(round(sr * decimal.Decimal(noise_start),3))
    stop =  int(round(sr * decimal.Decimal(noise_stop),3))
    noise_subset = np.asfortranarray(y[start:stop])
    
    # combine the two
    augmented_data = data_subset + noise_subset * scaling_factor
    # generate spectrogram
    augmented_spectrogram = generate_mel_spectrogram(augmented_data, sr, 0, spec_window_size, 
                                                      n_mels, window, fft_win , fft_hop , normalise)
    # generate label
    augmented_label = create_label_matrix(label_table, augmented_spectrogram,
                                          call_types, call_start, call_stop, 
                                          label_for_noise)
    
    # find out what the label is for this given window so that later we can choose the label/test set in a balanced way
    file_label = list(augmented_label.index.values[augmented_label.where(augmented_label > 0).sum(1) > 1])
    if len(file_label) > 1 and label_for_noise in file_label:
        file_label.remove(label_for_noise)
    category = '_'.join(file_label)
            
    # Save these files
    aug_spec_filename = file_ID + "_SPEC_" + str(call_start) + "s-" + str(call_stop) + "s_NOISE_AUGMENTED_" + category + ".npy"
    aug_mat_filename = file_ID + "_MAT_" + str(call_start) + "s-" + str(call_stop) + "s_NOISE_AUGMENTED_" + category + ".npy"
        
    
    return augmented_data, augmented_spectrogram, augmented_label, aug_spec_filename, aug_mat_filename




def augment_with_pitch_shift(spec_filepaths, wav_filepaths, calltype,  n_steps, other_ignored_in_training,
                       random_range, spec_window_size, n_mels, window, fft_win, fft_hop, normalise,
                       save_label_table_path, call_types, label_for_other, label_for_noise):
    '''
    This function looks in the folder where the spectrograms are saved, 
    finds a random spectrogram of a specific call type, finds the matching wavfile with a bit of randomness
    and shifts the pitch
    
    Input parameters:
        spec_filepaths: 
            list of strings - folder where all the spectrograms are stored
        wav_filepaths:
            string - folder where all the wav files are stored
        calltype:
            string - call type to be augmented e.g. "cc" or "GRN"
        n_steps:
            how many (fractional) half-steps to shift y. parameter from librosa.effects.pitch_shift
        other_ignored_in_training:
            True or False whether or not to include other in the training
        random_range:
            float - want to randomise the chunk of call being augmented so that it is not exactly the same as the originial spcetrogram
            e.g. the size of half if the spectrogram is recommended, so for meerkats this would be half of a second
        spec_window_size:
            float: spectrogram window size in seconds
        n_mels: 
            number of mel bands - suggested 64 or 128
        window: 
            spectrogram window generation type - suggested "hann"
        fft_win: 
            window length (in seconds)
        fft_hop: 
            hop between window starts (in seconds)
        normalise:
            true or false depending on whether we want to normalise accross the 
            mel bands to remove noise and get stronger signal
        save_label_table_path:
            location where label tables are stored
        call_types:
            a dictionary of call types and how they are labelled in the data - it is not case sensitive
        label_for_other:
            string which specifies which label any labels which do not fall into the call_types dectionary will be allocated to. 
            For instance, with meerkats, the 'chew' label might be relabelled as "oth". Normally this should be 
            in the call_types dictionary, but if not, this label will be created.
        label_for_noise:
            string used to label bakcground noise
    Output:
        augmented_data:
            an array containing the sum of call and the noise files
        augmented_spectrogram:
            a numpy array of a mel spectrogram of the augmented data
        augmented_label:
            a numpy array containing the labels
        aug_spec_filename: 
            filename for the augmented spectrogram (this way it tracks which file it came from and what the start and stop are)
        aug_mat_filename:
            filename for the augmented spectrogram (this way it tracks which file it came from and what the start and stop are)
        
        
    '''
  
    # randomly choose a spectrogram 
    call_spec = random.choice([x for x in spec_filepaths if calltype in x])#glob.glob(folder + "/*" + calltype +".npy")
    # keep only the file name
    call_spec = os.path.basename(call_spec) 
    # keep only the general name of the file so it can be linked to the corresponding .wav
    call_bits = re.split("_SPEC_", call_spec)
    file_ID = call_bits[0] 
    # find the wav
    call_wav_path = [s for s in wav_filepaths if file_ID in s][0]
    # find the corresponding labels
    call_label_table = file_ID + "_LABEL_TABLE.txt"
    label_table_path = os.path.join(save_label_table_path, call_label_table)
    label_table = pd.read_csv(label_table_path,  sep = ";")
    #save the label tables with other, but for the purpose of labelling, remove other
    if other_ignored_in_training:
        label_table = label_table[label_table[label_for_other] == False]
        label_table= label_table.reset_index(drop=True)
    
    #randomise the start a little so the new spectrogram will be a little different from the old
    call_start = round(float(float(re.split("s-", call_bits[1])[0]) + np.random.uniform(-random_range, random_range, 1)), 3)
    call_stop = round(call_start + spec_window_size,3 )
    #load the wave
    y, sr = librosa.load(call_wav_path, sr=None, mono=False)
    start_lab = int(round(sr * decimal.Decimal(call_start),3))
    stop_lab =  int(round(sr * decimal.Decimal(call_stop),3))
    #suset the wav
    data_subset = np.asfortranarray(y[start_lab:stop_lab])
    
    
    # combine the two
    augmented_data =librosa.effects.pitch_shift(data_subset, sr, n_steps) #data_subset + noise_subset * scaling_factor
    # generate spectrogram
    augmented_spectrogram = generate_mel_spectrogram(augmented_data, sr, 0, spec_window_size, 
                                                      n_mels, window, fft_win , fft_hop , normalise)
    # generate label
    augmented_label = create_label_matrix(label_table, augmented_spectrogram,
                                          call_types, call_start, call_stop, 
                                          label_for_noise)
    
    # find out what the label is for this given window so that later we can choose the label/test set in a balanced way
    file_label = list(augmented_label.index.values[augmented_label.where(augmented_label > 0).sum(1) > 1])
    if len(file_label) > 1 and 'noise' in file_label:
        file_label.remove('noise')
    category = '_'.join(file_label)
            
    # Save these files
    aug_spec_filename = file_ID + "_SPEC_" + str(call_start) + "s-" + str(call_stop) + "s_PITCH_AUGMENTED_" + category + ".npy"
    aug_mat_filename = file_ID + "_MAT_" + str(call_start) + "s-" + str(call_stop) + "s_PITCH_AUGMENTED_" + category + ".npy"
    
    
    return augmented_data, augmented_spectrogram, augmented_label, aug_spec_filename, aug_mat_filename




def augment_with_time_stretch(spec_filepaths, wav_filepaths, calltype,  stretch_factor, other_ignored_in_training,
                       random_range, spec_window_size, n_mels, window, fft_win, fft_hop, normalise,
                       save_label_table_path, call_types, label_for_other, label_for_noise):
    '''
    This function looks in the folder where the spectrograms are saved, 
    finds a random spectrogram of a specific call type, finds the matching wavfile with a bit of randomness
    and stretches the audio on the time domain
    
    Input parameters:
        spec_filepaths: 
            list of strings - folder where all the spectrograms are stored
        wav_filepaths:
            string - folder where all the wav files are stored
        calltype:
            string - call type to be augmented e.g. "cc" or "GRN"
        stretch_factor
            Stretch factor. If rate > 1, then the signal is sped up. If rate < 1, then the signal is slowed down.
        other_ignored_in_training:
            True or False whether or not to include other in the training
        random_range:
            float - want to randomise the chunk of call being augmented so that it is not exactly the same as the originial spcetrogram
            e.g. the size of half if the spectrogram is recommended, so for meerkats this would be half of a second
        spec_window_size:
            float: spectrogram window size in seconds
        n_mels: 
            number of mel bands - suggested 64 or 128
        window: 
            spectrogram window generation type - suggested "hann"
        fft_win: 
            window length (in seconds)
        fft_hop: 
            hop between window starts (in seconds)
        normalise:
            true or false depending on whether we want to normalise accross the 
            mel bands to remove noise and get stronger signal
        save_label_table_path:
            location where label tables are stored
        call_types:
            a dictionary of call types and how they are labelled in the data - it is not case sensitive
        label_for_other:
            string which specifies which label any labels which do not fall into the call_types dectionary will be allocated to. 
            For instance, with meerkats, the 'chew' label might be relabelled as "oth". Normally this should be 
            in the call_types dictionary, but if not, this label will be created.
        label_for_noise:
            string used to label bakcground noise
    Output:
        augmented_data:
            an array containing the sum of call and the noise files
        augmented_spectrogram:
            a numpy array of a mel spectrogram of the augmented data
        augmented_label:
            a numpy array containing the labels
        aug_spec_filename: 
            filename for the augmented spectrogram (this way it tracks which file it came from and what the start and stop are)
        aug_mat_filename:
            filename for the augmented spectrogram (this way it tracks which file it came from and what the start and stop are)
        
        
    '''
  
    # randomly choose a spectrogram 
    call_spec = random.choice([x for x in spec_filepaths if calltype in x])#glob.glob(folder + "/*" + calltype +".npy")
    # keep only the file name
    call_spec = os.path.basename(call_spec) 
    # keep only the general name of the file so it can be linked to the corresponding .wav
    call_bits = re.split("_SPEC_", call_spec)
    file_ID = call_bits[0] 
    # find the wav
    call_wav_path = [s for s in wav_filepaths if file_ID in s][0]
    # find the corresponding labels
    call_label_table = file_ID + "_LABEL_TABLE.txt"
    label_table_path = os.path.join(save_label_table_path, call_label_table)
    label_table = pd.read_csv(label_table_path,  sep = ";")
    #save the label tables with other, but for the purpose of labelling, remove other
    if other_ignored_in_training:
        label_table = label_table[label_table[label_for_other] == False]
        label_table= label_table.reset_index(drop=True)
    #randomise the start a little so the new spectrogram will be a little different from the old
    call_start = round(float(float(re.split("s-", call_bits[1])[0]) + np.random.uniform(-random_range, random_range, 1)), 3)
    call_stop = round(call_start + spec_window_size,3 )
    #load the wave
    y, sr = librosa.load(call_wav_path, sr=None, mono=False)
    start_lab = int(round(sr * decimal.Decimal(call_start),3))
    stop_lab =  int(round(sr * decimal.Decimal(call_stop),3))
    #suset the wav
    data_subset = np.asfortranarray(y[start_lab:stop_lab])
    
    
    # combine the two
    augmented_data =librosa.effects.time_stretch(data_subset, stretch_factor) #datra_subset + noise_subset * scaling_factor
    # generate spectrogram
    augmented_spectrogram = generate_mel_spectrogram(augmented_data, sr, 0, spec_window_size, 
                                                      n_mels, window, fft_win , fft_hop , normalise)
    # generate label
    augmented_label = create_label_matrix(label_table, augmented_spectrogram,
                                          call_types, call_start, call_stop, 
                                          label_for_noise)
    
    # find out what the label is for this given window so that later we can choose the label/test set in a balanced way
    file_label = list(augmented_label.index.values[augmented_label.where(augmented_label > 0).sum(1) > 1])
    if len(file_label) > 1 and 'noise' in file_label:
        file_label.remove('noise')
    category = '_'.join(file_label)
            
    # Save these files
    aug_spec_filename = file_ID + "_SPEC_" + str(call_start) + "s-" + str(call_stop) + "s_TIMESTRETCH_AUGMENTED_" + category + ".npy"
    aug_mat_filename = file_ID + "_MAT_" + str(call_start) + "s-" + str(call_stop) + "s_TIMESTRETCH_AUGMENTED_" + category + ".npy"
    
    
    return augmented_data, augmented_spectrogram, augmented_label, aug_spec_filename, aug_mat_filename
