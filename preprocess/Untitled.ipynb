{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# I ran this after running your code up to the \"SPLIT DATA INTO TRAINING/VALIDATION AND TEST SETS\" part. IT should run once the user loads validation_label_table\n",
    "\n",
    "# how many calls of each type are in the validation label table:\n",
    "\n",
    "call_dico = {'cc':0,'sn':0,'mo':0,'agg':0,'ld':0,'soc':0,'al':0,'beep':0,'synch':0,'oth':0,'noise':0}\n",
    "for i in validation_label_table.index.tolist():\n",
    "    if validation_label_table.at[i,'cc']:\n",
    "        call_dico['cc']+=1\n",
    "    elif validation_label_table.at[i,'sn']:\n",
    "        call_dico['sn']+=1\n",
    "    elif validation_label_table.at[i,'mo']:\n",
    "        call_dico['mo']+=1\n",
    "    elif validation_label_table.at[i,'agg']:\n",
    "        call_dico['agg']+=1\n",
    "    elif validation_label_table.at[i,'ld']:\n",
    "        call_dico['ld']+=1\n",
    "    elif validation_label_table.at[i,'soc']:\n",
    "        call_dico['soc']+=1\n",
    "    elif validation_label_table.at[i,'al']:\n",
    "        call_dico['al']+=1\n",
    "    elif validation_label_table.at[i,'beep']:\n",
    "        call_dico['beep']+=1\n",
    "    elif validation_label_table.at[i,'synch']:\n",
    "        call_dico['synch']+=1\n",
    "    elif validation_label_table.at[i,'oth']:\n",
    "        call_dico['oth']+=1\n",
    "    elif validation_label_table.at[i,'noise']:\n",
    "        call_dico['noise']+=1\n",
    "print(call_dico)\n",
    "\n",
    "# {'cc': 5237, 'sn': 3498, 'mo': 172, 'agg': 498, 'ld': 26, 'soc': 1745, 'al': 258, 'beep': 70, 'synch': 732, 'oth': 1988, 'noise': 79}\n",
    "\n",
    "\n",
    "# What are the skipon/skipoff/et. and where are they located?\n",
    "noise_idx = []\n",
    "for i in validation_label_table.index.tolist():\n",
    "    if validation_label_table.at[i,'noise']:\n",
    "        noise_idx.append((i, validation_label_table.at[i, 'Label']))\n",
    "print(noise_idx)\n",
    "\n",
    "# [(840, 'start'), (1170, 'stop'), (2200, 'start'), (2890, 'stop'), (5169, 'start'), (5369, 'stop'), (6189, 'start'), (6479, 'stop'), (6486, 'start'), (6949, 'stop'), (20295, 'start'), (20382, 'stop'), (27671, 'start'), (28013, 'stop'), (29857, 'start'), (30841, 'stop'), (34457, 'start'), (34799, 'stop'), (35078, 'start'), (35933, 'stop'), (36578, 'start'), (36661, 'skipon (soc interaction, mostly nf)'), (36665, 'skipoff'), (37054, 'stop'), (41644, 'start'), (41934, 'stop'), (43846, 'start'), (44128, 'skipon (seriesn of non-meerkat and some nf calls)'), (44134, 'skipoff'), (44469, 'stop'), (48417, 'start'), (49141, 'stop'), (55299, 'start'), (55654, 'stop'), (58241, 'start'), (58593, 'stop'), (61118, 'start'), (61568, 'skipon'), (61569, 'skipoff'), (61810, 'skipon'), (61811, 'skipoff'), (61839, 'skipon'), (61840, 'skipoff'), (61877, 'stop'), (68505, 'start'), (68818, 'skipon (brief soc interaction, fully nf)'), (68819, 'skipoff'), (69013, 'skipon'), (69016, 'skipoff'), (69113, 'stop'), (69441, 'start'), (69980, 'stop'), (71435, 'start'), (71872, 'stop'), (75361, 'start'), (75744, 'stop'), (77222, 'start'), (77630, 'skipon'), (77637, 'skipoff'), (78137, 'stop'), (78138, 'start'), (78257, 'stop'), (78258, 'start'), (78661, 'stop'), (80132, 'start'), (80882, 'stop'), (82964, 'start'), (83173, 'stop'), (83589, 'start'), (84334, 'skipon'), (84335, 'skipoff'), (84716, 'stop'), (85374, 'start'), (85597, 'skipon (short seriesn of soc nf calls)'), (85598, 'skipoff'), (85706, 'skipon (short seriesn of an unk call)'), (85707, 'skipoff'), (85712, 'skipon (short seriesn of very distant nf calls, possibly s nf)'), (85713, 'skipoff'), (85750, 'stop'), (88258, 'start'), (88461, 'stop')]\n",
    "\n",
    "# very few calls are removed by the skipon/skipoff in those files.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#The previous steps were done based on a random sample of files selected as the validation set, which yields similar results, but for the sake of testablity, I'm going to continue with the canoncial data set. \n",
    "#Let's check the label tables that are saved on the hard drive at /media/mathieu/Elements/data/MEERKAT_OUTPUT/models/EXAMPLE_NoiseAugmented_0.3_0.8_NotWeighted_MaskedOther_Forked/test_data/label_table\n",
    "table_dir = '/media/mathieu/Elements/code/KiranLDA/results/EXAMPLE_NoiseAugmented_0.3_0.8_NotWeighted_MaskedOther_Forked/new_run/label_table'\n",
    "label_tables_list = glob.glob(os.path.join(table_dir, \"*.txt\"))\n",
    "label_tables_list.sort()\n",
    "\n",
    "new_dico = {'cc':0,'sn':0,'mo':0,'agg':0,'ld':0,'soc':0,'al':0,'beep':0,'synch':0,'oth':0,'noise':0}\n",
    "for f in range(len(label_tables_list)):\n",
    "    table = pd.read_csv(label_tables_list[f], delimiter = \";\")\n",
    "    for i in table.index.tolist():\n",
    "        if table.at[i,'cc']:\n",
    "            new_dico['cc']+=1\n",
    "        elif table.at[i,'sn']:\n",
    "            new_dico['sn']+=1\n",
    "        elif table.at[i,'mo']:\n",
    "            new_dico['mo']+=1\n",
    "        elif table.at[i,'agg']:\n",
    "            new_dico['agg']+=1\n",
    "        elif table.at[i,'ld']:\n",
    "            new_dico['ld']+=1\n",
    "        elif table.at[i,'soc']:\n",
    "            new_dico['soc']+=1\n",
    "        elif table.at[i,'al']:\n",
    "            new_dico['al']+=1\n",
    "        elif table.at[i,'beep']:\n",
    "            new_dico['beep']+=1\n",
    "        elif table.at[i,'synch']:\n",
    "            new_dico['synch']+=1\n",
    "        elif table.at[i,'oth']:\n",
    "            new_dico['oth']+=1\n",
    "        elif table.at[i,'noise']:\n",
    "            new_dico['noise']+=1\n",
    "print(new_dico)\n",
    "    \n",
    "# {'cc': 5518, 'sn': 3255, 'mo': 168, 'agg': 299, 'ld': 31, 'soc': 1546, 'al': 83, 'beep': 100, 'synch': 824, 'oth': 1764, 'noise': 87}    \n",
    "    \n",
    "# What are the skipon/skipoff/et. for these files and where are they located?\n",
    "noise_idx = []\n",
    "for i in validation_label_table.index.tolist():\n",
    "    if validation_label_table.at[i,'noise']:\n",
    "        noise_idx.append((i, validation_label_table.at[i, 'Label']))\n",
    "print(noise_idx)\n",
    "\n",
    "# [(840, 'start'), (1170, 'stop'), (2200, 'start'), (2890, 'stop'), (5169, 'start'), (5369, 'stop'), (6189, 'start'), (6479, 'stop'), (6486, 'start'), (6949, 'stop'), (20295, 'start'), (20382, 'stop'), (27671, 'start'), (28013, 'stop'), (29857, 'start'), (30841, 'stop'), (34457, 'start'), (34799, 'stop'), (35078, 'start'), (35933, 'stop'), (36578, 'start'), (36661, 'skipon (soc interaction, mostly nf)'), (36665, 'skipoff'), (37054, 'stop'), (41644, 'start'), (41934, 'stop'), (43846, 'start'), (44128, 'skipon (seriesn of non-meerkat and some nf calls)'), (44134, 'skipoff'), (44469, 'stop'), (48417, 'start'), (49141, 'stop'), (55299, 'start'), (55654, 'stop'), (58241, 'start'), (58593, 'stop'), (61118, 'start'), (61568, 'skipon'), (61569, 'skipoff'), (61810, 'skipon'), (61811, 'skipoff'), (61839, 'skipon'), (61840, 'skipoff'), (61877, 'stop'), (68505, 'start'), (68818, 'skipon (brief soc interaction, fully nf)'), (68819, 'skipoff'), (69013, 'skipon'), (69016, 'skipoff'), (69113, 'stop'), (69441, 'start'), (69980, 'stop'), (71435, 'start'), (71872, 'stop'), (75361, 'start'), (75744, 'stop'), (77222, 'start'), (77630, 'skipon'), (77637, 'skipoff'), (78137, 'stop'), (78138, 'start'), (78257, 'stop'), (78258, 'start'), (78661, 'stop'), (80132, 'start'), (80882, 'stop'), (82964, 'start'), (83173, 'stop'), (83589, 'start'), (84334, 'skipon'), (84335, 'skipoff'), (84716, 'stop'), (85374, 'start'), (85597, 'skipon (short seriesn of soc nf calls)'), (85598, 'skipoff'), (85706, 'skipon (short seriesn of an unk call)'), (85707, 'skipoff'), (85712, 'skipon (short seriesn of very distant nf calls, possibly s nf)'), (85713, 'skipoff'), (85750, 'stop'), (88258, 'start'), (88461, 'stop')]\n",
    "\n",
    "\n",
    "# Next let's check the label tables obtained from the evaluation  metrics\n",
    "main_dir = '/media/mathieu/Elements/code/KiranLDA/results/EXAMPLE_NoiseAugmented_0.3_0.8_NotWeighted_MaskedOther_Forked/new_run/metrics/call_type_by_call_type/0/'\n",
    "# low_thresh = 0.1, high_threh = 0.3:\n",
    "thr_dir = os.path.join(main_dir, str(0.1), str(0.3))\n",
    "GT_table_address = os.path.join(thr_dir,'_Ground truth.p')\n",
    "gt_indices = pd.read_pickle(GT_table_address)\n",
    "\n",
    "new_dico = {'cc':0,'sn':0,'mo':0,'agg':0,'ld':0,'soc':0,'al':0,'beep':0,'synch':0,'oth':0,'noise':0}\n",
    "for f in gt_indices.index.tolist():\n",
    "    for call in gt_indices.columns.tolist():\n",
    "        new_dico[call] +=  len(gt_indices.at[f,call])\n",
    "print(new_dico)\n",
    "# {'cc': 5518, 'sn': 3240, 'mo': 168, 'agg': 299, 'ld': 31, 'soc': 1530, 'al': 83, 'beep': 99, 'synch': 799, 'oth': 1752, 'noise': 81}\n",
    "\n",
    "# finally, what do the confusion matrices look like?\n",
    "cm_address = os.path.join(thr_dir,'_Confusion matrix.csv')\n",
    "cm = pd.read_csv(cm_address, delimiter=',', index_col=0)\n",
    "cm_dico = {'cc':0,'sn':0,'mo':0,'agg':0,'ld':0,'soc':0,'al':0,'beep':0,'synch':0,'oth':0,'noise':0}\n",
    "for call in cm.index.tolist():\n",
    "    for pred in cm.columns.tolist():\n",
    "        cm_dico[call] +=  cm.at[call,pred]\n",
    "print(cm_dico)\n",
    "# {'cc': 6107, 'sn': 3457, 'mo': 181, 'agg': 303, 'ld': 32, 'soc': 1729, 'al': 90, 'beep': 102, 'synch': 863, 'oth': 2322, 'noise': 48553}\n",
    "\n",
    "# same thing for low_thresh = 0.3, high_threh = 0.95:\n",
    "thr_dir = os.path.join(main_dir, str(0.3), str(0.95))\n",
    "GT_table_address = os.path.join(thr_dir,'_Ground truth.p')\n",
    "gt_indices = pd.read_pickle(GT_table_address)\n",
    "\n",
    "new_dico = {'cc':0,'sn':0,'mo':0,'agg':0,'ld':0,'soc':0,'al':0,'beep':0,'synch':0,'oth':0,'noise':0}\n",
    "for f in gt_indices.index.tolist():\n",
    "    for call in gt_indices.columns.tolist():\n",
    "        new_dico[call] +=  len(gt_indices.at[f,call])\n",
    "print(new_dico)\n",
    "# {'cc': 5518, 'sn': 3240, 'mo': 168, 'agg': 299, 'ld': 31, 'soc': 1530, 'al': 83, 'beep': 99, 'synch': 799, 'oth': 1752, 'noise': 81}\n",
    "cm_address = os.path.join(thr_dir,'_Confusion matrix.csv')\n",
    "cm = pd.read_csv(cm_address, delimiter=',', index_col=0)\n",
    "cm_dico = {'cc':0,'sn':0,'mo':0,'agg':0,'ld':0,'soc':0,'al':0,'beep':0,'synch':0,'oth':0,'noise':0}\n",
    "for call in cm.index.tolist():\n",
    "    for pred in cm.columns.tolist():\n",
    "        cm_dico[call] +=  cm.at[call,pred]\n",
    "print(cm_dico)\n",
    "# {'cc': 6107, 'sn': 3457, 'mo': 181, 'agg': 303, 'ld': 32, 'soc': 1729, 'al': 90, 'beep': 102, 'synch': 863, 'oth': 2322, 'noise': 48553}\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
