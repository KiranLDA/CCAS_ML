{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENSITIVITY ANALYSES\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kiran/Documents/github/CCAS_ML/postprocess/evaluation_metrics_functions_old.py:10: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/Documents/github/CCAS_ML/postprocess/evaluation_metrics_functions_old.py:12: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "github_dir = \"/home/kiran/Documents/github/CCAS_ML\"\n",
    "\n",
    "# add path to local functions\n",
    "import os\n",
    "os.chdir(github_dir)\n",
    "\n",
    "# import all the params for this model\n",
    "from example_params import *\n",
    "is_forked = True # is going to need to go into the params file\n",
    "\n",
    "# import own functions\n",
    "import preprocess.preprocess_functions as pre\n",
    "import postprocess.evaluation_metrics_functions_old as metrics\n",
    "import postprocess.merge_predictions_functions as ppm\n",
    "import model.specgen_batch_generator as bg\n",
    "import model.network_class as rnn\n",
    "# import postprocess.visualise_prediction_functions as pp\n",
    "from model.callback_functions import LossHistory\n",
    "import model.audiopool as audiopool\n",
    "\n",
    "# import normal packages used in pre-processing\n",
    "import numpy as np\n",
    "import librosa\n",
    "import warnings\n",
    "import ntpath\n",
    "import os\n",
    "from itertools import compress  \n",
    "from random import random, shuffle\n",
    "from math import floor\n",
    "import statistics\n",
    "import glob\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML section packages\n",
    "import datetime\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, SeparableConv2D, concatenate\n",
    "from keras.layers import Reshape, Permute\n",
    "from keras.layers import TimeDistributed, Dense, Dropout, BatchNormalization\n",
    "from keras.models import load_model\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# postprocessfrom decimal import Decimal\n",
    "from decimal import Decimal\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# evaluate and plot \n",
    "import seaborn as sn\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------\n",
    "# PREPROCESSING / DATA WRANGLING\n",
    "\n",
    "Currently, all the meerkat files are found on the server. The labels in particular are divided by year (currently 2017 and 2019) and all file labels are in a single document. This bit of code just takes these and puts them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all the synched label files together\n",
    "labels_all = pd.DataFrame()\n",
    "for directory in label_dirs:\n",
    "    for group in group_IDs:\n",
    "        temp = pd.read_csv(os.path.join(directory, group +\"_ALL_CALLS_SYNCHED.csv\"), sep=sep,\n",
    "                       header=0, engine = engine, encoding = encoding) \n",
    "        temp[\"group\"] = group\n",
    "        labels_all = pd.concat([labels_all, temp]) \n",
    "        del temp\n",
    "\n",
    "labels_all = labels_all[-labels_all.wavFileName.str.contains('SOUNDFOC')]\n",
    "labels_all = labels_all.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data also contain focal follows (someone walking around behind the meerkats) and the resultion of this data is different and therefore not anlysed with the collar data (but could be done separately or put to the same resolution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset all the audio files that we should use in the analysis (i.e. not focal follow data)\n",
    "audio_files = list(set(labels_all[\"wavFileName\"]))\n",
    "audio_filenames = list(compress(audio_files, [\"SOUNDFOC\" not in filei for filei in audio_files]))\n",
    "\n",
    "# subset all the audio files that we should use in the analysis (i.e. not focal follow data)\n",
    "label_files = list(set(labels_all[\"csvFileName\"]))\n",
    "label_filenames = list(compress(label_files, [\"SOUNDFOC\" not in filei for filei in label_files]))\n",
    "\n",
    "# get the file IDS without all the extentions (used later for naming)\n",
    "all_filenames = [audio_filenames[i].split(\".\")[0] for i in range(0,len(audio_filenames))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we locate all the paths to the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the labels\n",
    "EXT = \"*.csv\"\n",
    "label_filepaths = []\n",
    "for PATH in acoustic_data_path :\n",
    "      label_filepaths.extend( [file for path, subdir, files in os.walk(PATH) for file in glob.glob(os.path.join(path, EXT))])\n",
    "EXT = \"*.CSV\"\n",
    "for PATH in acoustic_data_path :\n",
    "      label_filepaths.extend( [file for path, subdir, files in os.walk(PATH) for file in glob.glob(os.path.join(path, EXT))])\n",
    "\n",
    "# find all audio paths (will be longer than label path as not everything is labelled)\n",
    "audio_filepaths = []\n",
    "EXT = \"*.wav\"\n",
    "for PATH in audio_dirs:\n",
    "      audio_filepaths.extend( [file for path, subdir, files in os.walk(PATH) for file in glob.glob(os.path.join(path, EXT))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a label table\n",
    "\n",
    "Currently, the labels are stored in a file generated by audition for the meerkats. We want to these manual labels and put them into a more meaningful categories for for the machine learning. To set categories, I use a pre-defined dictionary called call_types that is defined in the parameters file and which specifies what the different classes are for the call types. Anything strange gets put into a category \"oth\" for other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This label 'c' on line 5909 will be classed as 'oth'\n",
      "This label 'c' on line 7266 will be classed as 'oth'\n",
      "This label 'cn' on line 7921 will be classed as 'oth'\n",
      "This label 'chew' on line 8385 will be classed as 'oth'\n",
      "This label 'sb' on line 8504 will be classed as 'oth'\n",
      "This label 'chew' on line 8782 will be classed as 'oth'\n",
      "This label 'chew' on line 8862 will be classed as 'oth'\n",
      "This label 'chew' on line 8886 will be classed as 'oth'\n",
      "This label 'chew' on line 8887 will be classed as 'oth'\n",
      "This label 'chew' on line 8890 will be classed as 'oth'\n",
      "This label 'chew' on line 8914 will be classed as 'oth'\n",
      "This label 'chew' on line 8933 will be classed as 'oth'\n",
      "This label 'chew' on line 8962 will be classed as 'oth'\n",
      "This label 'chew' on line 9008 will be classed as 'oth'\n",
      "This label 'chew' on line 9011 will be classed as 'oth'\n",
      "This label 'chew' on line 9045 will be classed as 'oth'\n",
      "This label 'chew' on line 9046 will be classed as 'oth'\n",
      "This label 'chew' on line 9243 will be classed as 'oth'\n",
      "This label 'chew' on line 9249 will be classed as 'oth'\n",
      "This label 'chew' on line 9268 will be classed as 'oth'\n",
      "This label 'chew' on line 9697 will be classed as 'oth'\n",
      "This label 'chew' on line 9842 will be classed as 'oth'\n",
      "This label 'chew' on line 9861 will be classed as 'oth'\n",
      "This label 'chew' on line 10115 will be classed as 'oth'\n",
      "This label 'chew' on line 10139 will be classed as 'oth'\n",
      "This label 'chew' on line 10141 will be classed as 'oth'\n",
      "This label '01:48:00' on line 11666 will be classed as 'oth'\n",
      "This label 'c' on line 13384 will be classed as 'oth'\n",
      "This label 'nan' on line 13961 will be classed as 'oth'\n",
      "This label 'sx' on line 18196 will be classed as 'oth'\n",
      "This label 'pause' on line 18848 will be classed as 'oth'\n",
      "This label 'sc f' on line 19787 will be classed as 'oth'\n",
      "This label 'eating' on line 20297 will be classed as 'oth'\n",
      "This label 'eating' on line 20298 will be classed as 'oth'\n",
      "This label 'eating' on line 20312 will be classed as 'oth'\n",
      "This label 'eating' on line 20330 will be classed as 'oth'\n",
      "This label 'x' on line 20426 will be classed as 'oth'\n",
      "This label 'x' on line 20509 will be classed as 'oth'\n",
      "This label 'x' on line 21496 will be classed as 'oth'\n",
      "This label 'eating' on line 21500 will be classed as 'oth'\n",
      "This label 'eating' on line 21507 will be classed as 'oth'\n",
      "This label 'x' on line 21510 will be classed as 'oth'\n",
      "This label 'x' on line 21541 will be classed as 'oth'\n",
      "This label 'c nf' on line 22004 will be classed as 'oth'\n",
      "This label 'x' on line 22292 will be classed as 'oth'\n",
      "This label 'x' on line 22294 will be classed as 'oth'\n",
      "This label 'x' on line 22297 will be classed as 'oth'\n",
      "This label 'x' on line 22311 will be classed as 'oth'\n",
      "This label 'x nf' on line 22318 will be classed as 'oth'\n",
      "This label 'x' on line 22323 will be classed as 'oth'\n",
      "This label 'x' on line 22331 will be classed as 'oth'\n",
      "This label 'x nf' on line 22340 will be classed as 'oth'\n",
      "This label 'x nf' on line 22356 will be classed as 'oth'\n",
      "This label 'x' on line 22362 will be classed as 'oth'\n",
      "This label 'x' on line 22381 will be classed as 'oth'\n",
      "This label 'x nf' on line 22385 will be classed as 'oth'\n",
      "This label 'x nf' on line 22405 will be classed as 'oth'\n",
      "This label 'x nf' on line 22436 will be classed as 'oth'\n",
      "This label 'x' on line 22438 will be classed as 'oth'\n",
      "This label 'x nf' on line 22445 will be classed as 'oth'\n",
      "This label 'x nf' on line 22448 will be classed as 'oth'\n",
      "This label '01:25:30' on line 22510 will be classed as 'oth'\n",
      "This label 'na' on line 23324 will be classed as 'oth'\n",
      "This label 'na' on line 23331 will be classed as 'oth'\n",
      "This label 'na' on line 23344 will be classed as 'oth'\n",
      "This label 'na' on line 23353 will be classed as 'oth'\n",
      "This label 'na' on line 23551 will be classed as 'oth'\n",
      "This label 'na' on line 23553 will be classed as 'oth'\n",
      "This label 'na' on line 23561 will be classed as 'oth'\n",
      "This label 'na' on line 23626 will be classed as 'oth'\n",
      "This label 'na' on line 23632 will be classed as 'oth'\n",
      "This label 'na' on line 23674 will be classed as 'oth'\n",
      "This label 'na' on line 23755 will be classed as 'oth'\n",
      "This label 'na' on line 23821 will be classed as 'oth'\n",
      "This label 'na' on line 23856 will be classed as 'oth'\n",
      "This label 'na' on line 23877 will be classed as 'oth'\n",
      "This label 'x' on line 24344 will be classed as 'oth'\n",
      "This label 'x' on line 24386 will be classed as 'oth'\n",
      "This label 'x' on line 24664 will be classed as 'oth'\n",
      "This label 'x' on line 24693 will be classed as 'oth'\n",
      "This label 'x' on line 24709 will be classed as 'oth'\n",
      "This label 'x' on line 24710 will be classed as 'oth'\n",
      "This label 'x' on line 24712 will be classed as 'oth'\n",
      "This label 'x' on line 24754 will be classed as 'oth'\n",
      "This label 'x' on line 24770 will be classed as 'oth'\n",
      "This label 'x' on line 24771 will be classed as 'oth'\n",
      "This label 'x' on line 24813 will be classed as 'oth'\n",
      "This label 'x' on line 24840 will be classed as 'oth'\n",
      "This label 'x' on line 24841 will be classed as 'oth'\n",
      "This label 'x' on line 24842 will be classed as 'oth'\n",
      "This label 'x' on line 24907 will be classed as 'oth'\n",
      "This label 'x' on line 24908 will be classed as 'oth'\n",
      "This label 'x' on line 27182 will be classed as 'oth'\n",
      "This label 'x' on line 27396 will be classed as 'oth'\n",
      "This label 'x' on line 27457 will be classed as 'oth'\n",
      "This label 'x' on line 27568 will be classed as 'oth'\n",
      "This label 'x' on line 27580 will be classed as 'oth'\n",
      "This label 'x' on line 29274 will be classed as 'oth'\n",
      "This label 'x' on line 29531 will be classed as 'oth'\n",
      "This label 'x' on line 29688 will be classed as 'oth'\n",
      "This label 'x' on line 29690 will be classed as 'oth'\n",
      "This label 'c nf' on line 29839 will be classed as 'oth'\n",
      "This label 'x' on line 30166 will be classed as 'oth'\n",
      "This label 's%' on line 32036 will be classed as 'oth'\n",
      "This label 'chuck' on line 32167 will be classed as 'oth'\n",
      "This label 'x' on line 32340 will be classed as 'oth'\n",
      "This label 'x' on line 32407 will be classed as 'oth'\n",
      "This label 'synh 01:30:00' on line 32910 will be classed as 'oth'\n",
      "This label 'sych 01:51:00' on line 33314 will be classed as 'oth'\n",
      "This label 'x' on line 34057 will be classed as 'oth'\n",
      "This label 'digging' on line 34282 will be classed as 'oth'\n",
      "This label 'digging' on line 34285 will be classed as 'oth'\n",
      "This label 'chew' on line 34373 will be classed as 'oth'\n",
      "This label 'chew' on line 34374 will be classed as 'oth'\n",
      "This label 'chew' on line 34375 will be classed as 'oth'\n",
      "This label 'x' on line 34592 will be classed as 'oth'\n",
      "This label 'x' on line 34622 will be classed as 'oth'\n",
      "This label 'x' on line 34665 will be classed as 'oth'\n",
      "This label 'x' on line 34753 will be classed as 'oth'\n",
      "This label 'x' on line 34836 will be classed as 'oth'\n",
      "This label 'x' on line 34951 will be classed as 'oth'\n",
      "This label '//' on line 35075 will be classed as 'oth'\n",
      "This label 'x' on line 36573 will be classed as 'oth'\n",
      "This label 'x' on line 37322 will be classed as 'oth'\n",
      "This label 'x' on line 38818 will be classed as 'oth'\n",
      "This label 'sycnh 01:54:00' on line 40080 will be classed as 'oth'\n",
      "This label 'aynxh 01:28:30' on line 40931 will be classed as 'oth'\n",
      "This label 'x' on line 41786 will be classed as 'oth'\n",
      "This label 'x' on line 44978 will be classed as 'oth'\n",
      "This label 'x' on line 45052 will be classed as 'oth'\n",
      "This label 'x' on line 45095 will be classed as 'oth'\n",
      "This label 'x' on line 45109 will be classed as 'oth'\n",
      "This label 'x' on line 45135 will be classed as 'oth'\n",
      "This label 'x' on line 45474 will be classed as 'oth'\n",
      "This label 'x' on line 45758 will be classed as 'oth'\n",
      "This label 'x' on line 46865 will be classed as 'oth'\n",
      "This label 'x' on line 47160 will be classed as 'oth'\n",
      "This label 'x' on line 47324 will be classed as 'oth'\n",
      "This label 'x' on line 48199 will be classed as 'oth'\n",
      "This label 'ññ' on line 48424 will be classed as 'oth'\n",
      "This label 'ññ x' on line 48490 will be classed as 'oth'\n",
      "This label '××' on line 48615 will be classed as 'oth'\n",
      "This label 'x' on line 49340 will be classed as 'oth'\n",
      "This label 'x' on line 49664 will be classed as 'oth'\n",
      "This label 'x' on line 49745 will be classed as 'oth'\n",
      "This label 'x' on line 49887 will be classed as 'oth'\n",
      "This label 'x' on line 49888 will be classed as 'oth'\n",
      "This label 'x' on line 49889 will be classed as 'oth'\n",
      "This label 'x' on line 49890 will be classed as 'oth'\n",
      "This label 'x' on line 49891 will be classed as 'oth'\n",
      "This label 'x' on line 50849 will be classed as 'oth'\n",
      "This label 'x' on line 52248 will be classed as 'oth'\n",
      "This label 'x' on line 52382 will be classed as 'oth'\n",
      "This label 'x' on line 52419 will be classed as 'oth'\n",
      "This label 'eating' on line 52620 will be classed as 'oth'\n",
      "This label 'x' on line 52896 will be classed as 'oth'\n",
      "This label 'x' on line 52984 will be classed as 'oth'\n",
      "This label 'x' on line 53082 will be classed as 'oth'\n",
      "This label 'x' on line 55858 will be classed as 'oth'\n",
      "This label 'x' on line 56061 will be classed as 'oth'\n",
      "This label 'x' on line 56162 will be classed as 'oth'\n",
      "This label 'eating' on line 56190 will be classed as 'oth'\n",
      "This label 'x' on line 56385 will be classed as 'oth'\n",
      "This label 'x' on line 57233 will be classed as 'oth'\n",
      "This label 'x' on line 57814 will be classed as 'oth'\n",
      "This label 'x' on line 57886 will be classed as 'oth'\n",
      "This label 'x' on line 58020 will be classed as 'oth'\n",
      "This label 'm nf' on line 58263 will be classed as 'oth'\n",
      "This label 'x' on line 58372 will be classed as 'oth'\n",
      "This label 'sc x nf' on line 58510 will be classed as 'oth'\n",
      "This label 'x' on line 58736 will be classed as 'oth'\n",
      "This label 'x' on line 58812 will be classed as 'oth'\n",
      "This label 'x' on line 59226 will be classed as 'oth'\n",
      "This label 'x' on line 59634 will be classed as 'oth'\n",
      "This label 'x' on line 59762 will be classed as 'oth'\n",
      "This label 'x' on line 59879 will be classed as 'oth'\n",
      "This label 'x' on line 60509 will be classed as 'oth'\n",
      "This label 'x' on line 60626 will be classed as 'oth'\n",
      "This label 'x' on line 62005 will be classed as 'oth'\n",
      "This label 'x' on line 62584 will be classed as 'oth'\n",
      "This label 'x' on line 62686 will be classed as 'oth'\n",
      "This label 'x' on line 64059 will be classed as 'oth'\n",
      "This label 'x' on line 64060 will be classed as 'oth'\n",
      "This label 'x' on line 64510 will be classed as 'oth'\n",
      "This label 'x' on line 66199 will be classed as 'oth'\n",
      "This label 'x' on line 67409 will be classed as 'oth'\n",
      "This label 'eating' on line 67465 will be classed as 'oth'\n",
      "This label 'eating' on line 67469 will be classed as 'oth'\n",
      "This label 'eating' on line 67571 will be classed as 'oth'\n",
      "This label 'x' on line 67768 will be classed as 'oth'\n",
      "This label 'eating' on line 67786 will be classed as 'oth'\n",
      "This label 'x' on line 69049 will be classed as 'oth'\n",
      "This label 'x' on line 70355 will be classed as 'oth'\n",
      "This label 'x' on line 70434 will be classed as 'oth'\n",
      "This label 'x' on line 70466 will be classed as 'oth'\n",
      "This label 'x' on line 71220 will be classed as 'oth'\n",
      "This label 'ññ' on line 71762 will be classed as 'oth'\n",
      "This label 'x' on line 72157 will be classed as 'oth'\n",
      "This label 'x' on line 72158 will be classed as 'oth'\n",
      "This label 'sycnh 01:36:00' on line 72213 will be classed as 'oth'\n",
      "This label 'ññ nf' on line 72365 will be classed as 'oth'\n",
      "This label 'ññ nf' on line 72366 will be classed as 'oth'\n",
      "This label 'x' on line 73069 will be classed as 'oth'\n",
      "This label 'beg nf' on line 73110 will be classed as 'oth'\n",
      "This label 'beg nf' on line 73111 will be classed as 'oth'\n",
      "This label 'beg nf' on line 73112 will be classed as 'oth'\n",
      "This label 'beg nf' on line 73113 will be classed as 'oth'\n",
      "This label 'beg nf' on line 73114 will be classed as 'oth'\n",
      "This label 'beg nf' on line 73115 will be classed as 'oth'\n",
      "This label 'beg nf' on line 73116 will be classed as 'oth'\n",
      "This label 'x' on line 73330 will be classed as 'oth'\n",
      "This label 'x' on line 73360 will be classed as 'oth'\n",
      "This label 'x' on line 73421 will be classed as 'oth'\n",
      "This label 'x' on line 73494 will be classed as 'oth'\n",
      "This label 'x' on line 73551 will be classed as 'oth'\n",
      "This label 'x' on line 73610 will be classed as 'oth'\n",
      "This label 'x' on line 73660 will be classed as 'oth'\n",
      "This label 'x' on line 73667 will be classed as 'oth'\n",
      "This label 'x' on line 73676 will be classed as 'oth'\n",
      "This label 'x' on line 73677 will be classed as 'oth'\n",
      "This label 'x' on line 73761 will be classed as 'oth'\n",
      "This label 'x' on line 73762 will be classed as 'oth'\n",
      "This label 'x' on line 73896 will be classed as 'oth'\n",
      "This label 'x' on line 73965 will be classed as 'oth'\n",
      "This label 'zz' on line 73985 will be classed as 'oth'\n",
      "This label 'x' on line 74071 will be classed as 'oth'\n",
      "This label 'x' on line 74084 will be classed as 'oth'\n",
      "This label 'x' on line 74145 will be classed as 'oth'\n",
      "This label 'x' on line 74151 will be classed as 'oth'\n",
      "This label 'x' on line 74304 will be classed as 'oth'\n",
      "This label 'x' on line 74840 will be classed as 'oth'\n",
      "This label 'x' on line 74979 will be classed as 'oth'\n",
      "This label 'cñ *' on line 75342 will be classed as 'oth'\n",
      "This label 'cñ nf' on line 75344 will be classed as 'oth'\n",
      "This label 'ññ nf' on line 75363 will be classed as 'oth'\n",
      "This label 'ññ nf' on line 75364 will be classed as 'oth'\n",
      "This label 'ññ nf' on line 75365 will be classed as 'oth'\n",
      "This label 'x' on line 75679 will be classed as 'oth'\n",
      "This label 'x' on line 75703 will be classed as 'oth'\n",
      "This label 'x' on line 75730 will be classed as 'oth'\n",
      "This label 'x' on line 75754 will be classed as 'oth'\n",
      "This label 'x' on line 75764 will be classed as 'oth'\n",
      "This label 'x' on line 75776 will be classed as 'oth'\n",
      "This label 'x' on line 75806 will be classed as 'oth'\n",
      "This label 'x' on line 75877 will be classed as 'oth'\n",
      "This label 'x' on line 75882 will be classed as 'oth'\n",
      "This label 'x' on line 75895 will be classed as 'oth'\n",
      "This label 'x' on line 75909 will be classed as 'oth'\n",
      "This label 'x' on line 75923 will be classed as 'oth'\n",
      "This label 'x' on line 75946 will be classed as 'oth'\n",
      "This label 'synhch 01:37:30' on line 76620 will be classed as 'oth'\n",
      "This label 'x' on line 76757 will be classed as 'oth'\n",
      "This label 'x' on line 76760 will be classed as 'oth'\n",
      "This label 'x' on line 76767 will be classed as 'oth'\n",
      "This label 'x' on line 76768 will be classed as 'oth'\n",
      "This label 'x' on line 76769 will be classed as 'oth'\n",
      "This label 'x' on line 76772 will be classed as 'oth'\n",
      "This label 'x' on line 76773 will be classed as 'oth'\n",
      "This label 'x' on line 76774 will be classed as 'oth'\n",
      "This label 'x' on line 76775 will be classed as 'oth'\n",
      "This label 'x' on line 76857 will be classed as 'oth'\n",
      "This label 'x' on line 76893 will be classed as 'oth'\n",
      "This label 'x' on line 76894 will be classed as 'oth'\n",
      "This label 'x' on line 76902 will be classed as 'oth'\n",
      "This label 'x' on line 76907 will be classed as 'oth'\n",
      "This label 'x' on line 76922 will be classed as 'oth'\n",
      "This label 'x' on line 76940 will be classed as 'oth'\n",
      "This label 'x' on line 76941 will be classed as 'oth'\n",
      "This label 'x' on line 76943 will be classed as 'oth'\n",
      "This label 'x' on line 76945 will be classed as 'oth'\n",
      "This label 'x' on line 76946 will be classed as 'oth'\n",
      "This label 'x' on line 76994 will be classed as 'oth'\n",
      "This label 'x' on line 77061 will be classed as 'oth'\n",
      "This label '*' on line 77173 will be classed as 'oth'\n",
      "This label 'a %' on line 77243 will be classed as 'oth'\n",
      "This label 'x' on line 77358 will be classed as 'oth'\n",
      "This label 'sic nf %' on line 77601 will be classed as 'oth'\n",
      "This label 'x' on line 78211 will be classed as 'oth'\n",
      "This label 'x' on line 78624 will be classed as 'oth'\n",
      "This label 'x' on line 78643 will be classed as 'oth'\n",
      "This label 'x' on line 78649 will be classed as 'oth'\n",
      "This label 'x' on line 78683 will be classed as 'oth'\n",
      "This label 'x' on line 78698 will be classed as 'oth'\n",
      "This label 'x' on line 78702 will be classed as 'oth'\n",
      "This label 'sic nf' on line 78773 will be classed as 'oth'\n",
      "This label 'x' on line 78985 will be classed as 'oth'\n",
      "This label 'x' on line 79217 will be classed as 'oth'\n",
      "This label 'x' on line 79229 will be classed as 'oth'\n",
      "This label 'x' on line 79252 will be classed as 'oth'\n",
      "This label 'x' on line 79294 will be classed as 'oth'\n",
      "This label 'x' on line 79335 will be classed as 'oth'\n",
      "This label 'x' on line 79378 will be classed as 'oth'\n",
      "This label 'bark' on line 79389 will be classed as 'oth'\n",
      "This label 'x' on line 80076 will be classed as 'oth'\n",
      "This label 'x' on line 80100 will be classed as 'oth'\n",
      "This label 'syn 01:30:30 x' on line 80172 will be classed as 'oth'\n",
      "This label 'x' on line 80391 will be classed as 'oth'\n",
      "This label 'x' on line 80452 will be classed as 'oth'\n",
      "This label 'x' on line 80566 will be classed as 'oth'\n",
      "This label 'x' on line 80569 will be classed as 'oth'\n",
      "This label 'x' on line 80693 will be classed as 'oth'\n",
      "This label 'ñ' on line 81184 will be classed as 'oth'\n",
      "This label 'x' on line 81218 will be classed as 'oth'\n",
      "This label 'x' on line 81661 will be classed as 'oth'\n",
      "This label 'x' on line 82556 will be classed as 'oth'\n",
      "This label 'x' on line 82683 will be classed as 'oth'\n",
      "This label 'x' on line 82712 will be classed as 'oth'\n",
      "This label 'x' on line 82716 will be classed as 'oth'\n",
      "This label 'x' on line 82719 will be classed as 'oth'\n",
      "This label 'x' on line 82929 will be classed as 'oth'\n",
      "This label 'x' on line 82985 will be classed as 'oth'\n",
      "This label 'x' on line 83044 will be classed as 'oth'\n",
      "This label 'x' on line 83666 will be classed as 'oth'\n",
      "This label 'x' on line 83737 will be classed as 'oth'\n",
      "This label 'x' on line 83968 will be classed as 'oth'\n",
      "This label 'x' on line 84004 will be classed as 'oth'\n",
      "This label 'x' on line 84032 will be classed as 'oth'\n",
      "This label 'x' on line 84033 will be classed as 'oth'\n",
      "This label 'x' on line 84037 will be classed as 'oth'\n",
      "This label 'x' on line 84043 will be classed as 'oth'\n",
      "This label 'x' on line 84044 will be classed as 'oth'\n",
      "This label 'x' on line 84062 will be classed as 'oth'\n",
      "This label 'x' on line 84104 will be classed as 'oth'\n",
      "This label 'x' on line 84113 will be classed as 'oth'\n",
      "This label 'x' on line 84121 will be classed as 'oth'\n",
      "This label 'x' on line 84122 will be classed as 'oth'\n",
      "This label 'x' on line 84134 will be classed as 'oth'\n",
      "This label 'x' on line 84138 will be classed as 'oth'\n",
      "This label 'x' on line 84148 will be classed as 'oth'\n",
      "This label '01:57:00' on line 84384 will be classed as 'oth'\n",
      "This label 'x' on line 85457 will be classed as 'oth'\n",
      "This label 'x' on line 86042 will be classed as 'oth'\n",
      "This label 'x' on line 86048 will be classed as 'oth'\n",
      "This label 'x' on line 86073 will be classed as 'oth'\n",
      "This label 'x' on line 86358 will be classed as 'oth'\n",
      "This label 'x' on line 86617 will be classed as 'oth'\n",
      "This label 'ññ *' on line 86706 will be classed as 'oth'\n",
      "This label 'ññ *' on line 86708 will be classed as 'oth'\n",
      "This label 'x' on line 86953 will be classed as 'oth'\n",
      "This label 'x' on line 89845 will be classed as 'oth'\n",
      "This label 'x' on line 89846 will be classed as 'oth'\n",
      "This label 'x' on line 89847 will be classed as 'oth'\n",
      "This label 'x' on line 90616 will be classed as 'oth'\n",
      "This label 'x' on line 90617 will be classed as 'oth'\n",
      "This label 'x' on line 90728 will be classed as 'oth'\n",
      "This label 'x' on line 90729 will be classed as 'oth'\n",
      "This label 'x' on line 91004 will be classed as 'oth'\n",
      "This label 'x' on line 91119 will be classed as 'oth'\n",
      "This label 'x' on line 91120 will be classed as 'oth'\n",
      "This label 'x' on line 91136 will be classed as 'oth'\n",
      "This label 'x' on line 91141 will be classed as 'oth'\n",
      "This label 'x' on line 91151 will be classed as 'oth'\n",
      "This label 'x' on line 91155 will be classed as 'oth'\n",
      "This label 'x' on line 91162 will be classed as 'oth'\n",
      "This label 'x' on line 91171 will be classed as 'oth'\n",
      "This label 'x' on line 91172 will be classed as 'oth'\n",
      "This label 'x' on line 91916 will be classed as 'oth'\n",
      "This label 'x' on line 92331 will be classed as 'oth'\n",
      "This label 'x' on line 92597 will be classed as 'oth'\n",
      "This label 'x' on line 92598 will be classed as 'oth'\n",
      "This label 'x' on line 92730 will be classed as 'oth'\n",
      "This label 'x' on line 92731 will be classed as 'oth'\n",
      "This label 'x' on line 92816 will be classed as 'oth'\n",
      "This label 'x' on line 92894 will be classed as 'oth'\n",
      "This label 'x' on line 92971 will be classed as 'oth'\n",
      "This label 'x' on line 92984 will be classed as 'oth'\n",
      "This label 'x' on line 92988 will be classed as 'oth'\n",
      "This label 'x' on line 93007 will be classed as 'oth'\n",
      "This label 'x' on line 93008 will be classed as 'oth'\n",
      "This label 'x' on line 93009 will be classed as 'oth'\n",
      "This label 'x' on line 95676 will be classed as 'oth'\n",
      "This label 'x' on line 95677 will be classed as 'oth'\n",
      "This label 'x' on line 95816 will be classed as 'oth'\n",
      "This label 'ak nf' on line 96312 will be classed as 'oth'\n",
      "This label 'x' on line 97261 will be classed as 'oth'\n",
      "This label 'x' on line 97817 will be classed as 'oth'\n",
      "This label 'x' on line 98169 will be classed as 'oth'\n",
      "This label 'x' on line 98299 will be classed as 'oth'\n",
      "This label 'x' on line 98402 will be classed as 'oth'\n",
      "This label 'x' on line 98406 will be classed as 'oth'\n",
      "This label 'x' on line 98477 will be classed as 'oth'\n",
      "This label 'x' on line 98550 will be classed as 'oth'\n",
      "This label 'x' on line 98947 will be classed as 'oth'\n",
      "This label 'x' on line 98948 will be classed as 'oth'\n",
      "This label 'x' on line 98950 will be classed as 'oth'\n",
      "This label 'x' on line 98995 will be classed as 'oth'\n",
      "This label 'x' on line 98996 will be classed as 'oth'\n",
      "This label 'chuck nf' on line 99988 will be classed as 'oth'\n",
      "This label 'chuck nf' on line 99997 will be classed as 'oth'\n",
      "This label 'chuck *' on line 100006 will be classed as 'oth'\n",
      "This label 'c nf' on line 100137 will be classed as 'oth'\n",
      "This label 'x' on line 101217 will be classed as 'oth'\n",
      "This label 'v' on line 101338 will be classed as 'oth'\n",
      "This label 'x' on line 101433 will be classed as 'oth'\n",
      "This label 'x' on line 102304 will be classed as 'oth'\n",
      "This label 'x' on line 103150 will be classed as 'oth'\n",
      "This label 'x' on line 103160 will be classed as 'oth'\n",
      "This label 's% nf' on line 104301 will be classed as 'oth'\n",
      "This label 's%' on line 104721 will be classed as 'oth'\n",
      "This label 's%' on line 104725 will be classed as 'oth'\n",
      "This label 'c nf' on line 104799 will be classed as 'oth'\n",
      "This label 's%' on line 104906 will be classed as 'oth'\n",
      "This label 'a nf' on line 105189 will be classed as 'oth'\n",
      "This label 'x' on line 105668 will be classed as 'oth'\n",
      "This label 'a' on line 106014 will be classed as 'oth'\n",
      "This label 's%' on line 106157 will be classed as 'oth'\n",
      "This label 'x' on line 108465 will be classed as 'oth'\n",
      "This label 'x' on line 108522 will be classed as 'oth'\n",
      "This label 'x' on line 108547 will be classed as 'oth'\n",
      "This label 'sych 01:24:00' on line 108633 will be classed as 'oth'\n",
      "This label 'x' on line 108710 will be classed as 'oth'\n",
      "This label 'x' on line 108815 will be classed as 'oth'\n",
      "This label 'x nf' on line 108820 will be classed as 'oth'\n",
      "This label 'sycnh 01:58:30' on line 108975 will be classed as 'oth'\n",
      "This label 'x' on line 108978 will be classed as 'oth'\n",
      "This label 'x' on line 108979 will be classed as 'oth'\n",
      "This label 'x' on line 108980 will be classed as 'oth'\n",
      "This label 'x' on line 108981 will be classed as 'oth'\n",
      "This label 'x' on line 108982 will be classed as 'oth'\n",
      "This label 'x' on line 108983 will be classed as 'oth'\n",
      "This label 'x' on line 108984 will be classed as 'oth'\n",
      "This label 'x' on line 108985 will be classed as 'oth'\n",
      "This label 'x' on line 108986 will be classed as 'oth'\n",
      "This label 'x' on line 108987 will be classed as 'oth'\n",
      "This label 'x' on line 108988 will be classed as 'oth'\n",
      "This label 'x' on line 108990 will be classed as 'oth'\n",
      "This label 'x' on line 108992 will be classed as 'oth'\n",
      "This label 'x' on line 109165 will be classed as 'oth'\n",
      "This label 'x' on line 109240 will be classed as 'oth'\n",
      "This label 'x' on line 110168 will be classed as 'oth'\n",
      "This label 'x' on line 110169 will be classed as 'oth'\n",
      "This label 'x' on line 110189 will be classed as 'oth'\n",
      "This label 'x' on line 110213 will be classed as 'oth'\n",
      "This label 'x' on line 110243 will be classed as 'oth'\n",
      "This label 'x' on line 110244 will be classed as 'oth'\n",
      "This label 'x' on line 110245 will be classed as 'oth'\n",
      "This label 'chuck' on line 110251 will be classed as 'oth'\n",
      "This label 'chuck' on line 110252 will be classed as 'oth'\n",
      "This label 'x' on line 110276 will be classed as 'oth'\n",
      "This label 'x' on line 110386 will be classed as 'oth'\n",
      "This label 'x' on line 110467 will be classed as 'oth'\n",
      "This label 'x' on line 110550 will be classed as 'oth'\n",
      "This label 'sycnh 01:57:00' on line 110831 will be classed as 'oth'\n",
      "This label 'x' on line 110928 will be classed as 'oth'\n",
      "This label 'x' on line 110931 will be classed as 'oth'\n",
      "This label 'x' on line 110948 will be classed as 'oth'\n",
      "This label 'x' on line 110992 will be classed as 'oth'\n",
      "This label 'x' on line 111258 will be classed as 'oth'\n",
      "This label 'x' on line 111268 will be classed as 'oth'\n",
      "This label 'x' on line 111374 will be classed as 'oth'\n",
      "This label 'synhc 01:37:30' on line 111422 will be classed as 'oth'\n",
      "This label 'x' on line 111628 will be classed as 'oth'\n",
      "This label 'x' on line 111629 will be classed as 'oth'\n",
      "This label 'x' on line 111630 will be classed as 'oth'\n",
      "This label 'x' on line 111631 will be classed as 'oth'\n",
      "This label 'x' on line 112105 will be classed as 'oth'\n",
      "This label 'x' on line 112156 will be classed as 'oth'\n",
      "This label 'x' on line 112173 will be classed as 'oth'\n",
      "This label 'x' on line 112174 will be classed as 'oth'\n",
      "This label 'x' on line 112180 will be classed as 'oth'\n",
      "This label 'x' on line 112216 will be classed as 'oth'\n",
      "This label 'x' on line 112217 will be classed as 'oth'\n",
      "This label 'x' on line 112278 will be classed as 'oth'\n",
      "This label 'x' on line 112290 will be classed as 'oth'\n",
      "This label 'x' on line 112300 will be classed as 'oth'\n",
      "This label 'x' on line 112500 will be classed as 'oth'\n",
      "This label 'x' on line 112507 will be classed as 'oth'\n",
      "This label 'x' on line 112508 will be classed as 'oth'\n",
      "This label 'x' on line 112509 will be classed as 'oth'\n",
      "This label 'x' on line 112510 will be classed as 'oth'\n",
      "This label 'x' on line 112511 will be classed as 'oth'\n",
      "This label 'x' on line 112512 will be classed as 'oth'\n",
      "This label 'x' on line 112513 will be classed as 'oth'\n",
      "This label 'x' on line 112514 will be classed as 'oth'\n",
      "This label 'x' on line 112515 will be classed as 'oth'\n",
      "This label 'x' on line 112516 will be classed as 'oth'\n",
      "This label 'x' on line 112517 will be classed as 'oth'\n",
      "This label 'x' on line 112518 will be classed as 'oth'\n",
      "This label 'x' on line 112519 will be classed as 'oth'\n",
      "This label 'x' on line 112520 will be classed as 'oth'\n",
      "This label 'x' on line 112558 will be classed as 'oth'\n",
      "This label 'x' on line 112559 will be classed as 'oth'\n",
      "This label 'x' on line 112560 will be classed as 'oth'\n",
      "This label 'x' on line 112569 will be classed as 'oth'\n",
      "This label 'x' on line 112578 will be classed as 'oth'\n"
     ]
    }
   ],
   "source": [
    "# Create the label table\n",
    "label_table = pre.create_meerkat_table(labels_all, call_types, sep,\n",
    "                                       start_column, duration_column, columns_to_keep,\n",
    "                                       label_column, convert_to_seconds, \n",
    "                                       label_for_other, label_for_noise, engine,\n",
    "                                       multiclass_forbidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.068\n"
     ]
    }
   ],
   "source": [
    "# estimate the average beep length because many of them are not annotated in the data\n",
    "avg_beep = round(statistics.mean(label_table.loc[label_table[\"beep\"],\"Duration\"].loc[label_table.loc[label_table[\"beep\"],\"Duration\"]>0]),3)\n",
    "label_table.loc[(label_table[\"beep\"].bool and label_table[\"Duration\"] == 0.) ==True, \"Duration\"] = avg_beep\n",
    "label_table.loc[(label_table[\"beep\"].bool and label_table[\"Duration\"] == avg_beep) ==True, \"End\"] += avg_beep\n",
    "print(avg_beep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add wav and audio paths\n",
    "label_table[\"wav_path\"] = label_table['wavFileName'].apply(lambda x: [pathi for pathi in audio_filepaths if x in pathi][0])\n",
    "label_table[\"label_path\"] = label_table['csvFileName'].apply(lambda x: [pathi for pathi in label_filepaths if x in pathi][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure these paths are added to the noise table too\n",
    "columns_to_keep.append(\"wav_path\")\n",
    "columns_to_keep.append(\"label_path\")\n",
    "\n",
    "# create the matching noise table\n",
    "noise_table = pre.create_noise_table(label_table, call_types, label_for_noise, label_for_startstop, columns_to_keep)#, '\\$'])\n",
    "\n",
    "# remove rows where the annotated noise is smaller than the window size otherwise the spectrogram we generate will inclue a call\n",
    "noise_table = noise_table.drop(noise_table[noise_table[\"Duration\"] < spec_window_size].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YEAR and GROUP SENSITIVITY ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "audio_filenames Here we split the training and test set based on files (rather than spectrograms). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/200\n",
      "145/145 [==============================] - 189s 1s/step - loss: 1.3525 - output_calltype_loss: 1.3420 - output_callpresence_loss: 0.2110 - output_calltype_categorical_accuracy: 0.6984 - output_callpresence_binary_accuracy: 0.7112 - val_loss: 1.1669 - val_output_calltype_loss: 1.1568 - val_output_callpresence_loss: 0.2008 - val_output_calltype_categorical_accuracy: 0.7064 - val_output_callpresence_binary_accuracy: 0.7151\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/callbacks.py:995: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/200\n",
      "115/145 [======================>.......] - ETA: 36s - loss: 1.1835 - output_calltype_loss: 1.1735 - output_callpresence_loss: 0.2010 - output_calltype_categorical_accuracy: 0.7079 - output_callpresence_binary_accuracy: 0.7219"
     ]
    }
   ],
   "source": [
    "train_pattern = [[\"L2019\",\"HM2019\"],[\"HM2017\",\"HM2019\"], [\"L2019\"], [\"HM2017\"]]\n",
    "\n",
    "for sensitivity_i in train_pattern:  \n",
    "    \n",
    "    \n",
    "    ### SETUP file structure for sensitivity runs\n",
    "    #------------------------------------------------------------\n",
    "    run_name = \"NoiseAugmented_\"+ str(min_scaling_factor)+\"_\" +str(max_scaling_factor)+\"_NotWeighted_MaskedOther_Forked_trained_with_\" + '_'.join(sensitivity_i)\n",
    "\n",
    "    # basically the root directory for train, test and model\n",
    "    save_data_path = os.path.join(results_dir, run_name)\n",
    "    if not os.path.isdir(save_data_path):\n",
    "        os.makedirs(save_data_path)\n",
    "\n",
    "    # Test folders\n",
    "    test_path = os.path.join(save_data_path, 'test_data')\n",
    "    if not os.path.isdir(test_path):\n",
    "        os.makedirs(test_path)\n",
    "\n",
    "\n",
    "    save_pred_test_path = os.path.join(test_path , \"predictions\")\n",
    "    if not os.path.isdir(save_pred_test_path):\n",
    "        os.makedirs(save_pred_test_path)\n",
    "\n",
    "    save_pred_stack_test_path = os.path.join(save_pred_test_path,\"stacks\")\n",
    "    if not os.path.isdir(save_pred_stack_test_path):\n",
    "        os.makedirs(save_pred_stack_test_path)        \n",
    "\n",
    "    save_pred_table_test_path = os.path.join(save_pred_test_path,\"pred_table\")\n",
    "    if not os.path.isdir(save_pred_table_test_path):\n",
    "        os.makedirs(save_pred_table_test_path)\n",
    "\n",
    "    save_label_table_test_path = os.path.join(test_path, 'label_table')\n",
    "    if not os.path.isdir(save_label_table_test_path):\n",
    "        os.makedirs(save_label_table_test_path)\n",
    "\n",
    "    save_metrics_path = os.path.join(test_path , \"metrics\")\n",
    "    if not os.path.isdir(save_metrics_path):\n",
    "        os.makedirs(save_metrics_path)\n",
    "\n",
    "    save_metrics_path_eval = os.path.join(save_metrics_path, eval_analysis)\n",
    "    if not os.path.isdir(save_metrics_path_eval):\n",
    "        os.makedirs(save_metrics_path_eval)\n",
    "\n",
    "\n",
    "    # Model folder\n",
    "    save_model_path = os.path.join(save_data_path, 'trained_model')\n",
    "    if not os.path.isdir(save_model_path):\n",
    "        os.makedirs(save_model_path)\n",
    "       \n",
    "\n",
    "    training_files = label_table['wavFileName'][label_table['group'].isin(sensitivity_i)].unique()\n",
    "    testing_filenames = label_table['wavFileName'][label_table['group'].isin(sensitivity_i) == False].unique()\n",
    "    \n",
    "    if len(training_files) > 100:\n",
    "        shuffle(training_files)\n",
    "        training_files = training_files[0:100]\n",
    "    \n",
    "    if len(testing_filenames) > 11:\n",
    "        shuffle(testing_filenames)\n",
    "        testing_filenames = testing_filenames[0:11]\n",
    "        \n",
    "    \n",
    "    # Split the training and test set based on the separation\n",
    "    split_index = floor(len(training_files) * train_val_split )\n",
    "    shuffle(training_files)\n",
    "    training_filenames = training_files[:split_index]\n",
    "    validation_filenames = training_files[split_index:]\n",
    "\n",
    "\n",
    "    # save a copy of the training and testing diles\n",
    "    with open(os.path.join(save_model_path, \"training_files_used.txt\"), \"w\") as f:\n",
    "        for s in training_filenames:\n",
    "            f.write(str(s) +\"\\n\")\n",
    "    with open(os.path.join(save_model_path, \"testing_files_used.txt\"), \"w\") as f:\n",
    "        for s in testing_filenames:\n",
    "            f.write(str(s) +\"\\n\")\n",
    "    with open(os.path.join(save_model_path, \"validation_files_used.txt\"), \"w\") as f:\n",
    "        for s in validation_filenames:\n",
    "            f.write(str(s) +\"\\n\")\n",
    "\n",
    "\n",
    "    '''Then we create a dictionary that will be used in the datagenerator. \n",
    "    Each key is a calltype and contains the start/stop/duration/filename where that call occurs. \n",
    "    This allows the data generator to shuffle them during the training.\n",
    "    '''\n",
    "\n",
    "    # separate out the training and test sets for analysis\n",
    "    training_label_table = label_table[label_table['wavFileName'].isin(training_filenames)]\n",
    "    testing_label_table = label_table[label_table['wavFileName'].isin(testing_filenames)]\n",
    "    validation_label_table = label_table[label_table['wavFileName'].isin(validation_filenames)]\n",
    "\n",
    "    # do the same for the noise\n",
    "    training_noise_table = noise_table[noise_table['wavFileName'].isin(training_filenames)]\n",
    "    testing_noise_table = noise_table[noise_table['wavFileName'].isin(testing_filenames)]\n",
    "    validation_noise_table = noise_table[noise_table['wavFileName'].isin(validation_filenames)]\n",
    "\n",
    "    # Compile training data into a format that the data generator can use\n",
    "    training_label_dict = dict()\n",
    "    for label in call_types: \n",
    "        training_label_dict[label] = training_label_table.loc[training_label_table[label] == True, [\"Label\", \"Start\", \"Duration\",\"End\",\"wav_path\",\"label_path\"]]\n",
    "    training_label_dict[label_for_noise] = training_noise_table[[\"Label\", \"Start\", \"Duration\",\"End\",\"wav_path\",\"label_path\"]]\n",
    "\n",
    "    # Compile test data into a format that the data generator can use\n",
    "    testing_label_dict = dict()\n",
    "    for label in call_types: \n",
    "        testing_label_dict[label] = testing_label_table.loc[testing_label_table[label] == True, [\"Label\", \"Start\", \"Duration\",\"End\",\"wav_path\",\"label_path\"]]\n",
    "    testing_label_dict[label_for_noise] = testing_noise_table[[\"Label\", \"Start\", \"Duration\",\"End\",\"wav_path\",\"label_path\"]]\n",
    "\n",
    "    # Compile validation data into a format that the data generator can use\n",
    "    validation_label_dict = dict()\n",
    "    for label in call_types: \n",
    "        validation_label_dict[label] = validation_label_table.loc[validation_label_table[label] == True, [\"Label\", \"Start\", \"Duration\",\"End\",\"wav_path\",\"label_path\"]]\n",
    "    validation_label_dict[label_for_noise] = validation_label_table[[\"Label\", \"Start\", \"Duration\",\"End\",\"wav_path\",\"label_path\"]]\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    # TRAINING\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    \n",
    "\n",
    "    ## Build the training and validation data generators (for real this time)\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    \n",
    "\n",
    "\n",
    "    if is_forked == True:\n",
    "        # initiate the data generator\n",
    "        train_generator = bg.ForkedDataGenerator(training_label_dict,\n",
    "                                                 training_label_table, \n",
    "                                                 spec_window_size,\n",
    "                                                 n_mels, \n",
    "                                                 window, \n",
    "                                                 fft_win , \n",
    "                                                 fft_hop , \n",
    "                                                 normalise,\n",
    "                                                 label_for_noise,\n",
    "                                                 label_for_other,\n",
    "                                                 min_scaling_factor,\n",
    "                                                 max_scaling_factor,\n",
    "                                                 n_per_call,\n",
    "                                                 other_ignored_in_training,\n",
    "                                                 mask_value,\n",
    "                                                 mask_vector)\n",
    "        \n",
    "        # get a batch to estimate rnn parameters\n",
    "        x_train, y_train = train_generator.__next__()#__getitem__(0)\n",
    "\n",
    "        # initial parameters\n",
    "        num_calltypes = y_train[0].shape[2]\n",
    "        gru_units = y_train[0].shape[1] \n",
    "\n",
    "\n",
    "        # initialise the training data generator and validation data generator\n",
    "        train_generator = bg.ForkedDataGenerator(training_label_dict,\n",
    "                                                 training_label_table, \n",
    "                                                 spec_window_size,\n",
    "                                                 n_mels, \n",
    "                                                 window, \n",
    "                                                 fft_win , \n",
    "                                                 fft_hop , \n",
    "                                                 normalise,\n",
    "                                                 label_for_noise,\n",
    "                                                 label_for_other,\n",
    "                                                 min_scaling_factor,\n",
    "                                                 max_scaling_factor,\n",
    "                                                 n_per_call,\n",
    "                                                 other_ignored_in_training,\n",
    "                                                 mask_value,\n",
    "                                                 mask_vector)\n",
    "\n",
    "        val_generator = bg.ForkedDataGenerator(validation_label_dict,\n",
    "                                               validation_label_table, \n",
    "                                               spec_window_size,\n",
    "                                               n_mels, \n",
    "                                               window, \n",
    "                                               fft_win , \n",
    "                                               fft_hop , \n",
    "                                               normalise,\n",
    "                                               label_for_noise,\n",
    "                                               label_for_other,\n",
    "                                               min_scaling_factor,\n",
    "                                               max_scaling_factor,\n",
    "                                               n_per_call,\n",
    "                                               other_ignored_in_training,\n",
    "                                               mask_value,\n",
    "                                               mask_vector)\n",
    "\n",
    "    else:\n",
    "        train_generator = bg.DataGenerator(training_label_dict,\n",
    "                                                 training_label_table, \n",
    "                                                 spec_window_size,\n",
    "                                                 n_mels, \n",
    "                                                 window, \n",
    "                                                 fft_win , \n",
    "                                                 fft_hop , \n",
    "                                                 normalise,\n",
    "                                                 label_for_noise,\n",
    "                                                 label_for_other,\n",
    "                                                 min_scaling_factor,\n",
    "                                                 max_scaling_factor,\n",
    "                                                 n_per_call,\n",
    "                                                 other_ignored_in_training,\n",
    "                                                 mask_value,\n",
    "                                                 mask_vector)\n",
    "        x_train, y_train = train_generator.__next__()#__getitem__(0)\n",
    "\n",
    "        # initial parameters\n",
    "        num_calltypes = y_train[0].shape[2]\n",
    "        gru_units = y_train[0].shape[1] \n",
    "\n",
    "        train_generator = bg.DataGenerator(training_label_dict,\n",
    "                                                 training_label_table, \n",
    "                                                 spec_window_size,\n",
    "                                                 n_mels, \n",
    "                                                 window, \n",
    "                                                 fft_win , \n",
    "                                                 fft_hop , \n",
    "                                                 normalise,\n",
    "                                                 label_for_noise,\n",
    "                                                 label_for_other,\n",
    "                                                 min_scaling_factor,\n",
    "                                                 max_scaling_factor,\n",
    "                                                 n_per_call,\n",
    "                                                 other_ignored_in_training,\n",
    "                                                 mask_value,\n",
    "                                                 mask_vector)\n",
    "\n",
    "        val_generator = bg.DataGenerator(validation_label_dict,\n",
    "                                               validation_label_table, \n",
    "                                               spec_window_size,\n",
    "                                               n_mels, \n",
    "                                               window, \n",
    "                                               fft_win , \n",
    "                                               fft_hop , \n",
    "                                               normalise,\n",
    "                                               label_for_noise,\n",
    "                                               label_for_other,\n",
    "                                               min_scaling_factor,\n",
    "                                               max_scaling_factor,\n",
    "                                               n_per_call,\n",
    "                                               other_ignored_in_training,\n",
    "                                               mask_value,\n",
    "                                               mask_vector)    \n",
    "\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    ## CONSTRUCT THE RNN\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    # initialise the model class\n",
    "    model = rnn.BuildNetwork(x_train, num_calltypes, filters, gru_units, dense_neurons, dropout, mask_value)\n",
    "\n",
    "    # build the model\n",
    "    if is_forked == True:\n",
    "        RNN_model = model.build_forked_masked_rnn()\n",
    "\n",
    "        # Multiple target losses\n",
    "        losses = {\n",
    "            'output_calltype' : 'categorical_crossentropy',  # classification\n",
    "            'output_callpresence' : 'mse'  # regression 0-1\n",
    "        }\n",
    "\n",
    "        loss_weights = {\n",
    "            'output_calltype' : 1.0,\n",
    "            'output_callpresence' : 0.05  # Making this too large is not a good idea as we really want the network paying attention to class\n",
    "        }\n",
    "        accuracy_metrics = {\n",
    "            'output_calltype' : 'categorical_accuracy',\n",
    "            'output_callpresence' : 'binary_accuracy'\n",
    "            \n",
    "        }\n",
    "\n",
    "    else:\n",
    "        RNN_model = model.build_masked_rnn()\n",
    "        # only one target loss\n",
    "        losses = 'categorical_crossentropy'\n",
    "        loss_weights = None\n",
    "        accuracy_metrics = 'categorical_accuracy'\n",
    "\n",
    "    # Adam optimiser\n",
    "    adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "    # Compile the model\n",
    "    #RNN_model.compile(optimizer=adam, loss=losses, loss_weights=loss_weights, metrics=['binary_accuracy'])\n",
    "    RNN_model.compile(optimizer=adam, loss=losses, loss_weights=loss_weights, metrics = accuracy_metrics)\n",
    "\n",
    "    # Setup callbycks: learning rate / loss /tensorboard\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr_plat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, verbose=1,\n",
    "                                       mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.000001)\n",
    "    loss = LossHistory()\n",
    "\n",
    "    # setup a path with a timestamp\n",
    "    date_time = datetime.datetime.now()\n",
    "    date_now = str(date_time.date())\n",
    "    time_now = str(date_time.time())\n",
    "    save_tensorboard_path = os.path.join(save_model_path, \"tensorboard_logs_\" + date_now + \"_\" + time_now)\n",
    "    if not os.path.isdir(save_tensorboard_path):\n",
    "        os.makedirs(save_tensorboard_path)   \n",
    "\n",
    "    # tensorboard\n",
    "    tensorboard = TensorBoard(log_dir = save_tensorboard_path,\n",
    "                              histogram_freq=0,\n",
    "                              write_graph=True,  # Show the network\n",
    "                              write_grads=True   # Show gradients\n",
    "                              )  \n",
    "    # fit model\n",
    "    RNN_model.fit_generator(train_generator, \n",
    "                            steps_per_epoch = train_generator.__len__(),\n",
    "                            epochs = epochs,\n",
    "                            callbacks = [early_stopping, reduce_lr_plat, loss, tensorboard],\n",
    "                            validation_data = val_generator,\n",
    "                            validation_steps = val_generator.__len__())\n",
    "\n",
    "\n",
    "    # Look at the model\n",
    "    # plot_model(RNN_model, run_name + \".png\", show_shapes=True)\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    ## SAVE THE MODEL\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    # save the model\n",
    "    date_time = datetime.datetime.now()\n",
    "    date_now = str(date_time.date())\n",
    "    time_now = str(date_time.time())\n",
    "    sf = os.path.join(save_model_path, run_name+ \"_\" + date_now + \"_\" + time_now)\n",
    "    if not os.path.isdir(sf):\n",
    "        os.makedirs(sf)\n",
    "\n",
    "    RNN_model.save(sf + '/savedmodel' + '.h5')\n",
    "\n",
    "    print(sf)\n",
    "\n",
    "    test = load_model(sf + '/savedmodel' + '.h5')\n",
    "    test.summary()\n",
    "    #test.predict([spec])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    ## TESTING\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    ## Predict over the test files\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    skipped_files = []\n",
    "\n",
    "    # we only do one file in this example to avoid it running too long\n",
    "    for file_ID in testing_filenames:\n",
    "        # file_ID = testing_filenames[0] # for testing purposes only\n",
    "\n",
    "        # subset the label table to only use that one file\n",
    "        file_label_table = testing_label_table[testing_label_table['wavFileName'].isin([file_ID])]\n",
    "        file_label_table = file_label_table.sort_values(by=['Start']).reset_index()\n",
    "        # Find the file ID name i.e. remove the extention\n",
    "        file_ID = file_ID.split(\".\")[0] \n",
    "        # find the matching audio for the label data\n",
    "        audio_path = file_label_table[\"wav_path\"][0]   \n",
    "\n",
    "        print(\"*****************************************************************\")   \n",
    "        print(\"*****************************************************************\") \n",
    "        print (\"File being processed : \" + audio_path)    \n",
    "\n",
    "        # find the start and stop  of the labelling periods (also using skipon/skipoff)\n",
    "        loop_table = file_label_table.loc[file_label_table[\"Label\"].str.contains('|'.join(label_for_startstop), regex=True, case = False), [\"Label\",\"Start\"]]\n",
    "        loop_times = list(loop_table[\"Start\"])\n",
    "\n",
    "        # Make sure that the file contains the right number of start and stops, otherwise go to the next file\n",
    "        if len(loop_times)%2 != 0:\n",
    "            print(\"!!!!!!!!!!!!!!!!\")\n",
    "            warnings.warn(\"There is a missing start or stop in this file and it has been skipped: \" + audio_path)\n",
    "            skipped_files.append(file_ID)\n",
    "            continue \n",
    "\n",
    "        if len(loop_times) == 0:\n",
    "            print(\"!!!!!!!!!!!!!!!!\")\n",
    "            warnings.warn(\"There is a missing start or stop in this file and it has been skipped: \" + audio_path)\n",
    "            skipped_files.append(file_ID)\n",
    "            continue \n",
    "\n",
    "        # save the label_table\n",
    "        save_label_table_filename = file_ID + \"_LABEL_TABLE.txt\"\n",
    "        file_label_table.to_csv(os.path.join(save_label_table_test_path, save_label_table_filename), \n",
    "                            header=True, index=None, sep=';')\n",
    "\n",
    "        # load the audio data\n",
    "        y, sr = librosa.load(audio_path, sr=None, mono=False)\n",
    "\n",
    "        # # Reshaping the Audio file (mono) to deal with all wav files similarly\n",
    "        # if y.ndim == 1:\n",
    "        #     y = y.reshape(1, -1)\n",
    "\n",
    "        # # Implement this for acc data\n",
    "        # for ch in range(y.shape[0]):\n",
    "        # ch=0\n",
    "        # y_sub = y[:,ch]\n",
    "        y_sub = y\n",
    "\n",
    "        # loop through every labelling start based on skipon/off within this loop_table\n",
    "        for loopi in range(0, int(len(loop_times)), 2):\n",
    "            # loopi = 0\n",
    "            fromi =  loop_times[loopi]\n",
    "            #toi = fromi + 5\n",
    "            toi = loop_times[int(loopi + 1)] # define the end of the labelling periods\n",
    "\n",
    "            calltype_pred_list = []\n",
    "            callpresence_pred_list = []\n",
    "            # if the file exists, load it\n",
    "            if os.path.exists(os.path.join(save_pred_stack_test_path, file_ID + '_CALLTYPE_PRED_STACK_' + str(fromi) + '-' + str(toi) + '.npy')): \n",
    "                calltype_pred_list = np.load( os.path.join(save_pred_stack_test_path, file_ID + '_CALLTYPE_PRED_STACK_' + str(fromi) + '-' + str(toi) + '.npy')) \n",
    "                callpresence_pred_list = np.load( os.path.join(save_pred_stack_test_path, file_ID + '_CALLPRESENCE_PRED_STACK_' + str(fromi) + '-' + str(toi) + '.npy'))\n",
    "\n",
    "\n",
    "            # if the file is incomplete or non existant redo it\n",
    "            if (len(np.arange(fromi, toi, slide)) - sum(np.arange(fromi, toi, slide)+spec_window_size > toi)) != (len(calltype_pred_list)):\n",
    "\n",
    "                for spectro_slide in np.arange(fromi, toi, slide):                \n",
    "                    # spectro_slide = fromi\n",
    "                    start = round(spectro_slide,3)\n",
    "                    stop = round(spectro_slide + spec_window_size, 3)\n",
    "\n",
    "                    # ignore cases where the window is larger than what is labelled (e.g. at the end)\n",
    "                    if stop <= toi:\n",
    "\n",
    "                        #generate the spectrogram\n",
    "                        spectro = pre.generate_mel_spectrogram(y=y_sub, sr=sr, start=start, stop=stop, \n",
    "                                                                n_mels = n_mels, window='hann', \n",
    "                                                                fft_win= fft_win, fft_hop = fft_hop, \n",
    "                                                                normalise = True)\n",
    "\n",
    "                        # transpose it and put it in a format that works with the NN\n",
    "                        spec = spectro.T\n",
    "                        spec = spec[np.newaxis, ..., np.newaxis]  \n",
    "\n",
    "                        # generate a mask (as a placeholder) but don't mask anything as we are predicting and want to include other\n",
    "                        mask = np.asarray([True for i in range(spectro.shape[1])])\n",
    "                        mask = mask[np.newaxis,...]\n",
    "\n",
    "                        # generate the prediction\n",
    "                        pred = RNN_model.predict([spec,mask])\n",
    "\n",
    "                        # add this prediction to the stack that will be used to generate the predictions table\n",
    "                        if is_forked:\n",
    "                            calltype_pred_list.append(np.squeeze(pred[0]))\n",
    "                            callpresence_pred_list.append(np.squeeze(pred[1]))\n",
    "                        else:\n",
    "                            calltype_pred_list.append(np.squeeze(pred))\n",
    "\n",
    "                # save the prediction stacks\n",
    "                np.save( os.path.join(save_pred_stack_test_path, file_ID + '_CALLTYPE_PRED_STACK_' + str(fromi) + '-' + str(toi) + '.npy'), calltype_pred_list)\n",
    "                with open(os.path.join(save_pred_stack_test_path, file_ID + '_CALLTYPE_PRED_STACK_' + str(fromi) + '-' + str(toi) + '.txt'), \"w\") as f:\n",
    "                    for row in calltype_pred_list:\n",
    "                        f.write(str(row) +\"\\n\")\n",
    "                if is_forked:      \n",
    "                    np.save( os.path.join(save_pred_stack_test_path, file_ID + '_CALLPRESENCE_PRED_STACK_' + str(fromi) + '-' + str(toi) + '.npy'), callpresence_pred_list)\n",
    "                    with open(os.path.join(save_pred_stack_test_path, file_ID + '_CALLPRESENCE_PRED_STACK_' + str(fromi) + '-' + str(toi) + '.txt'), \"w\") as f:\n",
    "                        for row in callpresence_pred_list:\n",
    "                            f.write(str(row) +\"\\n\")\n",
    "\n",
    "            # Loop through different sets of thresholds\n",
    "            for low_thr in [0.1]:\n",
    "                for high_thr in [0.5,0.6,0.7,0.8,0.9,0.95]: \n",
    "\n",
    "                    # make sure it doesnt generate a 0.00098982374957839486 type number\n",
    "                    low_thr = round(low_thr,2)                               \n",
    "                    high_thr = round(high_thr,2)\n",
    "\n",
    "                    # stop the loop if the low threshold is bigger than the high threshold\n",
    "                    if low_thr >= high_thr:\n",
    "                        continue\n",
    "\n",
    "                    save_pred_table_filename = file_ID + \"_CALLTYPE_PRED_TABLE_thr_\" + str(low_thr) + \"-\" + str(high_thr) + \".txt\"\n",
    "\n",
    "                    # if the file exists, pass to the next iteration of the loop\n",
    "                    #if os.path.exists(os.path.join(save_pred_table_test_path, save_pred_table_filename)):\n",
    "                    #    continue\n",
    "\n",
    "                    print(\"*****************************************************************\") \n",
    "                    print (\"Low Threshold: \" + str(low_thr))    \n",
    "                    print (\"High Threshold: \" + str(high_thr))  \n",
    "\n",
    "                    #----------------------------------------------------------------------------\n",
    "                    # Compile the predictions for each on/off labelling chunk\n",
    "                    detections = ppm.merge_p(probabilities = calltype_pred_list, \n",
    "                                              labels=list(call_types.keys()),\n",
    "                                              starttime = 0, \n",
    "                                              frameadv_s = fft_hop, \n",
    "                                              specadv_s = slide,\n",
    "                                              low_thr=low_thr, \n",
    "                                              high_thr=high_thr, \n",
    "                                              debug=1)\n",
    "\n",
    "                    #in case the dataset was just noise, still create an empty placeholder to merge\n",
    "                    if len(detections) == 0:  \n",
    "                        detections = pd.DataFrame(columns = ['category', 'start', 'end', 'scores'])\n",
    "\n",
    "                    # create an empty dataset\n",
    "                    pred_table = pd.DataFrame() \n",
    "\n",
    "                    #convert these detections to a predictions table                \n",
    "                    table = pd.DataFrame(detections)\n",
    "                    table[\"Label\"] = table[\"category\"]\n",
    "                    table[\"Start\"] = round(table[\"start\"]*fft_hop + fromi, 3) #table[\"start\"].apply(Decimal)*Decimal(fft_hop) + Decimal(fromi)\n",
    "                    table[\"Duration\"] = round( (table[\"end\"]-table[\"start\"])*fft_hop, 3) #(table[\"end\"].apply(Decimal)-table[\"start\"].apply(Decimal))*Decimal(fft_hop)\n",
    "                    table[\"End\"] = round(table[\"end\"]*fft_hop + fromi, 3) #table[\"Start\"].apply(Decimal) + table[\"Duration\"].apply(Decimal)\n",
    "\n",
    "                    # keep only the useful columns    \n",
    "                    table = table[[\"Label\",\"Start\",\"Duration\", \"End\", \"scores\"]]  \n",
    "\n",
    "                    # Add a row which stores the start of the labelling period\n",
    "                    row_start = pd.DataFrame()\n",
    "                    row_start.loc[0,'Label'] = list(loop_table[\"Label\"])[loopi]\n",
    "                    row_start.loc[0,'Start'] = fromi\n",
    "                    row_start.loc[0,'Duration'] = 0\n",
    "                    row_start.loc[0,'End'] = fromi \n",
    "                    row_start.loc[0,'scores'] = [0] \n",
    "\n",
    "                    # Add a row which stores the end of the labelling period\n",
    "                    row_stop = pd.DataFrame()\n",
    "                    row_stop.loc[0,'Label'] = list(loop_table[\"Label\"])[int(loopi + 1)]\n",
    "                    row_stop.loc[0,'Start'] = toi\n",
    "                    row_stop.loc[0,'Duration'] = 0\n",
    "                    row_stop.loc[0,'End'] = toi \n",
    "                    row_stop.loc[0,'scores'] = [0]       \n",
    "\n",
    "                    # add the true false columns based on the call types dictionary\n",
    "                    for true_label in call_types:\n",
    "                        table[true_label] = False\n",
    "                        row_start[true_label] = False\n",
    "                        row_stop[true_label] = False\n",
    "                        for old_label in call_types[true_label]:\n",
    "                            table.loc[table[\"Label\"].str.contains(old_label, regex=True, case = False), true_label] = True\n",
    "\n",
    "                    # make sure start and stop are not classified as calls\n",
    "                    row_start[label_for_noise] = True\n",
    "                    row_stop[label_for_noise] = True\n",
    "\n",
    "                    # put these rows to the label table\n",
    "                    table = pd.concat([row_start, table, row_stop]) \n",
    "\n",
    "                    # add this table to the overall predictions table for that collar\n",
    "                    pred_table = pd.concat([pred_table, table ])\n",
    "\n",
    "                    # for each on/off labelling chunk, we can save the prediction and append it to the previous chunk\n",
    "                    if loopi == 0:                    \n",
    "                        # for the first chunck keep the header, but not when appending later. Also, overwrite old runs\n",
    "                        pred_table.to_csv(os.path.join(save_pred_table_test_path, save_pred_table_filename), \n",
    "                                          header=True, index=None, sep=';', mode = 'w')\n",
    "                    else:\n",
    "                        pred_table.to_csv(os.path.join(save_pred_table_test_path, save_pred_table_filename), \n",
    "                                          header=None, index=None, sep=';', mode = 'a')\n",
    "\n",
    "    '''\n",
    "    # # load the saved file\n",
    "    # with open(os.path.join(save_pred_stack_test_path, file_ID + '_PRED_STACK.txt')) as f:\n",
    "    #     content = f.readlines()\n",
    "    # # remove whitespace characters like `\\n` at the end of each line\n",
    "    # pred_list = [x.strip() for x in content] \n",
    "\n",
    "\n",
    "    # #or\n",
    "    # pred_list = np.load( os.path.join(save_pred_stack_test_path, file_ID + '_PRED_STACK.npy'))\n",
    "    # '''\n",
    "\n",
    "    # save the files that were skipped\n",
    "    print(skipped_files)\n",
    "\n",
    "    # save a copy of the training and testing diles\n",
    "    with open(os.path.join(save_model_path, \"skipped_testing_files.txt\"), \"w\") as f:\n",
    "        for s in skipped_files:\n",
    "            f.write(str(s) +\"\\n\")\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    ## TESTING\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    # because of new file format, need to only keep certain columns so that the evaluation metrics work with the label tables\n",
    "    column_names = [\"Label\",\"Start\",\"Duration\",\"End\"]\n",
    "    column_names.extend(list(testing_label_dict.keys()))  \n",
    "\n",
    "    file_ID_list = [file_ID.split(\".\")[0] for file_ID in testing_filenames if file_ID not in skipped_files]\n",
    "    labels_list =  [os.path.join(save_label_table_test_path,file_ID.split(\".\")[0]  + \"_LABEL_TABLE.txt\" ) for file_ID in file_ID_list]\n",
    "    \n",
    "    # get rid of duplicates\n",
    "    for file in labels_list :\n",
    "        df = pd.read_csv(file, delimiter=';') \n",
    "        # df = df.drop_duplicates(keep=False)\n",
    "        df = df[column_names]\n",
    "        df.to_csv(file, header=True, index=None, sep=';', mode = 'w')\n",
    "\n",
    "    for low_thr in [0.1]:\n",
    "        for high_thr in [0.5,0.6,0.7,0.8,0.9,0.95]: \n",
    "\n",
    "            low_thr = round(low_thr,2)                               \n",
    "            high_thr = round(high_thr,2) \n",
    "            print(\"**********************************************************\")\n",
    "            print(\"Evaluating thresholds: \" + str(low_thr) + \"-\" + str(high_thr))\n",
    "            print(\"**********************************************************\")\n",
    "\n",
    "            if low_thr >= high_thr:\n",
    "                continue\n",
    "\n",
    "            pred_list = [os.path.join(save_pred_table_test_path,file_ID.split(\".\")[0]  + \"_CALLTYPE_PRED_TABLE_thr_\" + str(low_thr) + \"-\" + str(high_thr) + \".txt\" ) for file_ID in file_ID_list ]\n",
    "            evaluation = metrics.Evaluate(label_list = labels_list, \n",
    "                                          prediction_list = pred_list, \n",
    "                                          noise_label = \"noise\", \n",
    "                                          IoU_threshold = 0.2, \n",
    "                                          call_analysis = eval_analysis, \n",
    "                                          GT_proportion_cut = 0.01, \n",
    "                                          no_call = no_call,\n",
    "                                          headers = set(['Label', 'Duration', 'Start', 'End']),\n",
    "                                          nonfoc_tags =[\"NONFOC\", \"nf\", \"*\"]\n",
    "                                         ) # 0.99 is 0.5\n",
    "            output, skipped_calls = evaluation.main()        \n",
    "            print(str(skipped_calls) + \" calls were skipped in total\")\n",
    "\n",
    "            to_pickle = [\"Time_Difference\", \"Matching_Table\", \"Prediction_Indices\", \"Label_Indices\" , \"_Match\"]\n",
    "            for metric in output.keys():\n",
    "                if any(ext in metric for ext in to_pickle):\n",
    "                    filename = \"PRED_TABLE_thr_\" + str(low_thr) + \"-\" + str(high_thr) + \"_\" +str(metric) +\".p\"\n",
    "                    with open(os.path.join(save_metrics_path_eval, filename), 'wb') as fp:\n",
    "                        pickle.dump(output[metric], fp) \n",
    "                else:\n",
    "                    filename = \"PRED_TABLE_thr_\" + str(low_thr) + \"-\" + str(high_thr) + \"_\" +str(metric) +\".csv\"\n",
    "                    output[metric].to_csv(os.path.join(save_metrics_path_eval, filename))    \n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    # PLOT A PREDICTION\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    pool = audiopool.AudioPool() \n",
    "\n",
    "    # Find a call\n",
    "    call = testing_label_dict[\"sn\"].iloc[15]\n",
    "    label_subset = testing_label_table[testing_label_table['wav_path'].isin([call[\"wav_path\"]])]\n",
    "\n",
    "    # set the labels\n",
    "    label_list = list(call_types.keys())\n",
    "    if other_ignored_in_training:\n",
    "        label_list.remove(label_for_other)\n",
    "\n",
    "\n",
    "    # randomise the start a little so the new spectrogram will be a little different from the old\n",
    "    # if the call is very long have a large range to draw the window\n",
    "    if call[\"Duration\"]>= spec_window_size:\n",
    "        call_start = round(float(np.random.uniform(call[\"Start\"]-spec_window_size/2, \n",
    "                                                   call[\"End\"]-spec_window_size/2, 1)), 3)\n",
    "    # if the call is short call, draw it from somewhere\n",
    "    else:\n",
    "        call_start = round(float(np.random.uniform((call[\"Start\"]+call[\"End\"])/2-spec_window_size, \n",
    "                                                   (call[\"Start\"]+call[\"End\"])/2)), 3)\n",
    "\n",
    "    # load in a subsection of the spectrogram\n",
    "    # y, sr = librosa.load(call[\"wav_path\"], sr=None, mono=False,\n",
    "    #                      offset = call_start, duration =self.spec_window_size)\n",
    "    y = pool.get_seconds(call[\"wav_path\"], call_start, spec_window_size)\n",
    "    sr = pool.get_Fs(call[\"wav_path\"])\n",
    "\n",
    "    call_stop = round(call_start + spec_window_size,3 )\n",
    "\n",
    "    # have it as an array\n",
    "    data_subset = np.asfortranarray(y)\n",
    "\n",
    "    #get the spectrogram\n",
    "    spectrogram = pre.generate_mel_spectrogram(data_subset, sr, 0, spec_window_size, \n",
    "                                               n_mels, window, fft_win , fft_hop , normalise)\n",
    "\n",
    "    # generate label\n",
    "    label = pre.create_label_matrix(label_subset, \n",
    "                                    spectrogram, \n",
    "                                    testing_label_dict, \n",
    "                                    call_start, \n",
    "                                    call_stop, \n",
    "                                    label_for_noise, \n",
    "                                    label_for_other, \n",
    "                                    other_ignored_in_training)\n",
    "    # plot spectrogram\n",
    "    plt.figure(figsize=(10,4))\n",
    "    #plt.subplot(411)\n",
    "    yaxis = range(0, np.flipud(spectrogram).shape[0]+1)\n",
    "    xaxis = range(0, np.flipud(spectrogram).shape[1]+1)\n",
    "    plt.xticks(np.arange(0, np.flipud(label).shape[1]+1,50),\n",
    "               list(label.columns[np.arange(0, np.flipud(label).shape[1]+1,50)]))\n",
    "    librosa.display.specshow(spectrogram,  y_axis='mel', x_coords = label.columns)#, x_axis= \"time\",sr=sr, x_coords = label.columns)\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.clim(-35, 35)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.show()\n",
    "\n",
    "    # plot LABEL\n",
    "    #plt.subplot(412)\n",
    "    #print(label.shape)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    xaxis = range(0, np.flipud(label).shape[1]+1)\n",
    "    yaxis = range(0, np.flipud(label).shape[0]+1)\n",
    "    plt.yticks(np.arange(0.5, len(label_list)+0.5 ,1 ),reversed(label_list))\n",
    "    plt.xticks(np.arange(0, np.flipud(label).shape[1]+1,50),\n",
    "               list(label.columns[np.arange(0, np.flipud(label).shape[1]+1,50)]))\n",
    "    plt.pcolormesh(xaxis, yaxis, np.flipud(label))\n",
    "    plt.clim(0, 1)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Calltype')\n",
    "    plt.colorbar(label=\"Label\")\n",
    "    plt.show()\n",
    "\n",
    "    if is_forked:\n",
    "        # generate matrix of call/not call\n",
    "        callmat = pre.create_call_matrix(label_subset, spectrogram, call_start, call_stop, \n",
    "                                          label_for_noise, label_for_other, other_ignored_in_training)\n",
    "\n",
    "    # prediction\n",
    "    # transpose it and put it in a format that works with the NN\n",
    "    spec = spectrogram.T\n",
    "    spec = spec[np.newaxis, ..., np.newaxis]  \n",
    "\n",
    "    # generate a mask (as a placeholder) but don't mask anything as we are predicting and want to include other\n",
    "    mask = np.asarray([True for i in range(spectrogram.shape[1])])\n",
    "    mask = mask[np.newaxis,...]\n",
    "\n",
    "    # generate the prediction\n",
    "    pred = RNN_model.predict([spec,mask])\n",
    "\n",
    "    # add this prediction to the stack that will be used to generate the predictions table\n",
    "    if is_forked:\n",
    "        calltype_pred= pred[0]\n",
    "        callpresence_pred = pred[1]   \n",
    "    else:\n",
    "        calltype_pred = pred\n",
    "\n",
    "    pred = calltype_pred[0].Ttra\n",
    "\n",
    "    #print(pred.shape)\n",
    "    #plot calltype prediction\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    xaxis = range(0, np.flipud(label).shape[1]+1)\n",
    "    yaxis = range(0, np.flipud(label).shape[0]+1)\n",
    "    plt.yticks(np.arange(0.5, len(label_list)+0.5 ,1 ),reversed(label_list))\n",
    "    plt.xticks(np.arange(0, np.flipud(label).shape[1]+1,50),\n",
    "               list(label.columns[np.arange(0, np.flipud(label).shape[1]+1,50)]))\n",
    "    plt.pcolormesh(xaxis, yaxis, np.flipud(pred))\n",
    "    plt.clim(0, 1)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Calltype Prediction')\n",
    "    plt.colorbar(label=\"Label\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    if is_forked:  \n",
    "        # plot call matrix\n",
    "        #plt.subplot(413)\n",
    "        plt.figure(figsize=(10, 1))\n",
    "        xaxis = range(0, np.flipud(label).shape[1]+1)\n",
    "        yaxis = range(0, np.flipud(callmat).shape[0]+1)\n",
    "        plt.yticks(np.arange(0.5, callmat.shape[0]+0.5 ,1 ), reversed(callmat.index.values))\n",
    "        plt.xticks(np.arange(0, np.flipud(label).shape[1]+1,50),\n",
    "                   list(label.columns[np.arange(0, np.flipud(label).shape[1]+1,50)]))\n",
    "        plt.pcolormesh(xaxis, yaxis, np.flipud(callmat))\n",
    "        plt.clim(0, 1)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Call / No Call')\n",
    "        plt.colorbar(label=\"Label\")\n",
    "        plt.show()\n",
    "\n",
    "        pred = callpresence_pred[0].T\n",
    "        #plot prediction\n",
    "        plt.figure(figsize=(10, 1))\n",
    "        xaxis = range(0, np.flipud(label).shape[1]+1)\n",
    "        yaxis = range(0, np.flipud(callmat).shape[0]+1)\n",
    "        plt.yticks(np.arange(0.5, callmat.shape[0]+0.5 ,1 ), reversed(callmat.index.values))\n",
    "        plt.xticks(np.arange(0, np.flipud(label).shape[1]+1,50),\n",
    "                   list(label.columns[np.arange(0, np.flipud(label).shape[1]+1,50)]))\n",
    "        plt.pcolormesh(xaxis, yaxis, np.flipud(pred))\n",
    "        plt.clim(0, 1)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Call / No Call prediction')\n",
    "        plt.colorbar(label=\"Label\")\n",
    "        plt.show()\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    # CONFUSION MATRIX\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "\n",
    "    # loop over the threaholdsf\n",
    "    for low_thr in [0.1]:#[0.05,0.1,0.2]:\n",
    "        for high_thr in [0.6]:#[0.5,0.6,0.7,0.8,0.9,0.95]:         \n",
    "            #########################################\n",
    "            # FORMAT \n",
    "\n",
    "            low_thr = round(low_thr,2)                               \n",
    "            high_thr = round(high_thr,2) \n",
    "\n",
    "            if low_thr >= high_thr:\n",
    "                continue\n",
    "            if low_thr == 0.1 and high_thr == 0.2:\n",
    "                continue\n",
    "\n",
    "            if eval_analysis == \"normal\":\n",
    "                confusion_filename = os.path.join(save_metrics_path_eval, \"PRED_TABLE_thr_\" + str(low_thr) + \"-\" + str(high_thr) + '_foc_Confusion_Matrix.csv')\n",
    "            else:\n",
    "                confusion_filename = os.path.join(save_metrics_path_eval, \"PRED_TABLE_thr_\" + str(low_thr) + \"-\" + str(high_thr) + '__Confusion_Matrix.csv')\n",
    "            with open(confusion_filename, newline='') as csvfile:\n",
    "                array = list(csv.reader(csvfile))\n",
    "\n",
    "            df_cm = pd.DataFrame(array) #, range(6), range(6))    \n",
    "\n",
    "            # get rid of the weird indentations and make rows and columns as names\n",
    "            new_col = df_cm.iloc[0] # grab the first row for the header\n",
    "            df_cm = df_cm[1:] # take the data less the header row\n",
    "            df_cm.columns = new_col # set the header row as the df header    \n",
    "            new_row = df_cm['']\n",
    "            df_cm = df_cm.drop('', 1)\n",
    "            df_cm.index = new_row\n",
    "            df_cm.index.name= None\n",
    "            df_cm.columns.name= None\n",
    "\n",
    "            # # replace FP and FN with noise\n",
    "            df_cm['noise'] = df_cm['FN'] \n",
    "            #df_cm.loc['noise']=df_cm.loc['FP']\n",
    "\n",
    "            # remove FP and FN\n",
    "            df_cm = df_cm.drop(\"FN\", axis=1)\n",
    "            #df_cm = df_cm.drop(\"FP\", axis=0)\n",
    "\n",
    "            df_cm = df_cm.apply(pd.to_numeric)\n",
    "\n",
    "            # Raw confusion matrix\n",
    "            df_cm = df_cm[list(testing_label_dict.keys())]\n",
    "            df_cm = df_cm.reindex(list(testing_label_dict.keys()))       \n",
    "\n",
    "            #########################################\n",
    "            # CALCULATE\n",
    "\n",
    "            # Recall confusion matrix\n",
    "            df_recall = df_cm.div(df_cm.sum(axis=1), axis=0).round(2)#pd.DataFrame(df_cm.values / df_cm.sum(axis=1).values).round(2)\n",
    "\n",
    "            # Proportion of calls for confusion matrix\n",
    "            call_len = list()\n",
    "            for i in testing_label_dict.keys():\n",
    "                call_len.append(testing_label_dict[i].shape[0])\n",
    "            # add noise at the end\n",
    "            call_len[-1] = df_cm.sum(axis=1)[-1]\n",
    "\n",
    "            #proportion of calls\n",
    "            df_prop = df_cm.div(call_len, axis=0).round(2)#pd.DataFrame(df_cm.values / df_cm.sum(axis=1).values).round(2)\n",
    "\n",
    "            #########################################\n",
    "            # PLOT\n",
    "\n",
    "            #multi figure parameters\n",
    "            fig,((ax1,ax2,ax3)) = plt.subplots(1,3, figsize=(20,5))\n",
    "            fig.suptitle(str(low_thr) + \" - \" + str(high_thr))\n",
    "\n",
    "            # plot raw\n",
    "            sn.set(font_scale=1.1) # for label size\n",
    "            sn.heatmap((df_cm+1), annot=df_cm, fmt='g',norm = LogNorm(), annot_kws={\"size\": 10}, ax= ax1) # font size\n",
    "            ax1.set_title(\"Raw\")              \n",
    "\n",
    "            # plot recall\n",
    "            sn.set(font_scale=1.1) # for label size\n",
    "            sn.heatmap((df_recall), annot=True, fmt='g', annot_kws={\"size\": 10}, ax= ax2) # font size\n",
    "            ax2.set_title(\"Recall\" )\n",
    "\n",
    "            # plot proportion of calls\n",
    "            sn.set(font_scale=1.1) # for label size\n",
    "            sn.heatmap((df_prop), annot=True, fmt='g', annot_kws={\"size\": 10}, ax= ax3) # font size\n",
    "            ax3.set_title(\"Call Prop\")\n",
    "\n",
    "            # Save 3 panels\n",
    "            plt.savefig(os.path.join(save_metrics_path, eval_analysis, \"Confusion_mat_thr_\" + str(low_thr) + \"-\" + str(high_thr) + '.png'))\n",
    "            plt.show()\n",
    "            plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML1_env",
   "language": "python",
   "name": "ml1_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
