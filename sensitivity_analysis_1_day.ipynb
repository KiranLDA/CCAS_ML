{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENSITIVITY ANALYSES\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n",
      "/home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kiran/Documents/github/CCAS_ML/postprocess/evaluation_metrics_functions_old.py:10: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/Documents/github/CCAS_ML/postprocess/evaluation_metrics_functions_old.py:12: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "github_dir = \"/home/kiran/Documents/github/CCAS_ML\"\n",
    "\n",
    "# add path to local functions\n",
    "import os\n",
    "os.chdir(github_dir)\n",
    "\n",
    "# import all the params for this model\n",
    "from example_params import *\n",
    "is_forked = True # is going to need to go into the params file\n",
    "\n",
    "# import own functions\n",
    "import preprocess.preprocess_functions as pre\n",
    "import postprocess.evaluation_metrics_functions_old as metrics\n",
    "import postprocess.merge_predictions_functions as ppm\n",
    "import model.specgen_batch_generator as bg\n",
    "import model.network_class as rnn\n",
    "# import postprocess.visualise_prediction_functions as pp\n",
    "from model.callback_functions import LossHistory\n",
    "import model.audiopool as audiopool\n",
    "\n",
    "# import normal packages used in pre-processing\n",
    "import numpy as np\n",
    "import librosa\n",
    "import warnings\n",
    "import ntpath\n",
    "import os\n",
    "from itertools import compress  \n",
    "from random import random, shuffle\n",
    "from math import floor\n",
    "import statistics\n",
    "import glob\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML section packages\n",
    "import datetime\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Flatten\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, SeparableConv2D, concatenate\n",
    "from keras.layers import Reshape, Permute\n",
    "from keras.layers import TimeDistributed, Dense, Dropout, BatchNormalization\n",
    "from keras.models import load_model\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling2D\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# postprocessfrom decimal import Decimal\n",
    "from decimal import Decimal\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# evaluate and plot \n",
    "import seaborn as sn\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------\n",
    "# PREPROCESSING / DATA WRANGLING\n",
    "\n",
    "Currently, all the meerkat files are found on the server. The labels in particular are divided by year (currently 2017 and 2019) and all file labels are in a single document. This bit of code just takes these and puts them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all the synched label files together\n",
    "labels_all = pd.DataFrame()\n",
    "for directory in label_dirs:\n",
    "    for group in group_IDs:\n",
    "        temp = pd.read_csv(os.path.join(directory, group +\"_ALL_CALLS_SYNCHED.csv\"), sep=sep,\n",
    "                       header=0, engine = engine, encoding = encoding) \n",
    "        temp[\"group\"] = group\n",
    "        labels_all = pd.concat([labels_all, temp]) \n",
    "        del temp\n",
    "\n",
    "labels_all = labels_all[-labels_all.wavFileName.str.contains('SOUNDFOC')]\n",
    "labels_all = labels_all.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data also contain focal follows (someone walking around behind the meerkats) and the resultion of this data is different and therefore not anlysed with the collar data (but could be done separately or put to the same resolution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset all the audio files that we should use in the analysis (i.e. not focal follow data)\n",
    "audio_files = list(set(labels_all[\"wavFileName\"]))\n",
    "audio_filenames = list(compress(audio_files, [\"SOUNDFOC\" not in filei for filei in audio_files]))\n",
    "\n",
    "# subset all the audio files that we should use in the analysis (i.e. not focal follow data)\n",
    "label_files = list(set(labels_all[\"csvFileName\"]))\n",
    "label_filenames = list(compress(label_files, [\"SOUNDFOC\" not in filei for filei in label_files]))\n",
    "\n",
    "# get the file IDS without all the extentions (used later for naming)\n",
    "all_filenames = [audio_filenames[i].split(\".\")[0] for i in range(0,len(audio_filenames))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we locate all the paths to the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all the labels\n",
    "EXT = \"*.csv\"\n",
    "label_filepaths = []\n",
    "for PATH in acoustic_data_path :\n",
    "      label_filepaths.extend( [file for path, subdir, files in os.walk(PATH) for file in glob.glob(os.path.join(path, EXT))])\n",
    "EXT = \"*.CSV\"\n",
    "for PATH in acoustic_data_path :\n",
    "      label_filepaths.extend( [file for path, subdir, files in os.walk(PATH) for file in glob.glob(os.path.join(path, EXT))])\n",
    "\n",
    "# find all audio paths (will be longer than label path as not everything is labelled)\n",
    "audio_filepaths = []\n",
    "EXT = \"*.wav\"\n",
    "for PATH in audio_dirs:\n",
    "      audio_filepaths.extend( [file for path, subdir, files in os.walk(PATH) for file in glob.glob(os.path.join(path, EXT))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a label table\n",
    "\n",
    "Currently, the labels are stored in a file generated by audition for the meerkats. We want to these manual labels and put them into a more meaningful categories for for the machine learning. To set categories, I use a pre-defined dictionary called call_types that is defined in the parameters file and which specifies what the different classes are for the call types. Anything strange gets put into a category \"oth\" for other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This label 'c' on line 5909 will be classed as 'oth'\n",
      "This label 'c' on line 7266 will be classed as 'oth'\n",
      "This label 'cn' on line 7921 will be classed as 'oth'\n",
      "This label 'chew' on line 8385 will be classed as 'oth'\n",
      "This label 'sb' on line 8504 will be classed as 'oth'\n",
      "This label 'chew' on line 8782 will be classed as 'oth'\n",
      "This label 'chew' on line 8862 will be classed as 'oth'\n",
      "This label 'chew' on line 8886 will be classed as 'oth'\n",
      "This label 'chew' on line 8887 will be classed as 'oth'\n",
      "This label 'chew' on line 8890 will be classed as 'oth'\n",
      "This label 'chew' on line 8914 will be classed as 'oth'\n",
      "This label 'chew' on line 8933 will be classed as 'oth'\n",
      "This label 'chew' on line 8962 will be classed as 'oth'\n",
      "This label 'chew' on line 9008 will be classed as 'oth'\n",
      "This label 'chew' on line 9011 will be classed as 'oth'\n",
      "This label 'chew' on line 9045 will be classed as 'oth'\n",
      "This label 'chew' on line 9046 will be classed as 'oth'\n",
      "This label 'chew' on line 9243 will be classed as 'oth'\n",
      "This label 'chew' on line 9249 will be classed as 'oth'\n",
      "This label 'chew' on line 9268 will be classed as 'oth'\n",
      "This label 'chew' on line 9697 will be classed as 'oth'\n",
      "This label 'chew' on line 9842 will be classed as 'oth'\n",
      "This label 'chew' on line 9861 will be classed as 'oth'\n",
      "This label 'chew' on line 10115 will be classed as 'oth'\n",
      "This label 'chew' on line 10139 will be classed as 'oth'\n",
      "This label 'chew' on line 10141 will be classed as 'oth'\n",
      "This label '01:48:00' on line 11666 will be classed as 'oth'\n",
      "This label 'c' on line 13383 will be classed as 'oth'\n",
      "This label 'nan' on line 13960 will be classed as 'oth'\n",
      "This label 'sec nf' on line 18832 will be classed as 'oth'\n",
      "This label 'sec nf' on line 18833 will be classed as 'oth'\n",
      "This label '02:10:30' on line 18901 will be classed as 'oth'\n",
      "This label 'c' on line 18911 will be classed as 'oth'\n",
      "This label 'skioff' on line 20569 will be classed as 'oth'\n",
      "This label 'sycnh 02:19:30' on line 20865 will be classed as 'oth'\n",
      "This label 'al*' on line 20955 will be classed as 'oth'\n",
      "This label 'al*' on line 20961 will be classed as 'oth'\n",
      "This label 'al*' on line 20964 will be classed as 'oth'\n",
      "This label 'al*' on line 20965 will be classed as 'oth'\n",
      "This label 'al*' on line 24039 will be classed as 'oth'\n",
      "This label 'al*' on line 24040 will be classed as 'oth'\n",
      "This label 'al*' on line 24041 will be classed as 'oth'\n",
      "This label 'al*' on line 24042 will be classed as 'oth'\n",
      "This label 'al*' on line 24043 will be classed as 'oth'\n",
      "This label 'al*' on line 24044 will be classed as 'oth'\n",
      "This label 'al*' on line 24045 will be classed as 'oth'\n",
      "This label 'al*' on line 24046 will be classed as 'oth'\n",
      "This label 'al*' on line 24047 will be classed as 'oth'\n",
      "This label 'al*' on line 24048 will be classed as 'oth'\n",
      "This label 'al*' on line 24049 will be classed as 'oth'\n",
      "This label 'al*' on line 24050 will be classed as 'oth'\n",
      "This label 'al*' on line 24051 will be classed as 'oth'\n",
      "This label 'al*' on line 24052 will be classed as 'oth'\n",
      "This label 'al*' on line 24053 will be classed as 'oth'\n",
      "This label 'sycnh 01:33:00' on line 24363 will be classed as 'oth'\n",
      "This label 'sipoff' on line 24709 will be classed as 'oth'\n",
      "This label 'sycnh 01:52:30' on line 28198 will be classed as 'oth'\n",
      "This label 'bark' on line 29020 will be classed as 'oth'\n",
      "This label 'bark' on line 29021 will be classed as 'oth'\n",
      "This label 'bark' on line 29022 will be classed as 'oth'\n",
      "This label 'bark' on line 29023 will be classed as 'oth'\n",
      "This label 'bark' on line 29036 will be classed as 'oth'\n",
      "This label 'bark' on line 29037 will be classed as 'oth'\n",
      "This label 'bark' on line 29038 will be classed as 'oth'\n",
      "This label 'bark' on line 29039 will be classed as 'oth'\n",
      "This label 'bark' on line 29040 will be classed as 'oth'\n",
      "This label 'c nf' on line 35932 will be classed as 'oth'\n",
      "This label '*' on line 36974 will be classed as 'oth'\n",
      "This label 'a nf' on line 39336 will be classed as 'oth'\n",
      "This label 'a nf' on line 39341 will be classed as 'oth'\n",
      "This label 'sl nf' on line 41917 will be classed as 'oth'\n",
      "This label 'sycnh 01:54:00' on line 42347 will be classed as 'oth'\n",
      "This label 'x' on line 42884 will be classed as 'oth'\n",
      "This label 'x' on line 42885 will be classed as 'oth'\n",
      "This label 'c nf' on line 48881 will be classed as 'oth'\n",
      "This label 'x' on line 52411 will be classed as 'oth'\n",
      "This label 'sx' on line 56653 will be classed as 'oth'\n",
      "This label 'pause' on line 57305 will be classed as 'oth'\n",
      "This label 'sc f' on line 58244 will be classed as 'oth'\n",
      "This label 'eating' on line 58754 will be classed as 'oth'\n",
      "This label 'eating' on line 58755 will be classed as 'oth'\n",
      "This label 'eating' on line 58769 will be classed as 'oth'\n",
      "This label 'eating' on line 58787 will be classed as 'oth'\n",
      "This label 'x' on line 58883 will be classed as 'oth'\n",
      "This label 'x' on line 58966 will be classed as 'oth'\n",
      "This label 'x' on line 59953 will be classed as 'oth'\n",
      "This label 'eating' on line 59957 will be classed as 'oth'\n",
      "This label 'eating' on line 59964 will be classed as 'oth'\n",
      "This label 'x' on line 59967 will be classed as 'oth'\n",
      "This label 'x' on line 59998 will be classed as 'oth'\n",
      "This label 'c nf' on line 60461 will be classed as 'oth'\n",
      "This label 'x' on line 60749 will be classed as 'oth'\n",
      "This label 'x' on line 60751 will be classed as 'oth'\n",
      "This label 'x' on line 60754 will be classed as 'oth'\n",
      "This label 'x' on line 60768 will be classed as 'oth'\n",
      "This label 'x nf' on line 60775 will be classed as 'oth'\n",
      "This label 'x' on line 60780 will be classed as 'oth'\n",
      "This label 'x' on line 60788 will be classed as 'oth'\n",
      "This label 'x nf' on line 60797 will be classed as 'oth'\n",
      "This label 'x nf' on line 60813 will be classed as 'oth'\n",
      "This label 'x' on line 60819 will be classed as 'oth'\n",
      "This label 'x' on line 60838 will be classed as 'oth'\n",
      "This label 'x nf' on line 60842 will be classed as 'oth'\n",
      "This label 'x nf' on line 60862 will be classed as 'oth'\n",
      "This label 'x nf' on line 60893 will be classed as 'oth'\n",
      "This label 'x' on line 60895 will be classed as 'oth'\n",
      "This label 'x nf' on line 60902 will be classed as 'oth'\n",
      "This label 'x nf' on line 60905 will be classed as 'oth'\n",
      "This label '01:25:30' on line 60967 will be classed as 'oth'\n",
      "This label 'na' on line 61781 will be classed as 'oth'\n",
      "This label 'na' on line 61788 will be classed as 'oth'\n",
      "This label 'na' on line 61801 will be classed as 'oth'\n",
      "This label 'na' on line 61810 will be classed as 'oth'\n",
      "This label 'na' on line 62008 will be classed as 'oth'\n",
      "This label 'na' on line 62010 will be classed as 'oth'\n",
      "This label 'na' on line 62018 will be classed as 'oth'\n",
      "This label 'na' on line 62083 will be classed as 'oth'\n",
      "This label 'na' on line 62089 will be classed as 'oth'\n",
      "This label 'na' on line 62131 will be classed as 'oth'\n",
      "This label 'na' on line 62212 will be classed as 'oth'\n",
      "This label 'na' on line 62278 will be classed as 'oth'\n",
      "This label 'na' on line 62313 will be classed as 'oth'\n",
      "This label 'na' on line 62334 will be classed as 'oth'\n",
      "This label 'x' on line 62801 will be classed as 'oth'\n",
      "This label 'x' on line 62843 will be classed as 'oth'\n",
      "This label 'x' on line 63121 will be classed as 'oth'\n",
      "This label 'x' on line 63150 will be classed as 'oth'\n",
      "This label 'x' on line 63166 will be classed as 'oth'\n",
      "This label 'x' on line 63167 will be classed as 'oth'\n",
      "This label 'x' on line 63169 will be classed as 'oth'\n",
      "This label 'x' on line 63211 will be classed as 'oth'\n",
      "This label 'x' on line 63227 will be classed as 'oth'\n",
      "This label 'x' on line 63228 will be classed as 'oth'\n",
      "This label 'x' on line 63270 will be classed as 'oth'\n",
      "This label 'x' on line 63297 will be classed as 'oth'\n",
      "This label 'x' on line 63298 will be classed as 'oth'\n",
      "This label 'x' on line 63299 will be classed as 'oth'\n",
      "This label 'x' on line 63364 will be classed as 'oth'\n",
      "This label 'x' on line 63365 will be classed as 'oth'\n",
      "This label 'x' on line 65639 will be classed as 'oth'\n",
      "This label 'x' on line 65853 will be classed as 'oth'\n",
      "This label 'x' on line 65914 will be classed as 'oth'\n",
      "This label 'x' on line 66025 will be classed as 'oth'\n",
      "This label 'x' on line 66037 will be classed as 'oth'\n",
      "This label 'x' on line 67731 will be classed as 'oth'\n",
      "This label 'x' on line 67988 will be classed as 'oth'\n",
      "This label 'x' on line 68145 will be classed as 'oth'\n",
      "This label 'x' on line 68147 will be classed as 'oth'\n",
      "This label 'c nf' on line 68296 will be classed as 'oth'\n",
      "This label 'x' on line 68623 will be classed as 'oth'\n",
      "This label 's%' on line 70493 will be classed as 'oth'\n",
      "This label 'chuck' on line 70624 will be classed as 'oth'\n",
      "This label 'x' on line 70797 will be classed as 'oth'\n",
      "This label 'x' on line 70864 will be classed as 'oth'\n",
      "This label 'synh 01:30:00' on line 71367 will be classed as 'oth'\n",
      "This label 'sych 01:51:00' on line 71771 will be classed as 'oth'\n",
      "This label 'x' on line 72514 will be classed as 'oth'\n",
      "This label 'digging' on line 72739 will be classed as 'oth'\n",
      "This label 'digging' on line 72742 will be classed as 'oth'\n",
      "This label 'chew' on line 72830 will be classed as 'oth'\n",
      "This label 'chew' on line 72831 will be classed as 'oth'\n",
      "This label 'chew' on line 72832 will be classed as 'oth'\n",
      "This label 'x' on line 73049 will be classed as 'oth'\n",
      "This label 'x' on line 73079 will be classed as 'oth'\n",
      "This label 'x' on line 73122 will be classed as 'oth'\n",
      "This label 'x' on line 73210 will be classed as 'oth'\n",
      "This label 'x' on line 73293 will be classed as 'oth'\n",
      "This label 'x' on line 73408 will be classed as 'oth'\n",
      "This label '//' on line 73532 will be classed as 'oth'\n",
      "This label 'x' on line 75030 will be classed as 'oth'\n",
      "This label 'x' on line 75779 will be classed as 'oth'\n",
      "This label 'x' on line 77275 will be classed as 'oth'\n",
      "This label 'sycnh 01:54:00' on line 78537 will be classed as 'oth'\n",
      "This label 'aynxh 01:28:30' on line 79388 will be classed as 'oth'\n",
      "This label 'x' on line 80243 will be classed as 'oth'\n",
      "This label 'x' on line 83435 will be classed as 'oth'\n",
      "This label 'x' on line 83509 will be classed as 'oth'\n",
      "This label 'x' on line 83552 will be classed as 'oth'\n",
      "This label 'x' on line 83566 will be classed as 'oth'\n",
      "This label 'x' on line 83592 will be classed as 'oth'\n",
      "This label 'x' on line 83931 will be classed as 'oth'\n",
      "This label 'x' on line 84215 will be classed as 'oth'\n",
      "This label 'x' on line 85322 will be classed as 'oth'\n",
      "This label 'x' on line 85617 will be classed as 'oth'\n",
      "This label 'x' on line 85781 will be classed as 'oth'\n",
      "This label 'x' on line 86656 will be classed as 'oth'\n",
      "This label 'ññ' on line 86881 will be classed as 'oth'\n",
      "This label 'ññ x' on line 86947 will be classed as 'oth'\n",
      "This label '××' on line 87072 will be classed as 'oth'\n",
      "This label 'x' on line 87797 will be classed as 'oth'\n",
      "This label 'x' on line 88121 will be classed as 'oth'\n",
      "This label 'x' on line 88202 will be classed as 'oth'\n",
      "This label 'x' on line 88344 will be classed as 'oth'\n",
      "This label 'x' on line 88345 will be classed as 'oth'\n",
      "This label 'x' on line 88346 will be classed as 'oth'\n",
      "This label 'x' on line 88347 will be classed as 'oth'\n",
      "This label 'x' on line 88348 will be classed as 'oth'\n",
      "This label 'x' on line 89306 will be classed as 'oth'\n",
      "This label 'x' on line 90705 will be classed as 'oth'\n",
      "This label 'x' on line 90839 will be classed as 'oth'\n",
      "This label 'x' on line 90876 will be classed as 'oth'\n",
      "This label 'eating' on line 91077 will be classed as 'oth'\n",
      "This label 'x' on line 91353 will be classed as 'oth'\n",
      "This label 'x' on line 91441 will be classed as 'oth'\n",
      "This label 'x' on line 91539 will be classed as 'oth'\n",
      "This label 'x' on line 94315 will be classed as 'oth'\n",
      "This label 'x' on line 94518 will be classed as 'oth'\n",
      "This label 'x' on line 94619 will be classed as 'oth'\n",
      "This label 'eating' on line 94647 will be classed as 'oth'\n",
      "This label 'x' on line 94842 will be classed as 'oth'\n",
      "This label 'x' on line 95690 will be classed as 'oth'\n",
      "This label 'x' on line 96271 will be classed as 'oth'\n",
      "This label 'x' on line 96343 will be classed as 'oth'\n",
      "This label 'x' on line 96477 will be classed as 'oth'\n",
      "This label 'm nf' on line 96720 will be classed as 'oth'\n",
      "This label 'x' on line 96829 will be classed as 'oth'\n",
      "This label 'sc x nf' on line 96967 will be classed as 'oth'\n",
      "This label 'x' on line 97193 will be classed as 'oth'\n",
      "This label 'x' on line 97269 will be classed as 'oth'\n",
      "This label 'x' on line 97683 will be classed as 'oth'\n",
      "This label 'x' on line 98091 will be classed as 'oth'\n",
      "This label 'x' on line 98219 will be classed as 'oth'\n",
      "This label 'x' on line 98336 will be classed as 'oth'\n",
      "This label 'x' on line 98966 will be classed as 'oth'\n",
      "This label 'x' on line 99083 will be classed as 'oth'\n",
      "This label 'x' on line 100462 will be classed as 'oth'\n",
      "This label 'x' on line 101041 will be classed as 'oth'\n",
      "This label 'x' on line 101143 will be classed as 'oth'\n",
      "This label 'x' on line 102516 will be classed as 'oth'\n",
      "This label 'x' on line 102517 will be classed as 'oth'\n",
      "This label 'x' on line 102967 will be classed as 'oth'\n",
      "This label 'x' on line 104656 will be classed as 'oth'\n",
      "This label 'x' on line 105866 will be classed as 'oth'\n",
      "This label 'eating' on line 105922 will be classed as 'oth'\n",
      "This label 'eating' on line 105926 will be classed as 'oth'\n",
      "This label 'eating' on line 106028 will be classed as 'oth'\n",
      "This label 'x' on line 106225 will be classed as 'oth'\n",
      "This label 'eating' on line 106243 will be classed as 'oth'\n",
      "This label 'x' on line 107506 will be classed as 'oth'\n",
      "This label 'x' on line 108812 will be classed as 'oth'\n",
      "This label 'x' on line 108891 will be classed as 'oth'\n",
      "This label 'x' on line 108923 will be classed as 'oth'\n",
      "This label 'x' on line 109677 will be classed as 'oth'\n",
      "This label 'ññ' on line 110219 will be classed as 'oth'\n",
      "This label 'x' on line 110614 will be classed as 'oth'\n",
      "This label 'x' on line 110615 will be classed as 'oth'\n",
      "This label 'sycnh 01:36:00' on line 110670 will be classed as 'oth'\n",
      "This label 'ññ nf' on line 110822 will be classed as 'oth'\n",
      "This label 'ññ nf' on line 110823 will be classed as 'oth'\n",
      "This label 'x' on line 111526 will be classed as 'oth'\n",
      "This label 'beg nf' on line 111567 will be classed as 'oth'\n",
      "This label 'beg nf' on line 111568 will be classed as 'oth'\n",
      "This label 'beg nf' on line 111569 will be classed as 'oth'\n",
      "This label 'beg nf' on line 111570 will be classed as 'oth'\n",
      "This label 'beg nf' on line 111571 will be classed as 'oth'\n",
      "This label 'beg nf' on line 111572 will be classed as 'oth'\n",
      "This label 'beg nf' on line 111573 will be classed as 'oth'\n",
      "This label 'x' on line 111787 will be classed as 'oth'\n",
      "This label 'x' on line 111817 will be classed as 'oth'\n",
      "This label 'x' on line 111878 will be classed as 'oth'\n",
      "This label 'x' on line 111951 will be classed as 'oth'\n",
      "This label 'x' on line 112008 will be classed as 'oth'\n",
      "This label 'x' on line 112067 will be classed as 'oth'\n",
      "This label 'x' on line 112117 will be classed as 'oth'\n",
      "This label 'x' on line 112124 will be classed as 'oth'\n",
      "This label 'x' on line 112133 will be classed as 'oth'\n",
      "This label 'x' on line 112134 will be classed as 'oth'\n",
      "This label 'x' on line 112218 will be classed as 'oth'\n",
      "This label 'x' on line 112219 will be classed as 'oth'\n",
      "This label 'x' on line 112353 will be classed as 'oth'\n",
      "This label 'x' on line 112422 will be classed as 'oth'\n",
      "This label 'zz' on line 112442 will be classed as 'oth'\n",
      "This label 'x' on line 112528 will be classed as 'oth'\n",
      "This label 'x' on line 112541 will be classed as 'oth'\n",
      "This label 'x' on line 112602 will be classed as 'oth'\n",
      "This label 'x' on line 112608 will be classed as 'oth'\n",
      "This label 'x' on line 112761 will be classed as 'oth'\n",
      "This label 'x' on line 113297 will be classed as 'oth'\n",
      "This label 'x' on line 113436 will be classed as 'oth'\n",
      "This label 'cñ *' on line 113799 will be classed as 'oth'\n",
      "This label 'cñ nf' on line 113801 will be classed as 'oth'\n",
      "This label 'ññ nf' on line 113820 will be classed as 'oth'\n",
      "This label 'ññ nf' on line 113821 will be classed as 'oth'\n",
      "This label 'ññ nf' on line 113822 will be classed as 'oth'\n",
      "This label 'x' on line 114136 will be classed as 'oth'\n",
      "This label 'x' on line 114160 will be classed as 'oth'\n",
      "This label 'x' on line 114187 will be classed as 'oth'\n",
      "This label 'x' on line 114211 will be classed as 'oth'\n",
      "This label 'x' on line 114221 will be classed as 'oth'\n",
      "This label 'x' on line 114233 will be classed as 'oth'\n",
      "This label 'x' on line 114263 will be classed as 'oth'\n",
      "This label 'x' on line 114334 will be classed as 'oth'\n",
      "This label 'x' on line 114339 will be classed as 'oth'\n",
      "This label 'x' on line 114352 will be classed as 'oth'\n",
      "This label 'x' on line 114366 will be classed as 'oth'\n",
      "This label 'x' on line 114380 will be classed as 'oth'\n",
      "This label 'x' on line 114403 will be classed as 'oth'\n",
      "This label 'synhch 01:37:30' on line 115077 will be classed as 'oth'\n",
      "This label 'x' on line 115214 will be classed as 'oth'\n",
      "This label 'x' on line 115217 will be classed as 'oth'\n",
      "This label 'x' on line 115224 will be classed as 'oth'\n",
      "This label 'x' on line 115225 will be classed as 'oth'\n",
      "This label 'x' on line 115226 will be classed as 'oth'\n",
      "This label 'x' on line 115229 will be classed as 'oth'\n",
      "This label 'x' on line 115230 will be classed as 'oth'\n",
      "This label 'x' on line 115231 will be classed as 'oth'\n",
      "This label 'x' on line 115232 will be classed as 'oth'\n",
      "This label 'x' on line 115314 will be classed as 'oth'\n",
      "This label 'x' on line 115350 will be classed as 'oth'\n",
      "This label 'x' on line 115351 will be classed as 'oth'\n",
      "This label 'x' on line 115359 will be classed as 'oth'\n",
      "This label 'x' on line 115364 will be classed as 'oth'\n",
      "This label 'x' on line 115379 will be classed as 'oth'\n",
      "This label 'x' on line 115397 will be classed as 'oth'\n",
      "This label 'x' on line 115398 will be classed as 'oth'\n",
      "This label 'x' on line 115400 will be classed as 'oth'\n",
      "This label 'x' on line 115402 will be classed as 'oth'\n",
      "This label 'x' on line 115403 will be classed as 'oth'\n",
      "This label 'x' on line 115451 will be classed as 'oth'\n",
      "This label 'x' on line 115518 will be classed as 'oth'\n",
      "This label '*' on line 115630 will be classed as 'oth'\n",
      "This label 'a %' on line 115700 will be classed as 'oth'\n",
      "This label 'x' on line 115815 will be classed as 'oth'\n",
      "This label 'sic nf %' on line 116058 will be classed as 'oth'\n",
      "This label 'x' on line 116668 will be classed as 'oth'\n",
      "This label 'x' on line 117081 will be classed as 'oth'\n",
      "This label 'x' on line 117100 will be classed as 'oth'\n",
      "This label 'x' on line 117106 will be classed as 'oth'\n",
      "This label 'x' on line 117140 will be classed as 'oth'\n",
      "This label 'x' on line 117155 will be classed as 'oth'\n",
      "This label 'x' on line 117159 will be classed as 'oth'\n",
      "This label 'sic nf' on line 117230 will be classed as 'oth'\n",
      "This label 'x' on line 117442 will be classed as 'oth'\n",
      "This label 'x' on line 117674 will be classed as 'oth'\n",
      "This label 'x' on line 117686 will be classed as 'oth'\n",
      "This label 'x' on line 117709 will be classed as 'oth'\n",
      "This label 'x' on line 117751 will be classed as 'oth'\n",
      "This label 'x' on line 117792 will be classed as 'oth'\n",
      "This label 'x' on line 117835 will be classed as 'oth'\n",
      "This label 'bark' on line 117846 will be classed as 'oth'\n",
      "This label 'x' on line 118533 will be classed as 'oth'\n",
      "This label 'x' on line 118557 will be classed as 'oth'\n",
      "This label 'syn 01:30:30 x' on line 118629 will be classed as 'oth'\n",
      "This label 'x' on line 118848 will be classed as 'oth'\n",
      "This label 'x' on line 118909 will be classed as 'oth'\n",
      "This label 'x' on line 119023 will be classed as 'oth'\n",
      "This label 'x' on line 119026 will be classed as 'oth'\n",
      "This label 'x' on line 119150 will be classed as 'oth'\n",
      "This label 'ñ' on line 119641 will be classed as 'oth'\n",
      "This label 'x' on line 119675 will be classed as 'oth'\n",
      "This label 'x' on line 120118 will be classed as 'oth'\n",
      "This label 'x' on line 121013 will be classed as 'oth'\n",
      "This label 'x' on line 121140 will be classed as 'oth'\n",
      "This label 'x' on line 121169 will be classed as 'oth'\n",
      "This label 'x' on line 121173 will be classed as 'oth'\n",
      "This label 'x' on line 121176 will be classed as 'oth'\n",
      "This label 'x' on line 121386 will be classed as 'oth'\n",
      "This label 'x' on line 121442 will be classed as 'oth'\n",
      "This label 'x' on line 121501 will be classed as 'oth'\n",
      "This label 'x' on line 122123 will be classed as 'oth'\n",
      "This label 'x' on line 122194 will be classed as 'oth'\n",
      "This label 'x' on line 122425 will be classed as 'oth'\n",
      "This label 'x' on line 122461 will be classed as 'oth'\n",
      "This label 'x' on line 122489 will be classed as 'oth'\n",
      "This label 'x' on line 122490 will be classed as 'oth'\n",
      "This label 'x' on line 122494 will be classed as 'oth'\n",
      "This label 'x' on line 122500 will be classed as 'oth'\n",
      "This label 'x' on line 122501 will be classed as 'oth'\n",
      "This label 'x' on line 122519 will be classed as 'oth'\n",
      "This label 'x' on line 122561 will be classed as 'oth'\n",
      "This label 'x' on line 122570 will be classed as 'oth'\n",
      "This label 'x' on line 122578 will be classed as 'oth'\n",
      "This label 'x' on line 122579 will be classed as 'oth'\n",
      "This label 'x' on line 122591 will be classed as 'oth'\n",
      "This label 'x' on line 122595 will be classed as 'oth'\n",
      "This label 'x' on line 122605 will be classed as 'oth'\n",
      "This label '01:57:00' on line 122841 will be classed as 'oth'\n",
      "This label 'x' on line 123914 will be classed as 'oth'\n",
      "This label 'x' on line 124499 will be classed as 'oth'\n",
      "This label 'x' on line 124505 will be classed as 'oth'\n",
      "This label 'x' on line 124530 will be classed as 'oth'\n",
      "This label 'x' on line 124815 will be classed as 'oth'\n",
      "This label 'x' on line 125074 will be classed as 'oth'\n",
      "This label 'ññ *' on line 125163 will be classed as 'oth'\n",
      "This label 'ññ *' on line 125165 will be classed as 'oth'\n",
      "This label 'x' on line 125410 will be classed as 'oth'\n",
      "This label 'x' on line 128302 will be classed as 'oth'\n",
      "This label 'x' on line 128303 will be classed as 'oth'\n",
      "This label 'x' on line 128304 will be classed as 'oth'\n",
      "This label 'x' on line 129073 will be classed as 'oth'\n",
      "This label 'x' on line 129074 will be classed as 'oth'\n",
      "This label 'x' on line 129185 will be classed as 'oth'\n",
      "This label 'x' on line 129186 will be classed as 'oth'\n",
      "This label 'x' on line 129461 will be classed as 'oth'\n",
      "This label 'x' on line 129576 will be classed as 'oth'\n",
      "This label 'x' on line 129577 will be classed as 'oth'\n",
      "This label 'x' on line 129593 will be classed as 'oth'\n",
      "This label 'x' on line 129598 will be classed as 'oth'\n",
      "This label 'x' on line 129608 will be classed as 'oth'\n",
      "This label 'x' on line 129612 will be classed as 'oth'\n",
      "This label 'x' on line 129619 will be classed as 'oth'\n",
      "This label 'x' on line 129628 will be classed as 'oth'\n",
      "This label 'x' on line 129629 will be classed as 'oth'\n",
      "This label 'x' on line 130373 will be classed as 'oth'\n",
      "This label 'x' on line 130788 will be classed as 'oth'\n",
      "This label 'x' on line 131054 will be classed as 'oth'\n",
      "This label 'x' on line 131055 will be classed as 'oth'\n",
      "This label 'x' on line 131187 will be classed as 'oth'\n",
      "This label 'x' on line 131188 will be classed as 'oth'\n",
      "This label 'x' on line 131273 will be classed as 'oth'\n",
      "This label 'x' on line 131351 will be classed as 'oth'\n",
      "This label 'x' on line 131428 will be classed as 'oth'\n",
      "This label 'x' on line 131441 will be classed as 'oth'\n",
      "This label 'x' on line 131445 will be classed as 'oth'\n",
      "This label 'x' on line 131464 will be classed as 'oth'\n",
      "This label 'x' on line 131465 will be classed as 'oth'\n",
      "This label 'x' on line 131466 will be classed as 'oth'\n",
      "This label 'x' on line 134133 will be classed as 'oth'\n",
      "This label 'x' on line 134134 will be classed as 'oth'\n",
      "This label 'x' on line 134273 will be classed as 'oth'\n",
      "This label 'ak nf' on line 134769 will be classed as 'oth'\n",
      "This label 'x' on line 135718 will be classed as 'oth'\n",
      "This label 'x' on line 136274 will be classed as 'oth'\n",
      "This label 'x' on line 136626 will be classed as 'oth'\n",
      "This label 'x' on line 136756 will be classed as 'oth'\n",
      "This label 'x' on line 136859 will be classed as 'oth'\n",
      "This label 'x' on line 136863 will be classed as 'oth'\n",
      "This label 'x' on line 136934 will be classed as 'oth'\n",
      "This label 'x' on line 137007 will be classed as 'oth'\n",
      "This label 'x' on line 137404 will be classed as 'oth'\n",
      "This label 'x' on line 137405 will be classed as 'oth'\n",
      "This label 'x' on line 137407 will be classed as 'oth'\n",
      "This label 'x' on line 137452 will be classed as 'oth'\n",
      "This label 'x' on line 137453 will be classed as 'oth'\n",
      "This label 'chuck nf' on line 138445 will be classed as 'oth'\n",
      "This label 'chuck nf' on line 138454 will be classed as 'oth'\n",
      "This label 'chuck *' on line 138463 will be classed as 'oth'\n",
      "This label 'c nf' on line 138594 will be classed as 'oth'\n",
      "This label 'x' on line 139674 will be classed as 'oth'\n",
      "This label 'v' on line 139795 will be classed as 'oth'\n",
      "This label 'x' on line 139890 will be classed as 'oth'\n",
      "This label 'x' on line 140761 will be classed as 'oth'\n",
      "This label 'x' on line 141607 will be classed as 'oth'\n",
      "This label 'x' on line 141617 will be classed as 'oth'\n",
      "This label 's% nf' on line 142758 will be classed as 'oth'\n",
      "This label 's%' on line 143178 will be classed as 'oth'\n",
      "This label 's%' on line 143182 will be classed as 'oth'\n",
      "This label 'c nf' on line 143256 will be classed as 'oth'\n",
      "This label 's%' on line 143363 will be classed as 'oth'\n",
      "This label 'a nf' on line 143646 will be classed as 'oth'\n",
      "This label 'x' on line 144125 will be classed as 'oth'\n",
      "This label 'a' on line 144471 will be classed as 'oth'\n",
      "This label 's%' on line 144614 will be classed as 'oth'\n",
      "This label 'x' on line 146922 will be classed as 'oth'\n",
      "This label 'x' on line 146979 will be classed as 'oth'\n",
      "This label 'x' on line 147004 will be classed as 'oth'\n",
      "This label 'sych 01:24:00' on line 147090 will be classed as 'oth'\n",
      "This label 'x' on line 147167 will be classed as 'oth'\n",
      "This label 'x' on line 147272 will be classed as 'oth'\n",
      "This label 'x nf' on line 147277 will be classed as 'oth'\n",
      "This label 'sycnh 01:58:30' on line 147432 will be classed as 'oth'\n",
      "This label 'x' on line 147435 will be classed as 'oth'\n",
      "This label 'x' on line 147436 will be classed as 'oth'\n",
      "This label 'x' on line 147437 will be classed as 'oth'\n",
      "This label 'x' on line 147438 will be classed as 'oth'\n",
      "This label 'x' on line 147439 will be classed as 'oth'\n",
      "This label 'x' on line 147440 will be classed as 'oth'\n",
      "This label 'x' on line 147441 will be classed as 'oth'\n",
      "This label 'x' on line 147442 will be classed as 'oth'\n",
      "This label 'x' on line 147443 will be classed as 'oth'\n",
      "This label 'x' on line 147444 will be classed as 'oth'\n",
      "This label 'x' on line 147445 will be classed as 'oth'\n",
      "This label 'x' on line 147447 will be classed as 'oth'\n",
      "This label 'x' on line 147449 will be classed as 'oth'\n",
      "This label 'x' on line 147622 will be classed as 'oth'\n",
      "This label 'x' on line 147697 will be classed as 'oth'\n",
      "This label 'x' on line 148625 will be classed as 'oth'\n",
      "This label 'x' on line 148626 will be classed as 'oth'\n",
      "This label 'x' on line 148646 will be classed as 'oth'\n",
      "This label 'x' on line 148670 will be classed as 'oth'\n",
      "This label 'x' on line 148700 will be classed as 'oth'\n",
      "This label 'x' on line 148701 will be classed as 'oth'\n",
      "This label 'x' on line 148702 will be classed as 'oth'\n",
      "This label 'chuck' on line 148708 will be classed as 'oth'\n",
      "This label 'chuck' on line 148709 will be classed as 'oth'\n",
      "This label 'x' on line 148733 will be classed as 'oth'\n",
      "This label 'x' on line 148843 will be classed as 'oth'\n",
      "This label 'x' on line 148924 will be classed as 'oth'\n",
      "This label 'x' on line 149007 will be classed as 'oth'\n",
      "This label 'sycnh 01:57:00' on line 149288 will be classed as 'oth'\n",
      "This label 'x' on line 149385 will be classed as 'oth'\n",
      "This label 'x' on line 149388 will be classed as 'oth'\n",
      "This label 'x' on line 149405 will be classed as 'oth'\n",
      "This label 'x' on line 149449 will be classed as 'oth'\n",
      "This label 'x' on line 149715 will be classed as 'oth'\n",
      "This label 'x' on line 149725 will be classed as 'oth'\n",
      "This label 'x' on line 149831 will be classed as 'oth'\n",
      "This label 'synhc 01:37:30' on line 149879 will be classed as 'oth'\n",
      "This label 'x' on line 150085 will be classed as 'oth'\n",
      "This label 'x' on line 150086 will be classed as 'oth'\n",
      "This label 'x' on line 150087 will be classed as 'oth'\n",
      "This label 'x' on line 150088 will be classed as 'oth'\n",
      "This label 'x' on line 150562 will be classed as 'oth'\n",
      "This label 'x' on line 150613 will be classed as 'oth'\n",
      "This label 'x' on line 150630 will be classed as 'oth'\n",
      "This label 'x' on line 150631 will be classed as 'oth'\n",
      "This label 'x' on line 150637 will be classed as 'oth'\n",
      "This label 'x' on line 150673 will be classed as 'oth'\n",
      "This label 'x' on line 150674 will be classed as 'oth'\n",
      "This label 'x' on line 150735 will be classed as 'oth'\n",
      "This label 'x' on line 150747 will be classed as 'oth'\n",
      "This label 'x' on line 150757 will be classed as 'oth'\n",
      "This label 'x' on line 150957 will be classed as 'oth'\n",
      "This label 'x' on line 150964 will be classed as 'oth'\n",
      "This label 'x' on line 150965 will be classed as 'oth'\n",
      "This label 'x' on line 150966 will be classed as 'oth'\n",
      "This label 'x' on line 150967 will be classed as 'oth'\n",
      "This label 'x' on line 150968 will be classed as 'oth'\n",
      "This label 'x' on line 150969 will be classed as 'oth'\n",
      "This label 'x' on line 150970 will be classed as 'oth'\n",
      "This label 'x' on line 150971 will be classed as 'oth'\n",
      "This label 'x' on line 150972 will be classed as 'oth'\n",
      "This label 'x' on line 150973 will be classed as 'oth'\n",
      "This label 'x' on line 150974 will be classed as 'oth'\n",
      "This label 'x' on line 150975 will be classed as 'oth'\n",
      "This label 'x' on line 150976 will be classed as 'oth'\n",
      "This label 'x' on line 150977 will be classed as 'oth'\n",
      "This label 'x' on line 151015 will be classed as 'oth'\n",
      "This label 'x' on line 151016 will be classed as 'oth'\n",
      "This label 'x' on line 151017 will be classed as 'oth'\n",
      "This label 'x' on line 151026 will be classed as 'oth'\n",
      "This label 'x' on line 151035 will be classed as 'oth'\n"
     ]
    }
   ],
   "source": [
    "# Create the label table\n",
    "label_table = pre.create_meerkat_table(labels_all, call_types, sep,\n",
    "                                       start_column, duration_column, columns_to_keep,\n",
    "                                       label_column, convert_to_seconds, \n",
    "                                       label_for_other, label_for_noise, engine,\n",
    "                                       multiclass_forbidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.065\n"
     ]
    }
   ],
   "source": [
    "# estimate the average beep length because many of them are not annotated in the data\n",
    "avg_beep = round(statistics.mean(label_table.loc[label_table[\"beep\"],\"Duration\"].loc[label_table.loc[label_table[\"beep\"],\"Duration\"]>0]),3)\n",
    "label_table.loc[(label_table[\"beep\"].bool and label_table[\"Duration\"] == 0.) ==True, \"Duration\"] = avg_beep\n",
    "label_table.loc[(label_table[\"beep\"].bool and label_table[\"Duration\"] == avg_beep) ==True, \"End\"] += avg_beep\n",
    "print(avg_beep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add wav and audio paths\n",
    "label_table[\"wav_path\"] = label_table['wavFileName'].apply(lambda x: [pathi for pathi in audio_filepaths if x in pathi][0])\n",
    "label_table[\"label_path\"] = label_table['csvFileName'].apply(lambda x: [pathi for pathi in label_filepaths if x in pathi][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure these paths are added to the noise table too\n",
    "columns_to_keep.append(\"wav_path\")\n",
    "columns_to_keep.append(\"label_path\")\n",
    "\n",
    "# create the matching noise table\n",
    "noise_table = pre.create_noise_table(label_table, call_types, label_for_noise, label_for_startstop, columns_to_keep)#, '\\$'])\n",
    "\n",
    "# remove rows where the annotated noise is smaller than the window size otherwise the spectrogram we generate will inclue a call\n",
    "noise_table = noise_table.drop(noise_table[noise_table[\"Duration\"] < spec_window_size].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SENSITIVITY ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "audio_filenames Here we split the training and test set based on files (rather than spectrograms). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['20170806'],\n",
       " ['20170823'],\n",
       " ['20170824'],\n",
       " ['20170825'],\n",
       " ['20170903'],\n",
       " ['20170905'],\n",
       " ['20190623'],\n",
       " ['20190624'],\n",
       " ['20190625'],\n",
       " ['20190626'],\n",
       " ['20190627'],\n",
       " ['20190628'],\n",
       " ['20190712'],\n",
       " ['20190713'],\n",
       " ['20190714'],\n",
       " ['20190715'],\n",
       " ['20190716'],\n",
       " ['20190717'],\n",
       " ['20190718'],\n",
       " ['20190719'],\n",
       " ['20190805'],\n",
       " ['20190806'],\n",
       " ['20190807'],\n",
       " ['20190808'],\n",
       " ['20190809'],\n",
       " ['20190810'],\n",
       " ['20190811'],\n",
       " ['20190812']]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_pattern = [[\"L2019\",\"HM2019\"],[\"HM2017\",\"HM2019\"], [\"L2019\"], [\"HM2017\"]]\n",
    "train_pattern = label_table[\"date\"].unique()\n",
    "train_pattern = [[str(i)] for i in list(train_pattern )]\n",
    "train_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2974: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n",
      "Epoch 1/200\n",
      "5/5 [==============================] - 14s 3s/step - loss: 2.2713 - output_calltype_loss: 2.2591 - output_callpresence_loss: 0.2452 - output_calltype_categorical_accuracy: 0.4576 - output_callpresence_binary_accuracy: 0.5679 - val_loss: 2.2509 - val_output_calltype_loss: 2.2390 - val_output_callpresence_loss: 0.2393 - val_output_calltype_categorical_accuracy: 0.6846 - val_output_callpresence_binary_accuracy: 0.6853\n",
      "WARNING:tensorflow:From /home/kiran/anaconda3/envs/ML1_env/lib/python3.7/site-packages/keras/callbacks.py:995: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 9s 2s/step - loss: 2.0914 - output_calltype_loss: 2.0806 - output_callpresence_loss: 0.2167 - output_calltype_categorical_accuracy: 0.7105 - output_callpresence_binary_accuracy: 0.7138 - val_loss: 2.0770 - val_output_calltype_loss: 2.0662 - val_output_callpresence_loss: 0.2171 - val_output_calltype_categorical_accuracy: 0.6862 - val_output_callpresence_binary_accuracy: 0.6863\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 9s 2s/step - loss: 1.9235 - output_calltype_loss: 1.9123 - output_callpresence_loss: 0.2237 - output_calltype_categorical_accuracy: 0.6971 - output_callpresence_binary_accuracy: 0.7014 - val_loss: 1.8606 - val_output_calltype_loss: 1.8495 - val_output_callpresence_loss: 0.2223 - val_output_calltype_categorical_accuracy: 0.6952 - val_output_callpresence_binary_accuracy: 0.6976\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 9s 2s/step - loss: 1.7709 - output_calltype_loss: 1.7591 - output_callpresence_loss: 0.2352 - output_calltype_categorical_accuracy: 0.6983 - output_callpresence_binary_accuracy: 0.6989 - val_loss: 1.6564 - val_output_calltype_loss: 1.6446 - val_output_callpresence_loss: 0.2356 - val_output_calltype_categorical_accuracy: 0.6857 - val_output_callpresence_binary_accuracy: 0.6873\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 9s 2s/step - loss: 1.5766 - output_calltype_loss: 1.5660 - output_callpresence_loss: 0.2111 - output_calltype_categorical_accuracy: 0.7232 - output_callpresence_binary_accuracy: 0.7241 - val_loss: 1.3479 - val_output_calltype_loss: 1.3375 - val_output_callpresence_loss: 0.2085 - val_output_calltype_categorical_accuracy: 0.7091 - val_output_callpresence_binary_accuracy: 0.7100\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.3678 - output_calltype_loss: 1.3574 - output_callpresence_loss: 0.2086 - output_calltype_categorical_accuracy: 0.7309 - output_callpresence_binary_accuracy: 0.7154 - val_loss: 1.2521 - val_output_calltype_loss: 1.2411 - val_output_callpresence_loss: 0.2202 - val_output_calltype_categorical_accuracy: 0.6997 - val_output_callpresence_binary_accuracy: 0.7001\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 9s 2s/step - loss: 1.3277 - output_calltype_loss: 1.3164 - output_callpresence_loss: 0.2260 - output_calltype_categorical_accuracy: 0.6927 - output_callpresence_binary_accuracy: 0.6929 - val_loss: 1.4587 - val_output_calltype_loss: 1.4481 - val_output_callpresence_loss: 0.2121 - val_output_calltype_categorical_accuracy: 0.7255 - val_output_callpresence_binary_accuracy: 0.7268\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.3167 - output_calltype_loss: 1.3056 - output_callpresence_loss: 0.2221 - output_calltype_categorical_accuracy: 0.7050 - output_callpresence_binary_accuracy: 0.6900 - val_loss: 1.4078 - val_output_calltype_loss: 1.3979 - val_output_callpresence_loss: 0.1985 - val_output_calltype_categorical_accuracy: 0.7271 - val_output_callpresence_binary_accuracy: 0.7274\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2894 - output_calltype_loss: 1.2785 - output_callpresence_loss: 0.2176 - output_calltype_categorical_accuracy: 0.7024 - output_callpresence_binary_accuracy: 0.6934 - val_loss: 1.2614 - val_output_calltype_loss: 1.2511 - val_output_callpresence_loss: 0.2068 - val_output_calltype_categorical_accuracy: 0.7147 - val_output_callpresence_binary_accuracy: 0.7171\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2515 - output_calltype_loss: 1.2409 - output_callpresence_loss: 0.2121 - output_calltype_categorical_accuracy: 0.7132 - output_callpresence_binary_accuracy: 0.7139 - val_loss: 1.1624 - val_output_calltype_loss: 1.1524 - val_output_callpresence_loss: 0.2001 - val_output_calltype_categorical_accuracy: 0.7259 - val_output_callpresence_binary_accuracy: 0.7267\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2602 - output_calltype_loss: 1.2495 - output_callpresence_loss: 0.2140 - output_calltype_categorical_accuracy: 0.7021 - output_callpresence_binary_accuracy: 0.7084 - val_loss: 1.1992 - val_output_calltype_loss: 1.1887 - val_output_callpresence_loss: 0.2102 - val_output_calltype_categorical_accuracy: 0.6993 - val_output_callpresence_binary_accuracy: 0.7031\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2384 - output_calltype_loss: 1.2279 - output_callpresence_loss: 0.2106 - output_calltype_categorical_accuracy: 0.7171 - output_callpresence_binary_accuracy: 0.7178 - val_loss: 1.1611 - val_output_calltype_loss: 1.1511 - val_output_callpresence_loss: 0.1986 - val_output_calltype_categorical_accuracy: 0.7269 - val_output_callpresence_binary_accuracy: 0.7273\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2503 - output_calltype_loss: 1.2398 - output_callpresence_loss: 0.2099 - output_calltype_categorical_accuracy: 0.7136 - output_callpresence_binary_accuracy: 0.7153 - val_loss: 1.1044 - val_output_calltype_loss: 1.0950 - val_output_callpresence_loss: 0.1885 - val_output_calltype_categorical_accuracy: 0.7481 - val_output_callpresence_binary_accuracy: 0.7488\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2602 - output_calltype_loss: 1.2496 - output_callpresence_loss: 0.2119 - output_calltype_categorical_accuracy: 0.7056 - output_callpresence_binary_accuracy: 0.7099 - val_loss: 1.1975 - val_output_calltype_loss: 1.1874 - val_output_callpresence_loss: 0.2028 - val_output_calltype_categorical_accuracy: 0.7156 - val_output_callpresence_binary_accuracy: 0.7165\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 9s 2s/step - loss: 1.2187 - output_calltype_loss: 1.2083 - output_callpresence_loss: 0.2086 - output_calltype_categorical_accuracy: 0.7180 - output_callpresence_binary_accuracy: 0.7170 - val_loss: 1.1430 - val_output_calltype_loss: 1.1333 - val_output_callpresence_loss: 0.1937 - val_output_calltype_categorical_accuracy: 0.7339 - val_output_callpresence_binary_accuracy: 0.7359\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2193 - output_calltype_loss: 1.2091 - output_callpresence_loss: 0.2038 - output_calltype_categorical_accuracy: 0.7286 - output_callpresence_binary_accuracy: 0.7276 - val_loss: 1.2854 - val_output_calltype_loss: 1.2744 - val_output_callpresence_loss: 0.2210 - val_output_calltype_categorical_accuracy: 0.6834 - val_output_callpresence_binary_accuracy: 0.6842\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.3068 - output_calltype_loss: 1.2957 - output_callpresence_loss: 0.2209 - output_calltype_categorical_accuracy: 0.6868 - output_callpresence_binary_accuracy: 0.6901 - val_loss: 1.2050 - val_output_calltype_loss: 1.1946 - val_output_callpresence_loss: 0.2084 - val_output_calltype_categorical_accuracy: 0.6959 - val_output_callpresence_binary_accuracy: 0.6996\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.3225 - output_calltype_loss: 1.3114 - output_callpresence_loss: 0.2233 - output_calltype_categorical_accuracy: 0.6829 - output_callpresence_binary_accuracy: 0.6803 - val_loss: 1.1767 - val_output_calltype_loss: 1.1664 - val_output_callpresence_loss: 0.2070 - val_output_calltype_categorical_accuracy: 0.7101 - val_output_callpresence_binary_accuracy: 0.7109\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2780 - output_calltype_loss: 1.2671 - output_callpresence_loss: 0.2185 - output_calltype_categorical_accuracy: 0.6984 - output_callpresence_binary_accuracy: 0.6937 - val_loss: 1.2212 - val_output_calltype_loss: 1.2107 - val_output_callpresence_loss: 0.2087 - val_output_calltype_categorical_accuracy: 0.6977 - val_output_callpresence_binary_accuracy: 0.6992\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2492 - output_calltype_loss: 1.2387 - output_callpresence_loss: 0.2094 - output_calltype_categorical_accuracy: 0.7127 - output_callpresence_binary_accuracy: 0.7183 - val_loss: 1.1752 - val_output_calltype_loss: 1.1650 - val_output_callpresence_loss: 0.2044 - val_output_calltype_categorical_accuracy: 0.7090 - val_output_callpresence_binary_accuracy: 0.7115\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2164 - output_calltype_loss: 1.2062 - output_callpresence_loss: 0.2050 - output_calltype_categorical_accuracy: 0.7185 - output_callpresence_binary_accuracy: 0.7260 - val_loss: 1.1112 - val_output_calltype_loss: 1.1017 - val_output_callpresence_loss: 0.1916 - val_output_calltype_categorical_accuracy: 0.7365 - val_output_callpresence_binary_accuracy: 0.7378\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2361 - output_calltype_loss: 1.2258 - output_callpresence_loss: 0.2067 - output_calltype_categorical_accuracy: 0.7170 - output_callpresence_binary_accuracy: 0.7208 - val_loss: 1.2144 - val_output_calltype_loss: 1.2040 - val_output_callpresence_loss: 0.2071 - val_output_calltype_categorical_accuracy: 0.7000 - val_output_callpresence_binary_accuracy: 0.7036\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2481 - output_calltype_loss: 1.2376 - output_callpresence_loss: 0.2098 - output_calltype_categorical_accuracy: 0.7100 - output_callpresence_binary_accuracy: 0.7119 - val_loss: 1.1963 - val_output_calltype_loss: 1.1860 - val_output_callpresence_loss: 0.2045 - val_output_calltype_categorical_accuracy: 0.7075 - val_output_callpresence_binary_accuracy: 0.7078\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2850 - output_calltype_loss: 1.2742 - output_callpresence_loss: 0.2152 - output_calltype_categorical_accuracy: 0.6985 - output_callpresence_binary_accuracy: 0.6977 - val_loss: 1.1911 - val_output_calltype_loss: 1.1808 - val_output_callpresence_loss: 0.2069 - val_output_calltype_categorical_accuracy: 0.7044 - val_output_callpresence_binary_accuracy: 0.7046\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.1608 - output_calltype_loss: 1.1510 - output_callpresence_loss: 0.1965 - output_calltype_categorical_accuracy: 0.7389 - output_callpresence_binary_accuracy: 0.7400 - val_loss: 1.1493 - val_output_calltype_loss: 1.1394 - val_output_callpresence_loss: 0.1992 - val_output_calltype_categorical_accuracy: 0.7140 - val_output_callpresence_binary_accuracy: 0.7146\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2389 - output_calltype_loss: 1.2283 - output_callpresence_loss: 0.2109 - output_calltype_categorical_accuracy: 0.7077 - output_callpresence_binary_accuracy: 0.7115 - val_loss: 1.1904 - val_output_calltype_loss: 1.1802 - val_output_callpresence_loss: 0.2044 - val_output_calltype_categorical_accuracy: 0.6988 - val_output_callpresence_binary_accuracy: 0.7027\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2745 - output_calltype_loss: 1.2637 - output_callpresence_loss: 0.2159 - output_calltype_categorical_accuracy: 0.6945 - output_callpresence_binary_accuracy: 0.6990 - val_loss: 1.1817 - val_output_calltype_loss: 1.1716 - val_output_callpresence_loss: 0.2025 - val_output_calltype_categorical_accuracy: 0.7069 - val_output_callpresence_binary_accuracy: 0.7072\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2186 - output_calltype_loss: 1.2084 - output_callpresence_loss: 0.2037 - output_calltype_categorical_accuracy: 0.7160 - output_callpresence_binary_accuracy: 0.7178 - val_loss: 1.1615 - val_output_calltype_loss: 1.1515 - val_output_callpresence_loss: 0.2002 - val_output_calltype_categorical_accuracy: 0.7116 - val_output_callpresence_binary_accuracy: 0.7145\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2118 - output_calltype_loss: 1.2015 - output_callpresence_loss: 0.2057 - output_calltype_categorical_accuracy: 0.7133 - output_callpresence_binary_accuracy: 0.7174 - val_loss: 1.1884 - val_output_calltype_loss: 1.1783 - val_output_callpresence_loss: 0.2015 - val_output_calltype_categorical_accuracy: 0.6999 - val_output_callpresence_binary_accuracy: 0.7023\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.2541 - output_calltype_loss: 1.2435 - output_callpresence_loss: 0.2108 - output_calltype_categorical_accuracy: 0.6953 - output_callpresence_binary_accuracy: 0.7004 - val_loss: 1.1592 - val_output_calltype_loss: 1.1494 - val_output_callpresence_loss: 0.1961 - val_output_calltype_categorical_accuracy: 0.7141 - val_output_callpresence_binary_accuracy: 0.7165\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2639 - output_calltype_loss: 1.2533 - output_callpresence_loss: 0.2120 - output_calltype_categorical_accuracy: 0.6923 - output_callpresence_binary_accuracy: 0.6947 - val_loss: 1.1848 - val_output_calltype_loss: 1.1747 - val_output_callpresence_loss: 0.2024 - val_output_calltype_categorical_accuracy: 0.7005 - val_output_callpresence_binary_accuracy: 0.7008\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2058 - output_calltype_loss: 1.1957 - output_callpresence_loss: 0.2023 - output_calltype_categorical_accuracy: 0.7160 - output_callpresence_binary_accuracy: 0.7189 - val_loss: 1.2080 - val_output_calltype_loss: 1.1978 - val_output_callpresence_loss: 0.2047 - val_output_calltype_categorical_accuracy: 0.6934 - val_output_callpresence_binary_accuracy: 0.6937\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.1990 - output_calltype_loss: 1.1890 - output_callpresence_loss: 0.2015 - output_calltype_categorical_accuracy: 0.7187 - output_callpresence_binary_accuracy: 0.7222 - val_loss: 1.1785 - val_output_calltype_loss: 1.1684 - val_output_callpresence_loss: 0.2003 - val_output_calltype_categorical_accuracy: 0.7054 - val_output_callpresence_binary_accuracy: 0.7090\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2139 - output_calltype_loss: 1.2036 - output_callpresence_loss: 0.2044 - output_calltype_categorical_accuracy: 0.7104 - output_callpresence_binary_accuracy: 0.7111 - val_loss: 1.1736 - val_output_calltype_loss: 1.1638 - val_output_callpresence_loss: 0.1966 - val_output_calltype_categorical_accuracy: 0.7120 - val_output_callpresence_binary_accuracy: 0.7149\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2589 - output_calltype_loss: 1.2481 - output_callpresence_loss: 0.2142 - output_calltype_categorical_accuracy: 0.6790 - output_callpresence_binary_accuracy: 0.6837 - val_loss: 1.0702 - val_output_calltype_loss: 1.0612 - val_output_callpresence_loss: 0.1808 - val_output_calltype_categorical_accuracy: 0.7366 - val_output_callpresence_binary_accuracy: 0.7377\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2455 - output_calltype_loss: 1.2351 - output_callpresence_loss: 0.2085 - output_calltype_categorical_accuracy: 0.6869 - output_callpresence_binary_accuracy: 0.6894 - val_loss: 1.0962 - val_output_calltype_loss: 1.0871 - val_output_callpresence_loss: 0.1821 - val_output_calltype_categorical_accuracy: 0.7303 - val_output_callpresence_binary_accuracy: 0.7339\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.1853 - output_calltype_loss: 1.1754 - output_callpresence_loss: 0.1974 - output_calltype_categorical_accuracy: 0.7067 - output_callpresence_binary_accuracy: 0.7131 - val_loss: 1.2053 - val_output_calltype_loss: 1.1954 - val_output_callpresence_loss: 0.1976 - val_output_calltype_categorical_accuracy: 0.7071 - val_output_callpresence_binary_accuracy: 0.7078\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2221 - output_calltype_loss: 1.2120 - output_callpresence_loss: 0.2023 - output_calltype_categorical_accuracy: 0.6941 - output_callpresence_binary_accuracy: 0.6982 - val_loss: 1.1675 - val_output_calltype_loss: 1.1582 - val_output_callpresence_loss: 0.1851 - val_output_calltype_categorical_accuracy: 0.7327 - val_output_callpresence_binary_accuracy: 0.7345\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.1701 - output_calltype_loss: 1.1605 - output_callpresence_loss: 0.1920 - output_calltype_categorical_accuracy: 0.7129 - output_callpresence_binary_accuracy: 0.7132 - val_loss: 1.3482 - val_output_calltype_loss: 1.3376 - val_output_callpresence_loss: 0.2127 - val_output_calltype_categorical_accuracy: 0.6946 - val_output_callpresence_binary_accuracy: 0.6972\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.2264 - output_calltype_loss: 1.2163 - output_callpresence_loss: 0.2005 - output_calltype_categorical_accuracy: 0.6850 - output_callpresence_binary_accuracy: 0.6897 - val_loss: 1.3358 - val_output_calltype_loss: 1.3256 - val_output_callpresence_loss: 0.2037 - val_output_calltype_categorical_accuracy: 0.7079 - val_output_callpresence_binary_accuracy: 0.7090\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.0798 - output_calltype_loss: 1.0710 - output_callpresence_loss: 0.1773 - output_calltype_categorical_accuracy: 0.7379 - output_callpresence_binary_accuracy: 0.7417 - val_loss: 1.4105 - val_output_calltype_loss: 1.3999 - val_output_callpresence_loss: 0.2121 - val_output_calltype_categorical_accuracy: 0.7028 - val_output_callpresence_binary_accuracy: 0.7033\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.1391 - output_calltype_loss: 1.1301 - output_callpresence_loss: 0.1804 - output_calltype_categorical_accuracy: 0.7024 - output_callpresence_binary_accuracy: 0.7057 - val_loss: 1.5774 - val_output_calltype_loss: 1.5659 - val_output_callpresence_loss: 0.2298 - val_output_calltype_categorical_accuracy: 0.7010 - val_output_callpresence_binary_accuracy: 0.7017\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.0844 - output_calltype_loss: 1.0758 - output_callpresence_loss: 0.1719 - output_calltype_categorical_accuracy: 0.7160 - output_callpresence_binary_accuracy: 0.7209 - val_loss: 1.5599 - val_output_calltype_loss: 1.5488 - val_output_callpresence_loss: 0.2211 - val_output_calltype_categorical_accuracy: 0.7122 - val_output_callpresence_binary_accuracy: 0.7309\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.1331 - output_calltype_loss: 1.1244 - output_callpresence_loss: 0.1744 - output_calltype_categorical_accuracy: 0.6925 - output_callpresence_binary_accuracy: 0.7210 - val_loss: 1.4298 - val_output_calltype_loss: 1.4194 - val_output_callpresence_loss: 0.2068 - val_output_calltype_categorical_accuracy: 0.7107 - val_output_callpresence_binary_accuracy: 0.7523\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.1351 - output_calltype_loss: 1.1265 - output_callpresence_loss: 0.1724 - output_calltype_categorical_accuracy: 0.7033 - output_callpresence_binary_accuracy: 0.7511 - val_loss: 1.6164 - val_output_calltype_loss: 1.6044 - val_output_callpresence_loss: 0.2400 - val_output_calltype_categorical_accuracy: 0.6932 - val_output_callpresence_binary_accuracy: 0.7256\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.1172 - output_calltype_loss: 1.1091 - output_callpresence_loss: 0.1612 - output_calltype_categorical_accuracy: 0.6934 - output_callpresence_binary_accuracy: 0.7658 - val_loss: 1.5237 - val_output_calltype_loss: 1.5118 - val_output_callpresence_loss: 0.2390 - val_output_calltype_categorical_accuracy: 0.7045 - val_output_callpresence_binary_accuracy: 0.7345\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.0540 - output_calltype_loss: 1.0460 - output_callpresence_loss: 0.1591 - output_calltype_categorical_accuracy: 0.7214 - output_callpresence_binary_accuracy: 0.7745 - val_loss: 1.6587 - val_output_calltype_loss: 1.6462 - val_output_callpresence_loss: 0.2503 - val_output_calltype_categorical_accuracy: 0.6782 - val_output_callpresence_binary_accuracy: 0.7295\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.0558 - output_calltype_loss: 1.0486 - output_callpresence_loss: 0.1450 - output_calltype_categorical_accuracy: 0.7003 - output_callpresence_binary_accuracy: 0.8164 - val_loss: 1.4958 - val_output_calltype_loss: 1.4845 - val_output_callpresence_loss: 0.2261 - val_output_calltype_categorical_accuracy: 0.7112 - val_output_callpresence_binary_accuracy: 0.7518\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.0672 - output_calltype_loss: 1.0600 - output_callpresence_loss: 0.1446 - output_calltype_categorical_accuracy: 0.7042 - output_callpresence_binary_accuracy: 0.8304 - val_loss: 1.4993 - val_output_calltype_loss: 1.4880 - val_output_callpresence_loss: 0.2250 - val_output_calltype_categorical_accuracy: 0.6998 - val_output_callpresence_binary_accuracy: 0.7572\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.1080 - output_calltype_loss: 1.1008 - output_callpresence_loss: 0.1446 - output_calltype_categorical_accuracy: 0.6806 - output_callpresence_binary_accuracy: 0.8300 - val_loss: 1.4542 - val_output_calltype_loss: 1.4433 - val_output_callpresence_loss: 0.2174 - val_output_calltype_categorical_accuracy: 0.7104 - val_output_callpresence_binary_accuracy: 0.7691\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9926 - output_calltype_loss: 0.9864 - output_callpresence_loss: 0.1236 - output_calltype_categorical_accuracy: 0.7225 - output_callpresence_binary_accuracy: 0.8509 - val_loss: 1.6491 - val_output_calltype_loss: 1.6369 - val_output_callpresence_loss: 0.2434 - val_output_calltype_categorical_accuracy: 0.6939 - val_output_callpresence_binary_accuracy: 0.7452\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.0324 - output_calltype_loss: 1.0257 - output_callpresence_loss: 0.1358 - output_calltype_categorical_accuracy: 0.7089 - output_callpresence_binary_accuracy: 0.8356 - val_loss: 1.3775 - val_output_calltype_loss: 1.3672 - val_output_callpresence_loss: 0.2047 - val_output_calltype_categorical_accuracy: 0.7064 - val_output_callpresence_binary_accuracy: 0.7844\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9918 - output_calltype_loss: 0.9858 - output_callpresence_loss: 0.1201 - output_calltype_categorical_accuracy: 0.7204 - output_callpresence_binary_accuracy: 0.8547 - val_loss: 1.4006 - val_output_calltype_loss: 1.3899 - val_output_callpresence_loss: 0.2137 - val_output_calltype_categorical_accuracy: 0.7217 - val_output_callpresence_binary_accuracy: 0.7744\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.0521 - output_calltype_loss: 1.0457 - output_callpresence_loss: 0.1289 - output_calltype_categorical_accuracy: 0.6962 - output_callpresence_binary_accuracy: 0.8458 - val_loss: 1.4375 - val_output_calltype_loss: 1.4264 - val_output_callpresence_loss: 0.2210 - val_output_calltype_categorical_accuracy: 0.6905 - val_output_callpresence_binary_accuracy: 0.7658\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.9929 - output_calltype_loss: 0.9870 - output_callpresence_loss: 0.1171 - output_calltype_categorical_accuracy: 0.7173 - output_callpresence_binary_accuracy: 0.8562 - val_loss: 1.3597 - val_output_calltype_loss: 1.3491 - val_output_callpresence_loss: 0.2135 - val_output_calltype_categorical_accuracy: 0.7085 - val_output_callpresence_binary_accuracy: 0.7749\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.9559 - output_calltype_loss: 0.9503 - output_callpresence_loss: 0.1136 - output_calltype_categorical_accuracy: 0.7271 - output_callpresence_binary_accuracy: 0.8611 - val_loss: 1.5137 - val_output_calltype_loss: 1.5020 - val_output_callpresence_loss: 0.2356 - val_output_calltype_categorical_accuracy: 0.6922 - val_output_callpresence_binary_accuracy: 0.7511\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.9709 - output_calltype_loss: 0.9651 - output_callpresence_loss: 0.1154 - output_calltype_categorical_accuracy: 0.7294 - output_callpresence_binary_accuracy: 0.8621 - val_loss: 1.3866 - val_output_calltype_loss: 1.3759 - val_output_callpresence_loss: 0.2149 - val_output_calltype_categorical_accuracy: 0.7036 - val_output_callpresence_binary_accuracy: 0.7709\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9664 - output_calltype_loss: 0.9612 - output_callpresence_loss: 0.1040 - output_calltype_categorical_accuracy: 0.7163 - output_callpresence_binary_accuracy: 0.8757 - val_loss: 1.2682 - val_output_calltype_loss: 1.2586 - val_output_callpresence_loss: 0.1930 - val_output_calltype_categorical_accuracy: 0.7257 - val_output_callpresence_binary_accuracy: 0.7938\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.9792 - output_calltype_loss: 0.9739 - output_callpresence_loss: 0.1058 - output_calltype_categorical_accuracy: 0.6968 - output_callpresence_binary_accuracy: 0.8683 - val_loss: 1.4566 - val_output_calltype_loss: 1.4455 - val_output_callpresence_loss: 0.2227 - val_output_calltype_categorical_accuracy: 0.7203 - val_output_callpresence_binary_accuracy: 0.7655\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9949 - output_calltype_loss: 0.9893 - output_callpresence_loss: 0.1128 - output_calltype_categorical_accuracy: 0.7051 - output_callpresence_binary_accuracy: 0.8641 - val_loss: 1.2771 - val_output_calltype_loss: 1.2673 - val_output_callpresence_loss: 0.1964 - val_output_calltype_categorical_accuracy: 0.7338 - val_output_callpresence_binary_accuracy: 0.7888\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9319 - output_calltype_loss: 0.9268 - output_callpresence_loss: 0.1024 - output_calltype_categorical_accuracy: 0.7220 - output_callpresence_binary_accuracy: 0.8744 - val_loss: 1.3077 - val_output_calltype_loss: 1.2980 - val_output_callpresence_loss: 0.1950 - val_output_calltype_categorical_accuracy: 0.7294 - val_output_callpresence_binary_accuracy: 0.7930\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.0045 - output_calltype_loss: 0.9985 - output_callpresence_loss: 0.1198 - output_calltype_categorical_accuracy: 0.6956 - output_callpresence_binary_accuracy: 0.8508 - val_loss: 1.3778 - val_output_calltype_loss: 1.3670 - val_output_callpresence_loss: 0.2148 - val_output_calltype_categorical_accuracy: 0.7188 - val_output_callpresence_binary_accuracy: 0.7712\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.9775 - output_calltype_loss: 0.9720 - output_callpresence_loss: 0.1103 - output_calltype_categorical_accuracy: 0.7047 - output_callpresence_binary_accuracy: 0.8652 - val_loss: 1.3976 - val_output_calltype_loss: 1.3868 - val_output_callpresence_loss: 0.2157 - val_output_calltype_categorical_accuracy: 0.7157 - val_output_callpresence_binary_accuracy: 0.7712\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9776 - output_calltype_loss: 0.9722 - output_callpresence_loss: 0.1091 - output_calltype_categorical_accuracy: 0.7101 - output_callpresence_binary_accuracy: 0.8684 - val_loss: 1.2505 - val_output_calltype_loss: 1.2410 - val_output_callpresence_loss: 0.1906 - val_output_calltype_categorical_accuracy: 0.7362 - val_output_callpresence_binary_accuracy: 0.7958\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.9196 - output_calltype_loss: 0.9144 - output_callpresence_loss: 0.1037 - output_calltype_categorical_accuracy: 0.7358 - output_callpresence_binary_accuracy: 0.8747 - val_loss: 1.3988 - val_output_calltype_loss: 1.3879 - val_output_callpresence_loss: 0.2186 - val_output_calltype_categorical_accuracy: 0.7164 - val_output_callpresence_binary_accuracy: 0.7690\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9713 - output_calltype_loss: 0.9661 - output_callpresence_loss: 0.1029 - output_calltype_categorical_accuracy: 0.7134 - output_callpresence_binary_accuracy: 0.8740 - val_loss: 1.2420 - val_output_calltype_loss: 1.2323 - val_output_callpresence_loss: 0.1928 - val_output_calltype_categorical_accuracy: 0.7383 - val_output_callpresence_binary_accuracy: 0.7930\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.0142 - output_calltype_loss: 1.0079 - output_callpresence_loss: 0.1263 - output_calltype_categorical_accuracy: 0.7144 - output_callpresence_binary_accuracy: 0.8473 - val_loss: 1.3942 - val_output_calltype_loss: 1.3838 - val_output_callpresence_loss: 0.2071 - val_output_calltype_categorical_accuracy: 0.7157 - val_output_callpresence_binary_accuracy: 0.7809\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9689 - output_calltype_loss: 0.9635 - output_callpresence_loss: 0.1085 - output_calltype_categorical_accuracy: 0.7206 - output_callpresence_binary_accuracy: 0.8689 - val_loss: 1.2590 - val_output_calltype_loss: 1.2495 - val_output_callpresence_loss: 0.1895 - val_output_calltype_categorical_accuracy: 0.7264 - val_output_callpresence_binary_accuracy: 0.7955\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.8786 - output_calltype_loss: 0.8741 - output_callpresence_loss: 0.0886 - output_calltype_categorical_accuracy: 0.7492 - output_callpresence_binary_accuracy: 0.8925 - val_loss: 1.3736 - val_output_calltype_loss: 1.3631 - val_output_callpresence_loss: 0.2104 - val_output_calltype_categorical_accuracy: 0.7255 - val_output_callpresence_binary_accuracy: 0.7772\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 1.0027 - output_calltype_loss: 0.9969 - output_callpresence_loss: 0.1165 - output_calltype_categorical_accuracy: 0.7210 - output_callpresence_binary_accuracy: 0.8594 - val_loss: 1.3334 - val_output_calltype_loss: 1.3230 - val_output_callpresence_loss: 0.2079 - val_output_calltype_categorical_accuracy: 0.7189 - val_output_callpresence_binary_accuracy: 0.7778\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9529 - output_calltype_loss: 0.9476 - output_callpresence_loss: 0.1063 - output_calltype_categorical_accuracy: 0.7279 - output_callpresence_binary_accuracy: 0.8712 - val_loss: 1.1992 - val_output_calltype_loss: 1.1900 - val_output_callpresence_loss: 0.1847 - val_output_calltype_categorical_accuracy: 0.7387 - val_output_callpresence_binary_accuracy: 0.8009\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9432 - output_calltype_loss: 0.9380 - output_callpresence_loss: 0.1025 - output_calltype_categorical_accuracy: 0.7304 - output_callpresence_binary_accuracy: 0.8742 - val_loss: 1.2620 - val_output_calltype_loss: 1.2521 - val_output_callpresence_loss: 0.1980 - val_output_calltype_categorical_accuracy: 0.7308 - val_output_callpresence_binary_accuracy: 0.7862\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 8s 2s/step - loss: 0.9257 - output_calltype_loss: 0.9202 - output_callpresence_loss: 0.1096 - output_calltype_categorical_accuracy: 0.7385 - output_callpresence_binary_accuracy: 0.8674 - val_loss: 1.3336 - val_output_calltype_loss: 1.3240 - val_output_callpresence_loss: 0.1933 - val_output_calltype_categorical_accuracy: 0.7459 - val_output_callpresence_binary_accuracy: 0.7951\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9639 - output_calltype_loss: 0.9586 - output_callpresence_loss: 0.1064 - output_calltype_categorical_accuracy: 0.7268 - output_callpresence_binary_accuracy: 0.8750 - val_loss: 1.1655 - val_output_calltype_loss: 1.1566 - val_output_callpresence_loss: 0.1785 - val_output_calltype_categorical_accuracy: 0.7344 - val_output_callpresence_binary_accuracy: 0.8038\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.9790 - output_calltype_loss: 0.9737 - output_callpresence_loss: 0.1056 - output_calltype_categorical_accuracy: 0.7179 - output_callpresence_binary_accuracy: 0.8698 - val_loss: 1.1896 - val_output_calltype_loss: 1.1802 - val_output_callpresence_loss: 0.1884 - val_output_calltype_categorical_accuracy: 0.7323 - val_output_callpresence_binary_accuracy: 0.7956\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00075: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Layer bidirectional_1 was passed non-serializable keyword arguments: {'mask': <tf.Tensor 'input_2:0' shape=(?, 201) dtype=float32>}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "Layer bidirectional_2 was passed non-serializable keyword arguments: {'mask': <tf.Tensor 'input_2:0' shape=(?, 201) dtype=float32>}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/kiran/D0-P1/animal_data/meerkat/NoiseAugmented_0.3_0.8_NotWeighted_MaskedOther_Forked_trained_with_20170806/trained_model/NoiseAugmented_0.3_0.8_NotWeighted_MaskedOther_Forked_trained_with_20170806_2022-02-13_18:12:15.884783\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 201, 30, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 201, 30, 128) 1280        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 201, 6, 128)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 201, 6, 128)  147584      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 201, 3, 128)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 201, 3, 128)  147584      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 201, 1, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 201, 128)     0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 201, 201)     397980      reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 201, 201)     486018      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 201, 1024)    206848      bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 201, 1024)    0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 201, 1024)    1049600     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 201, 1024)    0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 201, 1024)    1049600     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 201, 1024)    1049600     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 201, 1024)    0           time_distributed_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 201, 1024)    0           time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "output_calltype (TimeDistribute (None, 201, 10)      10250       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_callpresence (TimeDistri (None, 201, 2)       2050        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,548,394\n",
      "Trainable params: 4,548,394\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "*****************************************************************\n",
      "*****************************************************************\n",
      "File being processed : /home/kiran/Documents/MPI-Server/EAS_shared/meerkat/archive/rawdata/MEERKAT_RAW_DATA/2019/HM_2019_2/COLLAR/AUDIO/HM_VHMM032_RS_R15_20190707-20190719/HM_VHMM032_RS_R15_20190707-20190719_file_9_(2019_07_15-11_44_59)_155944.wav\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.5\n",
      "Detecting calls in probability streams:  0 / 7199\n",
      "Detecting calls in probability streams:  1000 / 7199\n",
      "Detecting calls in probability streams:  2000 / 7199\n",
      "Detecting calls in probability streams:  3000 / 7199\n",
      "Detecting calls in probability streams:  4000 / 7199\n",
      "Detecting calls in probability streams:  5000 / 7199\n",
      "Detecting calls in probability streams:  6000 / 7199\n",
      "Detecting calls in probability streams:  7000 / 7199\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.6\n",
      "Detecting calls in probability streams:  0 / 7199\n",
      "Detecting calls in probability streams:  1000 / 7199\n",
      "Detecting calls in probability streams:  2000 / 7199\n",
      "Detecting calls in probability streams:  3000 / 7199\n",
      "Detecting calls in probability streams:  4000 / 7199\n",
      "Detecting calls in probability streams:  5000 / 7199\n",
      "Detecting calls in probability streams:  6000 / 7199\n",
      "Detecting calls in probability streams:  7000 / 7199\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.7\n",
      "Detecting calls in probability streams:  0 / 7199\n",
      "Detecting calls in probability streams:  1000 / 7199\n",
      "Detecting calls in probability streams:  2000 / 7199\n",
      "Detecting calls in probability streams:  3000 / 7199\n",
      "Detecting calls in probability streams:  4000 / 7199\n",
      "Detecting calls in probability streams:  5000 / 7199\n",
      "Detecting calls in probability streams:  6000 / 7199\n",
      "Detecting calls in probability streams:  7000 / 7199\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.8\n",
      "Detecting calls in probability streams:  0 / 7199\n",
      "Detecting calls in probability streams:  1000 / 7199\n",
      "Detecting calls in probability streams:  2000 / 7199\n",
      "Detecting calls in probability streams:  3000 / 7199\n",
      "Detecting calls in probability streams:  4000 / 7199\n",
      "Detecting calls in probability streams:  5000 / 7199\n",
      "Detecting calls in probability streams:  6000 / 7199\n",
      "Detecting calls in probability streams:  7000 / 7199\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.9\n",
      "Detecting calls in probability streams:  0 / 7199\n",
      "Detecting calls in probability streams:  1000 / 7199\n",
      "Detecting calls in probability streams:  2000 / 7199\n",
      "Detecting calls in probability streams:  3000 / 7199\n",
      "Detecting calls in probability streams:  4000 / 7199\n",
      "Detecting calls in probability streams:  5000 / 7199\n",
      "Detecting calls in probability streams:  6000 / 7199\n",
      "Detecting calls in probability streams:  7000 / 7199\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.95\n",
      "Detecting calls in probability streams:  0 / 7199\n",
      "Detecting calls in probability streams:  1000 / 7199\n",
      "Detecting calls in probability streams:  2000 / 7199\n",
      "Detecting calls in probability streams:  3000 / 7199\n",
      "Detecting calls in probability streams:  4000 / 7199\n",
      "Detecting calls in probability streams:  5000 / 7199\n",
      "Detecting calls in probability streams:  6000 / 7199\n",
      "Detecting calls in probability streams:  7000 / 7199\n",
      "*****************************************************************\n",
      "*****************************************************************\n",
      "File being processed : /home/kiran/Documents/MPI-Server/EAS_shared/meerkat/archive/rawdata/MEERKAT_RAW_DATA/2019/HM_2019_1/COLLAR/AUDIO/HM_VHMF001_HTB_R16_20190618-20190629/HM_VHMF001_HTB_R16_20190618-20190629_file_8_(2019_06_25-07_44_59)_255944.wav\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.5\n",
      "Detecting calls in probability streams:  0 / 4274\n",
      "Detecting calls in probability streams:  1000 / 4274\n",
      "Detecting calls in probability streams:  2000 / 4274\n",
      "Detecting calls in probability streams:  3000 / 4274\n",
      "Detecting calls in probability streams:  4000 / 4274\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.6\n",
      "Detecting calls in probability streams:  0 / 4274\n",
      "Detecting calls in probability streams:  1000 / 4274\n",
      "Detecting calls in probability streams:  2000 / 4274\n",
      "Detecting calls in probability streams:  3000 / 4274\n",
      "Detecting calls in probability streams:  4000 / 4274\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.7\n",
      "Detecting calls in probability streams:  0 / 4274\n",
      "Detecting calls in probability streams:  1000 / 4274\n",
      "Detecting calls in probability streams:  2000 / 4274\n",
      "Detecting calls in probability streams:  3000 / 4274\n",
      "Detecting calls in probability streams:  4000 / 4274\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.8\n",
      "Detecting calls in probability streams:  0 / 4274\n",
      "Detecting calls in probability streams:  1000 / 4274\n",
      "Detecting calls in probability streams:  2000 / 4274\n",
      "Detecting calls in probability streams:  3000 / 4274\n",
      "Detecting calls in probability streams:  4000 / 4274\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.9\n",
      "Detecting calls in probability streams:  0 / 4274\n",
      "Detecting calls in probability streams:  1000 / 4274\n",
      "Detecting calls in probability streams:  2000 / 4274\n",
      "Detecting calls in probability streams:  3000 / 4274\n",
      "Detecting calls in probability streams:  4000 / 4274\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.95\n",
      "Detecting calls in probability streams:  0 / 4274\n",
      "Detecting calls in probability streams:  1000 / 4274\n",
      "Detecting calls in probability streams:  2000 / 4274\n",
      "Detecting calls in probability streams:  3000 / 4274\n",
      "Detecting calls in probability streams:  4000 / 4274\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.5\n",
      "Detecting calls in probability streams:  0 / 289\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.6\n",
      "Detecting calls in probability streams:  0 / 289\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.7\n",
      "Detecting calls in probability streams:  0 / 289\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.8\n",
      "Detecting calls in probability streams:  0 / 289\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.9\n",
      "Detecting calls in probability streams:  0 / 289\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.95\n",
      "Detecting calls in probability streams:  0 / 289\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.5\n",
      "Detecting calls in probability streams:  0 / 73\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.6\n",
      "Detecting calls in probability streams:  0 / 73\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.7\n",
      "Detecting calls in probability streams:  0 / 73\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.8\n",
      "Detecting calls in probability streams:  0 / 73\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.9\n",
      "Detecting calls in probability streams:  0 / 73\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.95\n",
      "Detecting calls in probability streams:  0 / 73\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.5\n",
      "Detecting calls in probability streams:  0 / 2475\n",
      "Detecting calls in probability streams:  1000 / 2475\n",
      "Detecting calls in probability streams:  2000 / 2475\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.6\n",
      "Detecting calls in probability streams:  0 / 2475\n",
      "Detecting calls in probability streams:  1000 / 2475\n",
      "Detecting calls in probability streams:  2000 / 2475\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.7\n",
      "Detecting calls in probability streams:  0 / 2475\n",
      "Detecting calls in probability streams:  1000 / 2475\n",
      "Detecting calls in probability streams:  2000 / 2475\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.8\n",
      "Detecting calls in probability streams:  0 / 2475\n",
      "Detecting calls in probability streams:  1000 / 2475\n",
      "Detecting calls in probability streams:  2000 / 2475\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.9\n",
      "Detecting calls in probability streams:  0 / 2475\n",
      "Detecting calls in probability streams:  1000 / 2475\n",
      "Detecting calls in probability streams:  2000 / 2475\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.95\n",
      "Detecting calls in probability streams:  0 / 2475\n",
      "Detecting calls in probability streams:  1000 / 2475\n",
      "Detecting calls in probability streams:  2000 / 2475\n",
      "*****************************************************************\n",
      "*****************************************************************\n",
      "File being processed : /home/kiran/Documents/MPI-Server/EAS_shared/meerkat/archive/rawdata/MEERKAT_RAW_DATA/2019/L_2019_1/COLLAR/AUDIO/L_VLF235_RSRTTBL_R26_20190805-20190812/L_VLF235_RSRTTBL_R26_20190805-20190812_file_12_(2019_08_11-07_44_59)_115944.wav\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.5\n",
      "Detecting calls in probability streams:  0 / 7199\n",
      "Detecting calls in probability streams:  1000 / 7199\n",
      "Detecting calls in probability streams:  2000 / 7199\n",
      "Detecting calls in probability streams:  3000 / 7199\n",
      "Detecting calls in probability streams:  4000 / 7199\n",
      "Detecting calls in probability streams:  5000 / 7199\n",
      "Detecting calls in probability streams:  6000 / 7199\n",
      "Detecting calls in probability streams:  7000 / 7199\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.6\n",
      "Detecting calls in probability streams:  0 / 7199\n",
      "Detecting calls in probability streams:  1000 / 7199\n",
      "Detecting calls in probability streams:  2000 / 7199\n",
      "Detecting calls in probability streams:  3000 / 7199\n",
      "Detecting calls in probability streams:  4000 / 7199\n",
      "Detecting calls in probability streams:  5000 / 7199\n",
      "Detecting calls in probability streams:  6000 / 7199\n",
      "Detecting calls in probability streams:  7000 / 7199\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.7\n",
      "Detecting calls in probability streams:  0 / 7199\n",
      "Detecting calls in probability streams:  1000 / 7199\n",
      "Detecting calls in probability streams:  2000 / 7199\n",
      "Detecting calls in probability streams:  3000 / 7199\n",
      "Detecting calls in probability streams:  4000 / 7199\n",
      "Detecting calls in probability streams:  5000 / 7199\n",
      "Detecting calls in probability streams:  6000 / 7199\n",
      "Detecting calls in probability streams:  7000 / 7199\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.8\n",
      "Detecting calls in probability streams:  0 / 7199\n",
      "Detecting calls in probability streams:  1000 / 7199\n",
      "Detecting calls in probability streams:  2000 / 7199\n",
      "Detecting calls in probability streams:  3000 / 7199\n",
      "Detecting calls in probability streams:  4000 / 7199\n",
      "Detecting calls in probability streams:  5000 / 7199\n",
      "Detecting calls in probability streams:  6000 / 7199\n",
      "Detecting calls in probability streams:  7000 / 7199\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.9\n",
      "Detecting calls in probability streams:  0 / 7199\n",
      "Detecting calls in probability streams:  1000 / 7199\n",
      "Detecting calls in probability streams:  2000 / 7199\n",
      "Detecting calls in probability streams:  3000 / 7199\n",
      "Detecting calls in probability streams:  4000 / 7199\n",
      "Detecting calls in probability streams:  5000 / 7199\n",
      "Detecting calls in probability streams:  6000 / 7199\n",
      "Detecting calls in probability streams:  7000 / 7199\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.95\n",
      "Detecting calls in probability streams:  0 / 7199\n",
      "Detecting calls in probability streams:  1000 / 7199\n",
      "Detecting calls in probability streams:  2000 / 7199\n",
      "Detecting calls in probability streams:  3000 / 7199\n",
      "Detecting calls in probability streams:  4000 / 7199\n",
      "Detecting calls in probability streams:  5000 / 7199\n",
      "Detecting calls in probability streams:  6000 / 7199\n",
      "Detecting calls in probability streams:  7000 / 7199\n",
      "*****************************************************************\n",
      "*****************************************************************\n",
      "File being processed : /home/kiran/Documents/MPI-Server/EAS_shared/meerkat/archive/rawdata/MEERKAT_RAW_DATA/2017/HM_2017_3/COLLAR/AUDIO/HM_VHMF001_HTB_R14_20170903-20170908/HM_VHMF001_HTB_R14_20170903-20170908_file_2_(2017_09_03-05_44_59)_ASWMUX221052.wav\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.5\n",
      "Detecting calls in probability streams:  0 / 7228\n",
      "Detecting calls in probability streams:  1000 / 7228\n",
      "Detecting calls in probability streams:  2000 / 7228\n",
      "Detecting calls in probability streams:  3000 / 7228\n",
      "Detecting calls in probability streams:  4000 / 7228\n",
      "Detecting calls in probability streams:  5000 / 7228\n",
      "Detecting calls in probability streams:  6000 / 7228\n",
      "Detecting calls in probability streams:  7000 / 7228\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.6\n",
      "Detecting calls in probability streams:  0 / 7228\n",
      "Detecting calls in probability streams:  1000 / 7228\n",
      "Detecting calls in probability streams:  2000 / 7228\n",
      "Detecting calls in probability streams:  3000 / 7228\n",
      "Detecting calls in probability streams:  4000 / 7228\n",
      "Detecting calls in probability streams:  5000 / 7228\n",
      "Detecting calls in probability streams:  6000 / 7228\n",
      "Detecting calls in probability streams:  7000 / 7228\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.7\n",
      "Detecting calls in probability streams:  0 / 7228\n",
      "Detecting calls in probability streams:  1000 / 7228\n",
      "Detecting calls in probability streams:  2000 / 7228\n",
      "Detecting calls in probability streams:  3000 / 7228\n",
      "Detecting calls in probability streams:  4000 / 7228\n",
      "Detecting calls in probability streams:  5000 / 7228\n",
      "Detecting calls in probability streams:  6000 / 7228\n",
      "Detecting calls in probability streams:  7000 / 7228\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.8\n",
      "Detecting calls in probability streams:  0 / 7228\n",
      "Detecting calls in probability streams:  1000 / 7228\n",
      "Detecting calls in probability streams:  2000 / 7228\n",
      "Detecting calls in probability streams:  3000 / 7228\n",
      "Detecting calls in probability streams:  4000 / 7228\n",
      "Detecting calls in probability streams:  5000 / 7228\n",
      "Detecting calls in probability streams:  6000 / 7228\n",
      "Detecting calls in probability streams:  7000 / 7228\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.9\n",
      "Detecting calls in probability streams:  0 / 7228\n",
      "Detecting calls in probability streams:  1000 / 7228\n",
      "Detecting calls in probability streams:  2000 / 7228\n",
      "Detecting calls in probability streams:  3000 / 7228\n",
      "Detecting calls in probability streams:  4000 / 7228\n",
      "Detecting calls in probability streams:  5000 / 7228\n",
      "Detecting calls in probability streams:  6000 / 7228\n",
      "Detecting calls in probability streams:  7000 / 7228\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.95\n",
      "Detecting calls in probability streams:  0 / 7228\n",
      "Detecting calls in probability streams:  1000 / 7228\n",
      "Detecting calls in probability streams:  2000 / 7228\n",
      "Detecting calls in probability streams:  3000 / 7228\n",
      "Detecting calls in probability streams:  4000 / 7228\n",
      "Detecting calls in probability streams:  5000 / 7228\n",
      "Detecting calls in probability streams:  6000 / 7228\n",
      "Detecting calls in probability streams:  7000 / 7228\n",
      "*****************************************************************\n",
      "*****************************************************************\n",
      "File being processed : /home/kiran/Documents/MPI-Server/EAS_shared/meerkat/archive/rawdata/MEERKAT_RAW_DATA/2019/HM_2019_2/COLLAR/AUDIO/HM_VHMM014_LSTB_R19_20190707-20190719/HM_VHMM014_LSTB_R19_20190707-20190719_file_6_(2019_07_12-11_44_59)_125944.wav\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.5\n",
      "Detecting calls in probability streams:  0 / 1585\n",
      "Detecting calls in probability streams:  1000 / 1585\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.6\n",
      "Detecting calls in probability streams:  0 / 1585\n",
      "Detecting calls in probability streams:  1000 / 1585\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.7\n",
      "Detecting calls in probability streams:  0 / 1585\n",
      "Detecting calls in probability streams:  1000 / 1585\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.8\n",
      "Detecting calls in probability streams:  0 / 1585\n",
      "Detecting calls in probability streams:  1000 / 1585\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.9\n",
      "Detecting calls in probability streams:  0 / 1585\n",
      "Detecting calls in probability streams:  1000 / 1585\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.95\n",
      "Detecting calls in probability streams:  0 / 1585\n",
      "Detecting calls in probability streams:  1000 / 1585\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.5\n",
      "Detecting calls in probability streams:  0 / 135\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.6\n",
      "Detecting calls in probability streams:  0 / 135\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.7\n",
      "Detecting calls in probability streams:  0 / 135\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.8\n",
      "Detecting calls in probability streams:  0 / 135\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.9\n",
      "Detecting calls in probability streams:  0 / 135\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.95\n",
      "Detecting calls in probability streams:  0 / 135\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.5\n",
      "Detecting calls in probability streams:  0 / 1365\n",
      "Detecting calls in probability streams:  1000 / 1365\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.6\n",
      "Detecting calls in probability streams:  0 / 1365\n",
      "Detecting calls in probability streams:  1000 / 1365\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.7\n",
      "Detecting calls in probability streams:  0 / 1365\n",
      "Detecting calls in probability streams:  1000 / 1365\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.8\n",
      "Detecting calls in probability streams:  0 / 1365\n",
      "Detecting calls in probability streams:  1000 / 1365\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.9\n",
      "Detecting calls in probability streams:  0 / 1365\n",
      "Detecting calls in probability streams:  1000 / 1365\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.95\n",
      "Detecting calls in probability streams:  0 / 1365\n",
      "Detecting calls in probability streams:  1000 / 1365\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.5\n",
      "Detecting calls in probability streams:  0 / 4300\n",
      "Detecting calls in probability streams:  1000 / 4300\n",
      "Detecting calls in probability streams:  2000 / 4300\n",
      "Detecting calls in probability streams:  3000 / 4300\n",
      "Detecting calls in probability streams:  4000 / 4300\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.6\n",
      "Detecting calls in probability streams:  0 / 4300\n",
      "Detecting calls in probability streams:  1000 / 4300\n",
      "Detecting calls in probability streams:  2000 / 4300\n",
      "Detecting calls in probability streams:  3000 / 4300\n",
      "Detecting calls in probability streams:  4000 / 4300\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.7\n",
      "Detecting calls in probability streams:  0 / 4300\n",
      "Detecting calls in probability streams:  1000 / 4300\n",
      "Detecting calls in probability streams:  2000 / 4300\n",
      "Detecting calls in probability streams:  3000 / 4300\n",
      "Detecting calls in probability streams:  4000 / 4300\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.8\n",
      "Detecting calls in probability streams:  0 / 4300\n",
      "Detecting calls in probability streams:  1000 / 4300\n",
      "Detecting calls in probability streams:  2000 / 4300\n",
      "Detecting calls in probability streams:  3000 / 4300\n",
      "Detecting calls in probability streams:  4000 / 4300\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.9\n",
      "Detecting calls in probability streams:  0 / 4300\n",
      "Detecting calls in probability streams:  1000 / 4300\n",
      "Detecting calls in probability streams:  2000 / 4300\n",
      "Detecting calls in probability streams:  3000 / 4300\n",
      "Detecting calls in probability streams:  4000 / 4300\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.95\n",
      "Detecting calls in probability streams:  0 / 4300\n",
      "Detecting calls in probability streams:  1000 / 4300\n",
      "Detecting calls in probability streams:  2000 / 4300\n",
      "Detecting calls in probability streams:  3000 / 4300\n",
      "Detecting calls in probability streams:  4000 / 4300\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.5\n",
      "Detecting calls in probability streams:  0 / 5740\n",
      "Detecting calls in probability streams:  1000 / 5740\n",
      "Detecting calls in probability streams:  2000 / 5740\n",
      "Detecting calls in probability streams:  3000 / 5740\n",
      "Detecting calls in probability streams:  4000 / 5740\n",
      "Detecting calls in probability streams:  5000 / 5740\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.6\n",
      "Detecting calls in probability streams:  0 / 5740\n",
      "Detecting calls in probability streams:  1000 / 5740\n",
      "Detecting calls in probability streams:  2000 / 5740\n",
      "Detecting calls in probability streams:  3000 / 5740\n",
      "Detecting calls in probability streams:  4000 / 5740\n",
      "Detecting calls in probability streams:  5000 / 5740\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.7\n",
      "Detecting calls in probability streams:  0 / 5740\n",
      "Detecting calls in probability streams:  1000 / 5740\n",
      "Detecting calls in probability streams:  2000 / 5740\n",
      "Detecting calls in probability streams:  3000 / 5740\n",
      "Detecting calls in probability streams:  4000 / 5740\n",
      "Detecting calls in probability streams:  5000 / 5740\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.8\n",
      "Detecting calls in probability streams:  0 / 5740\n",
      "Detecting calls in probability streams:  1000 / 5740\n",
      "Detecting calls in probability streams:  2000 / 5740\n",
      "Detecting calls in probability streams:  3000 / 5740\n",
      "Detecting calls in probability streams:  4000 / 5740\n",
      "Detecting calls in probability streams:  5000 / 5740\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.9\n",
      "Detecting calls in probability streams:  0 / 5740\n",
      "Detecting calls in probability streams:  1000 / 5740\n",
      "Detecting calls in probability streams:  2000 / 5740\n",
      "Detecting calls in probability streams:  3000 / 5740\n",
      "Detecting calls in probability streams:  4000 / 5740\n",
      "Detecting calls in probability streams:  5000 / 5740\n",
      "*****************************************************************\n",
      "Low Threshold: 0.1\n",
      "High Threshold: 0.95\n",
      "Detecting calls in probability streams:  0 / 5740\n",
      "Detecting calls in probability streams:  1000 / 5740\n",
      "Detecting calls in probability streams:  2000 / 5740\n",
      "Detecting calls in probability streams:  3000 / 5740\n",
      "Detecting calls in probability streams:  4000 / 5740\n",
      "Detecting calls in probability streams:  5000 / 5740\n",
      "*****************************************************************\n",
      "*****************************************************************\n",
      "File being processed : /home/kiran/Documents/MPI-Server/EAS_shared/meerkat/archive/rawdata/MEERKAT_RAW_DATA/2019/L_2019_1/COLLAR/AUDIO/L_VLF244_HTBL_R02_20190805-20190812/L_VLF244_HTBL_R02_20190805-20190812_file_11_(2019_08_10-07_44_59)_105944.wav\n"
     ]
    }
   ],
   "source": [
    "for sensitivity_i in train_pattern:  \n",
    "    #sensitivity_i = ['VHMM003']\n",
    "\n",
    "\n",
    "    ### SETUP file structure for sensitivity runs\n",
    "    #------------------------------------------------------------\n",
    "    run_name = \"NoiseAugmented_\"+ str(min_scaling_factor)+\"_\" +str(max_scaling_factor)+\"_NotWeighted_MaskedOther_Forked_trained_with_\" + '_'.join(sensitivity_i)\n",
    "\n",
    "    # basically the root directory for train, test and model\n",
    "    save_data_path = os.path.join(results_dir, run_name)\n",
    "    if not os.path.isdir(save_data_path):\n",
    "        os.makedirs(save_data_path)\n",
    "\n",
    "    # Test folders\n",
    "    test_path = os.path.join(save_data_path, 'test_data')\n",
    "    if not os.path.isdir(test_path):\n",
    "        os.makedirs(test_path)\n",
    "\n",
    "\n",
    "    save_pred_test_path = os.path.join(test_path , \"predictions\")\n",
    "    if not os.path.isdir(save_pred_test_path):\n",
    "        os.makedirs(save_pred_test_path)\n",
    "\n",
    "    save_pred_stack_test_path = os.path.join(save_pred_test_path,\"stacks\")\n",
    "    if not os.path.isdir(save_pred_stack_test_path):\n",
    "        os.makedirs(save_pred_stack_test_path)        \n",
    "\n",
    "    save_pred_table_test_path = os.path.join(save_pred_test_path,\"pred_table\")\n",
    "    if not os.path.isdir(save_pred_table_test_path):\n",
    "        os.makedirs(save_pred_table_test_path)\n",
    "\n",
    "    save_label_table_test_path = os.path.join(test_path, 'label_table')\n",
    "    if not os.path.isdir(save_label_table_test_path):\n",
    "        os.makedirs(save_label_table_test_path)\n",
    "\n",
    "    save_metrics_path = os.path.join(test_path , \"metrics\")\n",
    "    if not os.path.isdir(save_metrics_path):\n",
    "        os.makedirs(save_metrics_path)\n",
    "\n",
    "    save_metrics_path_eval = os.path.join(save_metrics_path, eval_analysis)\n",
    "    if not os.path.isdir(save_metrics_path_eval):\n",
    "        os.makedirs(save_metrics_path_eval)\n",
    "\n",
    "\n",
    "    # Model folder\n",
    "    save_model_path = os.path.join(save_data_path, 'trained_model')\n",
    "    if not os.path.isdir(save_model_path):\n",
    "        os.makedirs(save_model_path)\n",
    "\n",
    "\n",
    "    training_files = label_table['wavFileName'][label_table['date'].isin(sensitivity_i)].unique()\n",
    "    testing_filenames = label_table['wavFileName'][label_table['date'].isin(sensitivity_i) == False].unique()\n",
    "\n",
    "\n",
    "\n",
    "    if len(training_files) > 100:\n",
    "        shuffle(training_files)\n",
    "        training_files = training_files[0:100]\n",
    "\n",
    "    if len(testing_filenames) > 11:\n",
    "        shuffle(testing_filenames)\n",
    "        #validation_filenames = testing_filenames[:4]\n",
    "        testing_filenames = testing_filenames[0:11]\n",
    "\n",
    "\n",
    "    # Split the training and test set based on the separation\n",
    "    split_index = floor(len(training_files) * train_val_split )\n",
    "    shuffle(training_files)\n",
    "    training_filenames = training_files#[:split_index] # am no longer separating the training and val here because\n",
    "    #validation_filenames = training_files[split_index:]\n",
    "\n",
    "\n",
    "    # save a copy of the training and testing diles\n",
    "    with open(os.path.join(save_model_path, \"training_files_used.txt\"), \"w\") as f:\n",
    "        for s in training_filenames:\n",
    "            f.write(str(s) +\"\\n\")\n",
    "    with open(os.path.join(save_model_path, \"testing_files_used.txt\"), \"w\") as f:\n",
    "        for s in testing_filenames:\n",
    "            f.write(str(s) +\"\\n\")\n",
    "    # with open(os.path.join(save_model_path, \"validation_files_used.txt\"), \"w\") as f:\n",
    "    #    for s in validation_filenames:\n",
    "    #       f.write(str(s) +\"\\n\")\n",
    "\n",
    "\n",
    "    '''Then we create a dictionary that will be used in the datagenerator. \n",
    "    Each key is a calltype and contains the start/stop/duration/filename where that call occurs. \n",
    "    This allows the data generator to shuffle them during the training.\n",
    "    '''\n",
    "\n",
    "    # separate out the training and test sets for analysis\n",
    "    training_label_full_table = label_table[label_table['wavFileName'].isin(training_filenames)]\n",
    "    testing_label_table = label_table[label_table['wavFileName'].isin(testing_filenames)]\n",
    "    #validation_label_table = label_table[label_table['wavFileName'].isin(validation_filenames)]\n",
    "\n",
    "    # do the same for the noise\n",
    "    training_noise_table = noise_table[noise_table['wavFileName'].isin(training_filenames)]\n",
    "    testing_noise_table = noise_table[noise_table['wavFileName'].isin(testing_filenames)]\n",
    "    #validation_noise_table = noise_table[noise_table['wavFileName'].isin(validation_filenames)]\n",
    "\n",
    "    # Compile test data into a format that the data generator can use\n",
    "    testing_label_dict = dict()\n",
    "    for label in call_types: \n",
    "        testing_label_dict[label] = testing_label_table.loc[testing_label_table[label] == True, [\"Label\", \"Start\", \"Duration\",\"End\",\"wav_path\",\"label_path\"]]\n",
    "    testing_label_dict[label_for_noise] = testing_noise_table[[\"Label\", \"Start\", \"Duration\",\"End\",\"wav_path\",\"label_path\"]]\n",
    "\n",
    "    # Compile training data into a format that the data generator can use\n",
    "    training_label_full_dict = dict()\n",
    "    '''training_label_dict = dict()\n",
    "    validation_label_dict = dict()\n",
    "    training_label_table = pd.DataFrame()\n",
    "    validation_label_table = pd.DataFrame()'''\n",
    "    for label in call_types: \n",
    "        training_label_full_dict[label] = training_label_full_table.loc[training_label_full_table[label] == True, [\"Label\", \"Start\", \"Duration\",\"End\",\"wav_path\",\"label_path\"]]\n",
    "    training_label_full_dict[label_for_noise] = training_noise_table[[\"Label\", \"Start\", \"Duration\",\"End\",\"wav_path\",\"label_path\"]]\n",
    "\n",
    "    #to deal with small datasets, the call_types that are not available for training need to be removed.\n",
    "    #call = training_label_full_dict.keys()\n",
    "    for call in list(training_label_full_dict):\n",
    "        if training_label_full_dict[call].shape[0] < 2:\n",
    "            del training_label_full_dict[call]\n",
    "            del testing_label_dict[call]\n",
    "\n",
    "    # subset validation from training dict\n",
    "    training_label_dict = dict()\n",
    "    validation_label_dict = dict()\n",
    "    for label in training_label_full_dict:        \n",
    "        # reshuffle rows\n",
    "        #training_label_full_dict[label] = training_label_full_dict[label].sample(frac=1)#.reset_index(drop=True)\n",
    "        #subset by training and test set        \n",
    "        split_index = floor(len(training_label_full_dict[label][\"Label\"]) * train_val_split )\n",
    "        training_label_dict[label] = training_label_full_dict[label].iloc[:split_index]#.reset_index(drop = True)\n",
    "        validation_label_dict[label] = training_label_full_dict[label].iloc[split_index:]#.reset_index(drop = True)\n",
    "\n",
    "    shuffle(training_files)\n",
    "    training_filenames = training_files#[:split_index]\n",
    "\n",
    "\n",
    "    # Compile validation data into a format that the data generator can use\n",
    "    #validation_label_dict = dict()\n",
    "    #for label in call_types: \n",
    "    #    validation_label_dict[label] = validation_label_table.loc[validation_label_table[label] == True, [\"Label\", \"Start\", \"Duration\",\"End\",\"wav_path\",\"label_path\"]]\n",
    "    #validation_label_dict[label_for_noise] = validation_label_table[[\"Label\", \"Start\", \"Duration\",\"End\",\"wav_path\",\"label_path\"]]\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    # TRAINING\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    ## Build the training and validation data generators (for real this time)\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "    if is_forked == True:\n",
    "        # initiate the data generator\n",
    "        train_generator = bg.ForkedDataGenerator(training_label_dict,\n",
    "                                                 #training_label_table, \n",
    "                                                 training_label_full_table,\n",
    "                                                 spec_window_size,\n",
    "                                                 n_mels, \n",
    "                                                 window, \n",
    "                                                 fft_win , \n",
    "                                                 fft_hop , \n",
    "                                                 normalise,\n",
    "                                                 label_for_noise,\n",
    "                                                 label_for_other,\n",
    "                                                 min_scaling_factor,\n",
    "                                                 max_scaling_factor,\n",
    "                                                 n_per_call,\n",
    "                                                 other_ignored_in_training,\n",
    "                                                 mask_value,\n",
    "                                                 mask_vector)\n",
    "\n",
    "        # get a batch to estimate rnn parameters\n",
    "        x_train, y_train = train_generator.__next__()#__getitem__(0)\n",
    "\n",
    "        # initial parameters\n",
    "        num_calltypes = y_train[0].shape[2]\n",
    "        gru_units = y_train[0].shape[1] \n",
    "\n",
    "\n",
    "        # initialise the training data generator and validation data generator\n",
    "        train_generator = bg.ForkedDataGenerator(training_label_dict,\n",
    "                                                 #training_label_table, \n",
    "                                                 training_label_full_table,\n",
    "                                                 spec_window_size,\n",
    "                                                 n_mels, \n",
    "                                                 window, \n",
    "                                                 fft_win , \n",
    "                                                 fft_hop , \n",
    "                                                 normalise,\n",
    "                                                 label_for_noise,\n",
    "                                                 label_for_other,\n",
    "                                                 min_scaling_factor,\n",
    "                                                 max_scaling_factor,\n",
    "                                                 n_per_call,\n",
    "                                                 other_ignored_in_training,\n",
    "                                                 mask_value,\n",
    "                                                 mask_vector)\n",
    "\n",
    "        val_generator = bg.ForkedDataGenerator(validation_label_dict,\n",
    "                                               #validation_label_table, \n",
    "                                               training_label_full_table,\n",
    "                                               spec_window_size,\n",
    "                                               n_mels, \n",
    "                                               window, \n",
    "                                               fft_win , \n",
    "                                               fft_hop , \n",
    "                                               normalise,\n",
    "                                               label_for_noise,\n",
    "                                               label_for_other,\n",
    "                                               min_scaling_factor,\n",
    "                                               max_scaling_factor,\n",
    "                                               n_per_call,\n",
    "                                               other_ignored_in_training,\n",
    "                                               mask_value,\n",
    "                                               mask_vector)\n",
    "\n",
    "    else:\n",
    "        train_generator = bg.DataGenerator(training_label_dict,\n",
    "                                                 #training_label_table, \n",
    "                                                 training_label_full_table,\n",
    "                                                 spec_window_size,\n",
    "                                                 n_mels, \n",
    "                                                 window, \n",
    "                                                 fft_win , \n",
    "                                                 fft_hop , \n",
    "                                                 normalise,\n",
    "                                                 label_for_noise,\n",
    "                                                 label_for_other,\n",
    "                                                 min_scaling_factor,\n",
    "                                                 max_scaling_factor,\n",
    "                                                 n_per_call,\n",
    "                                                 other_ignored_in_training,\n",
    "                                                 mask_value,\n",
    "                                                 mask_vector)\n",
    "        x_train, y_train = train_generator.__next__()#__getitem__(0)\n",
    "\n",
    "        # initial parameters\n",
    "        num_calltypes = y_train[0].shape[2]\n",
    "        gru_units = y_train[0].shape[1] \n",
    "\n",
    "        train_generator = bg.DataGenerator(training_label_dict,\n",
    "                                                 #training_label_table, \n",
    "                                                 training_label_full_table,\n",
    "                                                 spec_window_size,\n",
    "                                                 n_mels, \n",
    "                                                 window, \n",
    "                                                 fft_win , \n",
    "                                                 fft_hop , \n",
    "                                                 normalise,\n",
    "                                                 label_for_noise,\n",
    "                                                 label_for_other,\n",
    "                                                 min_scaling_factor,\n",
    "                                                 max_scaling_factor,\n",
    "                                                 n_per_call,\n",
    "                                                 other_ignored_in_training,\n",
    "                                                 mask_value,\n",
    "                                                 mask_vector)\n",
    "\n",
    "        val_generator = bg.DataGenerator(validation_label_dict,\n",
    "                                         training_label_full_table,      \n",
    "                                         #validation_label_table, \n",
    "                                               spec_window_size,\n",
    "                                               n_mels, \n",
    "                                               window, \n",
    "                                               fft_win , \n",
    "                                               fft_hop , \n",
    "                                               normalise,\n",
    "                                               label_for_noise,\n",
    "                                               label_for_other,\n",
    "                                               min_scaling_factor,\n",
    "                                               max_scaling_factor,\n",
    "                                               n_per_call,\n",
    "                                               other_ignored_in_training,\n",
    "                                               mask_value,\n",
    "                                               mask_vector)    \n",
    "\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    ## CONSTRUCT THE RNN\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    # initialise the model class\n",
    "    model = rnn.BuildNetwork(x_train, num_calltypes, filters, gru_units, dense_neurons, dropout, mask_value)\n",
    "\n",
    "    # build the model\n",
    "    if is_forked == True:\n",
    "        RNN_model = model.build_forked_masked_rnn()\n",
    "\n",
    "        # Multiple target losses\n",
    "        losses = {\n",
    "            'output_calltype' : 'categorical_crossentropy',  # classification\n",
    "            'output_callpresence' : 'mse'  # regression 0-1\n",
    "        }\n",
    "\n",
    "        loss_weights = {\n",
    "            'output_calltype' : 1.0,\n",
    "            'output_callpresence' : 0.05  # Making this too large is not a good idea as we really want the network paying attention to class\n",
    "        }\n",
    "        accuracy_metrics = {\n",
    "            'output_calltype' : 'categorical_accuracy',\n",
    "            'output_callpresence' : 'binary_accuracy'\n",
    "\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        RNN_model = model.build_masked_rnn()\n",
    "        # only one target loss\n",
    "        losses = 'categorical_crossentropy'\n",
    "        loss_weights = None\n",
    "        accuracy_metrics = 'categorical_accuracy'\n",
    "\n",
    "    # Adam optimiser\n",
    "    adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "    # Compile the model\n",
    "    #RNN_model.compile(optimizer=adam, loss=losses, loss_weights=loss_weights, metrics=['binary_accuracy'])\n",
    "    RNN_model.compile(optimizer=adam, loss=losses, loss_weights=loss_weights, metrics = accuracy_metrics)\n",
    "\n",
    "    # Setup callbycks: learning rate / loss /tensorboard\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True, verbose=1)\n",
    "    reduce_lr_plat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=25, verbose=1,\n",
    "                                       mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.000001)\n",
    "    loss = LossHistory()\n",
    "\n",
    "    # setup a path with a timestamp\n",
    "    date_time = datetime.datetime.now()\n",
    "    date_now = str(date_time.date())\n",
    "    time_now = str(date_time.time())\n",
    "    save_tensorboard_path = os.path.join(save_model_path, \"tensorboard_logs_\" + date_now + \"_\" + time_now)\n",
    "    if not os.path.isdir(save_tensorboard_path):\n",
    "        os.makedirs(save_tensorboard_path)   \n",
    "\n",
    "    # tensorboard\n",
    "    tensorboard = TensorBoard(log_dir = save_tensorboard_path,\n",
    "                              histogram_freq=0,\n",
    "                              write_graph=True,  # Show the network\n",
    "                              write_grads=True   # Show gradients\n",
    "                              )  \n",
    "    # fit model\n",
    "    RNN_model.fit_generator(train_generator, \n",
    "                            steps_per_epoch = train_generator.__len__(),\n",
    "                            epochs = epochs,\n",
    "                            callbacks = [early_stopping, reduce_lr_plat, loss, tensorboard],\n",
    "                            validation_data = val_generator,\n",
    "                            validation_steps = val_generator.__len__())\n",
    "\n",
    "\n",
    "    # Look at the model\n",
    "    # plot_model(RNN_model, run_name + \".png\", show_shapes=True)\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    ## SAVE THE MODEL\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    # save the model\n",
    "    date_time = datetime.datetime.now()\n",
    "    date_now = str(date_time.date())\n",
    "    time_now = str(date_time.time())\n",
    "    sf = os.path.join(save_model_path, run_name+ \"_\" + date_now + \"_\" + time_now)\n",
    "    if not os.path.isdir(sf):\n",
    "        os.makedirs(sf)\n",
    "\n",
    "    RNN_model.save(sf + '/savedmodel' + '.h5')\n",
    "\n",
    "    print(sf)\n",
    "\n",
    "    test = load_model(sf + '/savedmodel' + '.h5')\n",
    "    test.summary()\n",
    "    #test.predict([spec])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    ## TESTING\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    ## Predict over the test files\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    skipped_files = []\n",
    "\n",
    "    # we only do one file in this example to avoid it running too long\n",
    "    for file_ID in testing_filenames:\n",
    "        # file_ID = testing_filenames[0] # for testing purposes only\n",
    "\n",
    "        # subset the label table to only use that one file\n",
    "        file_label_table = pd.DataFrame(testing_label_table[testing_label_table['wavFileName'].isin([file_ID])])\n",
    "\n",
    "        #sometimes the labels are missing and categorise those as \"oth\"\n",
    "        file_label_table['Label'] = file_label_table['Label'].replace(np.nan, \"oth\")\n",
    "\n",
    "        file_label_table = file_label_table.sort_values(by=['Start']).reset_index()\n",
    "        # Find the file ID name i.e. remove the extention\n",
    "        file_ID = file_ID.split(\".\")[0] \n",
    "        # find the matching audio for the label data\n",
    "        audio_path = file_label_table[\"wav_path\"][0]   \n",
    "\n",
    "        print(\"*****************************************************************\")   \n",
    "        print(\"*****************************************************************\") \n",
    "        print (\"File being processed : \" + audio_path)    \n",
    "\n",
    "        # find the start and stop  of the labelling periods (also using skipon/skipoff)\n",
    "        loop_table = file_label_table.loc[file_label_table[\"Label\"].str.contains('|'.join(label_for_startstop), regex=True, case = False), [\"Label\",\"Start\"]]\n",
    "        loop_times = list(loop_table[\"Start\"])\n",
    "\n",
    "        # Make sure that the file contains the right number of start and stops, otherwise go to the next file\n",
    "        if len(loop_times)%2 != 0:\n",
    "            print(\"!!!!!!!!!!!!!!!!\")\n",
    "            warnings.warn(\"There is a missing start or stop in this file and it has been skipped: \" + audio_path)\n",
    "            skipped_files.append(file_ID)\n",
    "            continue \n",
    "\n",
    "        if len(loop_times) == 0:\n",
    "            print(\"!!!!!!!!!!!!!!!!\")\n",
    "            warnings.warn(\"There is a missing start or stop in this file and it has been skipped: \" + audio_path)\n",
    "            skipped_files.append(file_ID)\n",
    "            continue \n",
    "\n",
    "        # save the label_table\n",
    "        save_label_table_filename = file_ID + \"_LABEL_TABLE.txt\"\n",
    "        file_label_table.to_csv(os.path.join(save_label_table_test_path, save_label_table_filename), \n",
    "                            header=True, index=None, sep=';')\n",
    "\n",
    "        # load the audio data\n",
    "        y, sr = librosa.load(audio_path, sr=None, mono=False)\n",
    "\n",
    "        # # Reshaping the Audio file (mono) to deal with all wav files similarly\n",
    "        # if y.ndim == 1:\n",
    "        #     y = y.reshape(1, -1)\n",
    "\n",
    "        # # Implement this for acc data\n",
    "        # for ch in range(y.shape[0]):\n",
    "        # ch=0\n",
    "        # y_sub = y[:,ch]\n",
    "        y_sub = y\n",
    "\n",
    "        # loop through every labelling start based on skipon/off within this loop_table\n",
    "        for loopi in range(0, int(len(loop_times)), 2):\n",
    "            # loopi = 0\n",
    "            fromi =  loop_times[loopi]\n",
    "            #toi = fromi + 5\n",
    "            toi = loop_times[int(loopi + 1)] # define the end of the labelling periods\n",
    "\n",
    "            calltype_pred_list = []\n",
    "            callpresence_pred_list = []\n",
    "            # if the file exists, load it\n",
    "            if os.path.exists(os.path.join(save_pred_stack_test_path, file_ID + '_CALLTYPE_PRED_STACK_' + str(fromi) + '-' + str(toi) + '.npy')): \n",
    "                calltype_pred_list = np.load( os.path.join(save_pred_stack_test_path, file_ID + '_CALLTYPE_PRED_STACK_' + str(fromi) + '-' + str(toi) + '.npy')) \n",
    "                callpresence_pred_list = np.load( os.path.join(save_pred_stack_test_path, file_ID + '_CALLPRESENCE_PRED_STACK_' + str(fromi) + '-' + str(toi) + '.npy'))\n",
    "\n",
    "\n",
    "            # if the file is incomplete or non existant redo it\n",
    "            if (len(np.arange(fromi, toi, slide)) - sum(np.arange(fromi, toi, slide)+spec_window_size > toi)) != (len(calltype_pred_list)):\n",
    "\n",
    "                for spectro_slide in np.arange(fromi, toi, slide):                \n",
    "                    # spectro_slide = fromi\n",
    "                    start = round(spectro_slide,3)\n",
    "                    stop = round(spectro_slide + spec_window_size, 3)\n",
    "\n",
    "                    # ignore cases where the window is larger than what is labelled (e.g. at the end)\n",
    "                    if stop <= toi:\n",
    "\n",
    "                        #generate the spectrogram\n",
    "                        spectro = pre.generate_mel_spectrogram(y=y_sub, sr=sr, start=start, stop=stop, \n",
    "                                                                n_mels = n_mels, window='hann', \n",
    "                                                                fft_win= fft_win, fft_hop = fft_hop, \n",
    "                                                                normalise = True)\n",
    "\n",
    "                        # transpose it and put it in a format that works with the NN\n",
    "                        spec = spectro.T\n",
    "                        spec = spec[np.newaxis, ..., np.newaxis]  \n",
    "\n",
    "                        # generate a mask (as a placeholder) but don't mask anything as we are predicting and want to include other\n",
    "                        mask = np.asarray([True for i in range(spectro.shape[1])])\n",
    "                        mask = mask[np.newaxis,...]\n",
    "\n",
    "                        # generate the prediction\n",
    "                        pred = RNN_model.predict([spec,mask])\n",
    "\n",
    "                        # add this prediction to the stack that will be used to generate the predictions table\n",
    "                        if is_forked:\n",
    "                            calltype_pred_list.append(np.squeeze(pred[0]))\n",
    "                            callpresence_pred_list.append(np.squeeze(pred[1]))\n",
    "                        else:\n",
    "                            calltype_pred_list.append(np.squeeze(pred))\n",
    "\n",
    "                # save the prediction stacks\n",
    "                np.save( os.path.join(save_pred_stack_test_path, file_ID + '_CALLTYPE_PRED_STACK_' + str(fromi) + '-' + str(toi) + '.npy'), calltype_pred_list)\n",
    "                with open(os.path.join(save_pred_stack_test_path, file_ID + '_CALLTYPE_PRED_STACK_' + str(fromi) + '-' + str(toi) + '.txt'), \"w\") as f:\n",
    "                    for row in calltype_pred_list:\n",
    "                        f.write(str(row) +\"\\n\")\n",
    "                if is_forked:      \n",
    "                    np.save( os.path.join(save_pred_stack_test_path, file_ID + '_CALLPRESENCE_PRED_STACK_' + str(fromi) + '-' + str(toi) + '.npy'), callpresence_pred_list)\n",
    "                    with open(os.path.join(save_pred_stack_test_path, file_ID + '_CALLPRESENCE_PRED_STACK_' + str(fromi) + '-' + str(toi) + '.txt'), \"w\") as f:\n",
    "                        for row in callpresence_pred_list:\n",
    "                            f.write(str(row) +\"\\n\")\n",
    "\n",
    "            # Loop through different sets of thresholds\n",
    "            for low_thr in [0.1]:\n",
    "                for high_thr in [0.5,0.6,0.7,0.8,0.9,0.95]: \n",
    "\n",
    "                    # make sure it doesnt generate a 0.00098982374957839486 type number\n",
    "                    low_thr = round(low_thr,2)                               \n",
    "                    high_thr = round(high_thr,2)\n",
    "\n",
    "                    # stop the loop if the low threshold is bigger than the high threshold\n",
    "                    if low_thr >= high_thr:\n",
    "                        continue\n",
    "\n",
    "                    save_pred_table_filename = file_ID + \"_CALLTYPE_PRED_TABLE_thr_\" + str(low_thr) + \"-\" + str(high_thr) + \".txt\"\n",
    "\n",
    "                    # if the file exists, pass to the next iteration of the loop\n",
    "                    #if os.path.exists(os.path.join(save_pred_table_test_path, save_pred_table_filename)):\n",
    "                    #    continue\n",
    "\n",
    "                    print(\"*****************************************************************\") \n",
    "                    print (\"Low Threshold: \" + str(low_thr))    \n",
    "                    print (\"High Threshold: \" + str(high_thr))  \n",
    "\n",
    "                    #----------------------------------------------------------------------------\n",
    "                    # Compile the predictions for each on/off labelling chunk\n",
    "                    detections = ppm.merge_p(probabilities = calltype_pred_list, \n",
    "                                              labels=list(testing_label_dict.keys()),#list(call_types.keys()),\n",
    "                                              starttime = 0, \n",
    "                                              frameadv_s = fft_hop, \n",
    "                                              specadv_s = slide,\n",
    "                                              low_thr=low_thr, \n",
    "                                              high_thr=high_thr, \n",
    "                                              debug=1)\n",
    "\n",
    "                    #in case the dataset was just noise, still create an empty placeholder to merge\n",
    "                    if len(detections) == 0:  \n",
    "                        detections = pd.DataFrame(columns = ['category', 'start', 'end', 'scores'])\n",
    "\n",
    "                    # create an empty dataset\n",
    "                    pred_table = pd.DataFrame() \n",
    "\n",
    "                    #convert these detections to a predictions table                \n",
    "                    table = pd.DataFrame(detections)\n",
    "                    table[\"Label\"] = table[\"category\"]\n",
    "                    table[\"Start\"] = round(table[\"start\"]*fft_hop + fromi, 3) #table[\"start\"].apply(Decimal)*Decimal(fft_hop) + Decimal(fromi)\n",
    "                    table[\"Duration\"] = round( (table[\"end\"]-table[\"start\"])*fft_hop, 3) #(table[\"end\"].apply(Decimal)-table[\"start\"].apply(Decimal))*Decimal(fft_hop)\n",
    "                    table[\"End\"] = round(table[\"end\"]*fft_hop + fromi, 3) #table[\"Start\"].apply(Decimal) + table[\"Duration\"].apply(Decimal)\n",
    "\n",
    "                    # keep only the useful columns    \n",
    "                    table = table[[\"Label\",\"Start\",\"Duration\", \"End\", \"scores\"]]  \n",
    "\n",
    "                    # Add a row which stores the start of the labelling period\n",
    "                    row_start = pd.DataFrame()\n",
    "                    row_start.loc[0,'Label'] = list(loop_table[\"Label\"])[loopi]\n",
    "                    row_start.loc[0,'Start'] = fromi\n",
    "                    row_start.loc[0,'Duration'] = 0\n",
    "                    row_start.loc[0,'End'] = fromi \n",
    "                    row_start.loc[0,'scores'] = [0] \n",
    "\n",
    "                    # Add a row which stores the end of the labelling period\n",
    "                    row_stop = pd.DataFrame()\n",
    "                    row_stop.loc[0,'Label'] = list(loop_table[\"Label\"])[int(loopi + 1)]\n",
    "                    row_stop.loc[0,'Start'] = toi\n",
    "                    row_stop.loc[0,'Duration'] = 0\n",
    "                    row_stop.loc[0,'End'] = toi \n",
    "                    row_stop.loc[0,'scores'] = [0]       \n",
    "\n",
    "                    # add the true false columns based on the call types dictionary\n",
    "                    for true_label in call_types:\n",
    "                        table[true_label] = False\n",
    "                        row_start[true_label] = False\n",
    "                        row_stop[true_label] = False\n",
    "                        for old_label in call_types[true_label]:\n",
    "                            table.loc[table[\"Label\"].str.contains(old_label, regex=True, case = False), true_label] = True\n",
    "\n",
    "                    # make sure start and stop are not classified as calls\n",
    "                    row_start[label_for_noise] = True\n",
    "                    row_stop[label_for_noise] = True\n",
    "\n",
    "                    # put these rows to the label table\n",
    "                    table = pd.concat([row_start, table, row_stop]) \n",
    "\n",
    "                    # add this table to the overall predictions table for that collar\n",
    "                    pred_table = pd.concat([pred_table, table ])\n",
    "\n",
    "                    # for each on/off labelling chunk, we can save the prediction and append it to the previous chunk\n",
    "                    if loopi == 0:                    \n",
    "                        # for the first chunck keep the header, but not when appending later. Also, overwrite old runs\n",
    "                        pred_table.to_csv(os.path.join(save_pred_table_test_path, save_pred_table_filename), \n",
    "                                          header=True, index=None, sep=';', mode = 'w')\n",
    "                    else:\n",
    "                        pred_table.to_csv(os.path.join(save_pred_table_test_path, save_pred_table_filename), \n",
    "                                          header=None, index=None, sep=';', mode = 'a')\n",
    "\n",
    "    '''\n",
    "    # # load the saved file\n",
    "    # with open(os.path.join(save_pred_stack_test_path, file_ID + '_PRED_STACK.txt')) as f:\n",
    "    #     content = f.readlines()\n",
    "    # # remove whitespace characters like `\\n` at the end of each line\n",
    "    # pred_list = [x.strip() for x in content] \n",
    "\n",
    "\n",
    "    # #or\n",
    "    # pred_list = np.load( os.path.join(save_pred_stack_test_path, file_ID + '_PRED_STACK.npy'))\n",
    "    # '''\n",
    "\n",
    "    # save the files that were skipped\n",
    "    print(skipped_files)\n",
    "\n",
    "    # save a copy of the training and testing diles\n",
    "    with open(os.path.join(save_model_path, \"skipped_testing_files.txt\"), \"w\") as f:\n",
    "        for s in skipped_files:\n",
    "            f.write(str(s) +\"\\n\")\n",
    "\n",
    "\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    ## TESTING\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "    #---------------------------------------------------------------------------------------------\n",
    "\n",
    "    # because of new file format, need to only keep certain columns so that the evaluation metrics work with the label tables\n",
    "    column_names = [\"Label\",\"Start\",\"Duration\",\"End\"]\n",
    "    column_names.extend(list(call_types.keys()))  \n",
    "\n",
    "    file_ID_list = [file_ID.split(\".\")[0] for file_ID in testing_filenames if file_ID.split(\".\")[0] not in skipped_files]\n",
    "    labels_list =  [os.path.join(save_label_table_test_path,file_ID.split(\".\")[0]  + \"_LABEL_TABLE.txt\" ) for file_ID in file_ID_list]\n",
    "\n",
    "    # get rid of duplicates\n",
    "    for file in labels_list :\n",
    "        df = pd.read_csv(file, delimiter=';') \n",
    "        # df = df.drop_duplicates(keep=False)\n",
    "        df = df[column_names]\n",
    "        df.to_csv(file, header=True, index=None, sep=';', mode = 'w')\n",
    "\n",
    "    for low_thr in [0.1]:\n",
    "        for high_thr in [0.5,0.6,0.7,0.8,0.9,0.95]: \n",
    "\n",
    "            low_thr = round(low_thr,2)                               \n",
    "            high_thr = round(high_thr,2) \n",
    "            print(\"**********************************************************\")\n",
    "            print(\"Evaluating thresholds: \" + str(low_thr) + \"-\" + str(high_thr))\n",
    "            print(\"**********************************************************\")\n",
    "\n",
    "            if low_thr >= high_thr:\n",
    "                continue\n",
    "\n",
    "            pred_list = [os.path.join(save_pred_table_test_path,file_ID.split(\".\")[0]  + \"_CALLTYPE_PRED_TABLE_thr_\" + str(low_thr) + \"-\" + str(high_thr) + \".txt\" ) for file_ID in file_ID_list ]\n",
    "            evaluation = metrics.Evaluate(label_list = labels_list, \n",
    "                                          prediction_list = pred_list, \n",
    "                                          noise_label = \"noise\", \n",
    "                                          IoU_threshold = 0.2, \n",
    "                                          call_analysis = eval_analysis, \n",
    "                                          GT_proportion_cut = 0.01, \n",
    "                                          no_call = no_call,\n",
    "                                          headers = set(['Label', 'Duration', 'Start', 'End']),\n",
    "                                          nonfoc_tags =[\"NONFOC\", \"nf\", \"*\"]\n",
    "                                         ) # 0.99 is 0.5\n",
    "            output, skipped_calls = evaluation.main()        \n",
    "            print(str(skipped_calls) + \" calls were skipped in total\")\n",
    "\n",
    "            to_pickle = [\"Time_Difference\", \"Matching_Table\", \"Prediction_Indices\", \"Label_Indices\" , \"_Match\"]\n",
    "            for metric in output.keys():\n",
    "                if any(ext in metric for ext in to_pickle):\n",
    "                    filename = \"PRED_TABLE_thr_\" + str(low_thr) + \"-\" + str(high_thr) + \"_\" +str(metric) +\".p\"\n",
    "                    with open(os.path.join(save_metrics_path_eval, filename), 'wb') as fp:\n",
    "                        pickle.dump(output[metric], fp) \n",
    "                else:\n",
    "                    filename = \"PRED_TABLE_thr_\" + str(low_thr) + \"-\" + str(high_thr) + \"_\" +str(metric) +\".csv\"\n",
    "                    output[metric].to_csv(os.path.join(save_metrics_path_eval, filename))    \n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    # PLOT A PREDICTION\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "    pool = audiopool.AudioPool() \n",
    "\n",
    "    # Find a call\n",
    "    call = testing_label_dict[\"cc\"].iloc[0]\n",
    "    label_subset = testing_label_table[testing_label_table['wav_path'].isin([call[\"wav_path\"]])]\n",
    "\n",
    "    # set the labels\n",
    "    label_list = list(testing_label_dict.keys())#list(call_types.keys())\n",
    "    if other_ignored_in_training:\n",
    "        label_list.remove(label_for_other)\n",
    "\n",
    "\n",
    "    # randomise the start a little so the new spectrogram will be a little different from the old\n",
    "    # if the call is very long have a large range to draw the window\n",
    "    if call[\"Duration\"]>= spec_window_size:\n",
    "        call_start = round(float(np.random.uniform(call[\"Start\"]-spec_window_size/2, \n",
    "                                                   call[\"End\"]-spec_window_size/2, 1)), 3)\n",
    "    # if the call is short call, draw it from somewhere\n",
    "    else:\n",
    "        call_start = round(float(np.random.uniform((call[\"Start\"]+call[\"End\"])/2-spec_window_size, \n",
    "                                                   (call[\"Start\"]+call[\"End\"])/2)), 3)\n",
    "\n",
    "    # load in a subsection of the spectrogram\n",
    "    # y, sr = librosa.load(call[\"wav_path\"], sr=None, mono=False,\n",
    "    #                      offset = call_start, duration =self.spec_window_size)\n",
    "    y = pool.get_seconds(call[\"wav_path\"], call_start, spec_window_size)\n",
    "    sr = pool.get_Fs(call[\"wav_path\"])\n",
    "\n",
    "    call_stop = round(call_start + spec_window_size,3 )\n",
    "\n",
    "    # have it as an array\n",
    "    data_subset = np.asfortranarray(y)\n",
    "\n",
    "    #get the spectrogram\n",
    "    spectrogram = pre.generate_mel_spectrogram(data_subset, sr, 0, spec_window_size, \n",
    "                                               n_mels, window, fft_win , fft_hop , normalise)\n",
    "\n",
    "    # generate label\n",
    "    label = pre.create_label_matrix(label_subset, \n",
    "                                    spectrogram, \n",
    "                                    testing_label_dict, \n",
    "                                    call_start, \n",
    "                                    call_stop, \n",
    "                                    label_for_noise, \n",
    "                                    label_for_other, \n",
    "                                    other_ignored_in_training)\n",
    "    # plot spectrogram\n",
    "    plt.figure(figsize=(10,4))\n",
    "    #plt.subplot(411)\n",
    "    yaxis = range(0, np.flipud(spectrogram).shape[0]+1)\n",
    "    xaxis = range(0, np.flipud(spectrogram).shape[1]+1)\n",
    "    plt.xticks(np.arange(0, np.flipud(label).shape[1]+1,50),\n",
    "               list(label.columns[np.arange(0, np.flipud(label).shape[1]+1,50)]))\n",
    "    librosa.display.specshow(spectrogram,  y_axis='mel', x_coords = label.columns)#, x_axis= \"time\",sr=sr, x_coords = label.columns)\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.clim(-35, 35)\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.show()\n",
    "\n",
    "    # plot LABEL\n",
    "    #plt.subplot(412)\n",
    "    #print(label.shape)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    xaxis = range(0, np.flipud(label).shape[1]+1)\n",
    "    yaxis = range(0, np.flipud(label).shape[0]+1)\n",
    "    plt.yticks(np.arange(0.5, len(label_list)+0.5 ,1 ),reversed(label_list))\n",
    "    plt.xticks(np.arange(0, np.flipud(label).shape[1]+1,50),\n",
    "               list(label.columns[np.arange(0, np.flipud(label).shape[1]+1,50)]))\n",
    "    plt.pcolormesh(xaxis, yaxis, np.flipud(label))\n",
    "    plt.clim(0, 1)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Calltype')\n",
    "    plt.colorbar(label=\"Label\")\n",
    "    plt.show()\n",
    "\n",
    "    if is_forked:\n",
    "        # generate matrix of call/not call\n",
    "        callmat = pre.create_call_matrix(label_subset, spectrogram, call_start, call_stop, \n",
    "                                          label_for_noise, label_for_other, other_ignored_in_training)\n",
    "\n",
    "    # prediction\n",
    "    # transpose it and put it in a format that works with the NN\n",
    "    spec = spectrogram.T\n",
    "    spec = spec[np.newaxis, ..., np.newaxis]  \n",
    "\n",
    "    # generate a mask (as a placeholder) but don't mask anything as we are predicting and want to include other\n",
    "    mask = np.asarray([True for i in range(spectrogram.shape[1])])\n",
    "    mask = mask[np.newaxis,...]\n",
    "\n",
    "    # generate the prediction\n",
    "    pred = RNN_model.predict([spec,mask])\n",
    "\n",
    "    # add this prediction to the stack that will be used to generate the predictions table\n",
    "    if is_forked:\n",
    "        calltype_pred= pred[0]\n",
    "        callpresence_pred = pred[1]   \n",
    "    else:\n",
    "        calltype_pred = pred\n",
    "\n",
    "    pred = calltype_pred[0].T\n",
    "\n",
    "    #print(pred.shape)\n",
    "    #plot calltype prediction\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    xaxis = range(0, np.flipud(label).shape[1]+1)\n",
    "    yaxis = range(0, np.flipud(label).shape[0]+1)\n",
    "    plt.yticks(np.arange(0.5, len(label_list)+0.5 ,1 ),reversed(label_list))\n",
    "    plt.xticks(np.arange(0, np.flipud(label).shape[1]+1,50),\n",
    "               list(label.columns[np.arange(0, np.flipud(label).shape[1]+1,50)]))\n",
    "    plt.pcolormesh(xaxis, yaxis, np.flipud(pred))\n",
    "    plt.clim(0, 1)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Calltype Prediction')\n",
    "    plt.colorbar(label=\"Label\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    if is_forked:  \n",
    "        # plot call matrix\n",
    "        #plt.subplot(413)\n",
    "        plt.figure(figsize=(10, 1))\n",
    "        xaxis = range(0, np.flipud(label).shape[1]+1)\n",
    "        yaxis = range(0, np.flipud(callmat).shape[0]+1)\n",
    "        plt.yticks(np.arange(0.5, callmat.shape[0]+0.5 ,1 ), reversed(callmat.index.values))\n",
    "        plt.xticks(np.arange(0, np.flipud(label).shape[1]+1,50),\n",
    "                   list(label.columns[np.arange(0, np.flipud(label).shape[1]+1,50)]))\n",
    "        plt.pcolormesh(xaxis, yaxis, np.flipud(callmat))\n",
    "        plt.clim(0, 1)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Call / No Call')\n",
    "        plt.colorbar(label=\"Label\")\n",
    "        plt.show()\n",
    "\n",
    "        pred = callpresence_pred[0].T\n",
    "        #plot prediction\n",
    "        plt.figure(figsize=(10, 1))\n",
    "        xaxis = range(0, np.flipud(label).shape[1]+1)\n",
    "        yaxis = range(0, np.flipud(callmat).shape[0]+1)\n",
    "        plt.yticks(np.arange(0.5, callmat.shape[0]+0.5 ,1 ), reversed(callmat.index.values))\n",
    "        plt.xticks(np.arange(0, np.flipud(label).shape[1]+1,50),\n",
    "                   list(label.columns[np.arange(0, np.flipud(label).shape[1]+1,50)]))\n",
    "        plt.pcolormesh(xaxis, yaxis, np.flipud(pred))\n",
    "        plt.clim(0, 1)\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Call / No Call prediction')\n",
    "        plt.colorbar(label=\"Label\")\n",
    "        plt.show()\n",
    "\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "    # CONFUSION MATRIX\n",
    "    #--------------------------------------------------------------------------------------------\n",
    "\n",
    "    # loop over the threaholdsf\n",
    "    for low_thr in [0.1]:\n",
    "        for high_thr in [0.5,0.6,0.7,0.8,0.9,0.95]:     \n",
    "            #########################################\n",
    "            # FORMAT \n",
    "\n",
    "            low_thr = round(low_thr,2)                               \n",
    "            high_thr = round(high_thr,2) \n",
    "\n",
    "            if low_thr >= high_thr:\n",
    "                continue\n",
    "            if low_thr == 0.1 and high_thr == 0.2:\n",
    "                continue\n",
    "\n",
    "            if eval_analysis == \"normal\":\n",
    "                confusion_filename = os.path.join(save_metrics_path_eval, \"PRED_TABLE_thr_\" + str(low_thr) + \"-\" + str(high_thr) + '_foc_Confusion_Matrix.csv')\n",
    "            else:\n",
    "                confusion_filename = os.path.join(save_metrics_path_eval, \"PRED_TABLE_thr_\" + str(low_thr) + \"-\" + str(high_thr) + '__Confusion_Matrix.csv')\n",
    "            with open(confusion_filename, newline='') as csvfile:\n",
    "                array = list(csv.reader(csvfile))\n",
    "\n",
    "            df_cm = pd.DataFrame(array) #, range(6), range(6))    \n",
    "\n",
    "            # get rid of the weird indentations and make rows and columns as names\n",
    "            new_col = df_cm.iloc[0] # grab the first row for the header\n",
    "            df_cm = df_cm[1:] # take the data less the header row\n",
    "            df_cm.columns = new_col # set the header row as the df header    \n",
    "            new_row = df_cm['']\n",
    "            df_cm = df_cm.drop('', 1)\n",
    "            df_cm.index = new_row\n",
    "            df_cm.index.name= None\n",
    "            df_cm.columns.name= None\n",
    "\n",
    "            # # replace FP and FN with noise\n",
    "            df_cm['noise'] = df_cm['FN'] \n",
    "            #df_cm.loc['noise']=df_cm.loc['FP']\n",
    "\n",
    "            # remove FP and FN\n",
    "            df_cm = df_cm.drop(\"FN\", axis=1)\n",
    "            #df_cm = df_cm.drop(\"FP\", axis=0)\n",
    "\n",
    "            df_cm = df_cm.apply(pd.to_numeric)\n",
    "\n",
    "            # Raw confusion matrix\n",
    "            df_cm = df_cm[list(testing_label_dict.keys())]\n",
    "            df_cm = df_cm.reindex(list(testing_label_dict.keys()))       \n",
    "\n",
    "            #########################################\n",
    "            # CALCULATE\n",
    "\n",
    "            # Recall confusion matrix\n",
    "            df_recall = df_cm.div(df_cm.sum(axis=1), axis=0).round(2)#pd.DataFrame(df_cm.values / df_cm.sum(axis=1).values).round(2)\n",
    "\n",
    "            # Proportion of calls for confusion matrix\n",
    "            call_len = list()\n",
    "            for i in testing_label_dict.keys():\n",
    "                call_len.append(testing_label_dict[i].shape[0])\n",
    "            # add noise at the end\n",
    "            call_len[-1] = df_cm.sum(axis=1)[-1]\n",
    "\n",
    "            #proportion of calls\n",
    "            df_prop = df_cm.div(call_len, axis=0).round(2)#pd.DataFrame(df_cm.values / df_cm.sum(axis=1).values).round(2)\n",
    "\n",
    "            #########################################\n",
    "            # PLOT\n",
    "\n",
    "            #multi figure parameters\n",
    "            fig,((ax1,ax2,ax3)) = plt.subplots(1,3, figsize=(20,5))\n",
    "            fig.suptitle(str(low_thr) + \" - \" + str(high_thr))\n",
    "\n",
    "            # plot raw\n",
    "            sn.set(font_scale=1.1) # for label size\n",
    "            sn.heatmap((df_cm+1), annot=df_cm, fmt='g',norm = LogNorm(), annot_kws={\"size\": 10}, ax= ax1) # font size\n",
    "            ax1.set_title(\"Raw\")              \n",
    "\n",
    "            # plot recall\n",
    "            sn.set(font_scale=1.1) # for label size\n",
    "            sn.heatmap((df_recall), annot=True, fmt='g', annot_kws={\"size\": 10}, ax= ax2) # font size\n",
    "            ax2.set_title(\"Recall\" )\n",
    "\n",
    "            # plot proportion of calls\n",
    "            sn.set(font_scale=1.1) # for label size\n",
    "            sn.heatmap((df_prop), annot=True, fmt='g', annot_kws={\"size\": 10}, ax= ax3) # font size\n",
    "            ax3.set_title(\"Call Prop\")\n",
    "\n",
    "            # Save 3 panels\n",
    "            plt.savefig(os.path.join(save_metrics_path, eval_analysis, \"Confusion_mat_thr_\" + str(low_thr) + \"-\" + str(high_thr) + '.png'))\n",
    "            plt.show()\n",
    "            plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML1_env",
   "language": "python",
   "name": "ml1_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
